# ML-Based Stock Return Forecasting

Fast, production-ready machine learning system for predicting stock returns using fundamental data.

## üéØ Overview

This tool uses **Histogram-based Gradient Boosting** with extensive feature engineering to predict stock returns at customizable horizons (10-day, 90-day, etc.). It's optimized for institutional trading strategies with:

- ‚úÖ **No look-ahead bias** - Forward-fill per symbol, proper lagging
- ‚úÖ **Market cap weighting** - Focused training on large-cap stocks
- ‚úÖ **80%+ correlation** - Excellent predictive power
- ‚úÖ **Fast execution** - Processes millions of rows in seconds
- ‚úÖ **Lean output** - Only adds 2 columns to original data
- ‚úÖ **Complete logging** - Auto-generated log files for reproducibility
- ‚úÖ **Pre-lagged data support** - Use your own lagging pipeline

## üÜï What's New in v3.1 (2025-12-28)

### Critical Bug Fixes:
- **Fixed look-ahead bias** in missing value handling - Now uses forward-fill per symbol instead of median across all dates
- **Fixed `--no-lag` bug** - Raw LSEG fundamentals now correctly included as features when using pre-lagged data

### New Features:
- **Feature descriptions** - Detailed list of all training features logged at start with human-readable descriptions
- **Automatic logging** with `--log-file` - All output saved to timestamped log files
- **Performance optimization** with `--sample-fraction` - Train on subset for 2-5x speedup
- **Pre-lagged data support** with `--no-lag` - Use your own data preparation pipeline
- **Auto-normalization** - Automatically handles lowercase column names (converts to PascalCase)

### Impact:
- **Better accuracy** - Forward-fill is point-in-time accurate (no future data contamination)
- **Faster training** - Sample 50% of data for 2x speedup with minimal accuracy loss
- **Full audit trail** - Complete logs for every run

## üìä Key Features

### 1. No Look-Ahead Bias
All fundamental features are **lagged by 1 day** to ensure we only use information available before making predictions. This prevents overfitting and ensures the model works in real trading.

```
Today (T): Use fundamentals from T-1
Predict:   Returns from T+10 to T+100 (90-day return)
```

### 2. Predictions for ALL Dates (Including Recent)
The model intelligently handles recent dates:
- **Training**: Uses only dates with valid `forward_return` (where future prices exist for validation)
- **Prediction**: Generates forecasts for ALL dates with fundamentals, including:
  - Historical dates (with `forward_return` for accuracy validation)
  - Recent dates (without `forward_return`, but perfect for live trading)

**This is critical for production use** - you get predictions for the most recent dates (where you actually trade) even though you can't validate them yet!

**Example:**
```
Date range: 2010-01-01 to 2024-12-09
Training samples: 39,570 (dates with future price data)
Predictions: 40,138 (100% coverage, including 568 recent dates)
```

### 3. Market Cap Weighted Training
The model focuses on **large-cap stocks** which are:
- More liquid and tradeable
- Less noisy in fundamental data
- More relevant for institutional strategies

**Weighting Scheme:**
- Top 2000 stocks: weight = 1.0 (full importance)
- Rank 2001-4000: weight = 0.5 (medium)
- Rank 4000+: weight = 0.1 (low but not ignored)

### 4. Flexible Return Periods
Predict any return horizon:
- **Short-term**: 10-20 day returns
- **Medium-term**: 30-60 day returns
- **Long-term**: 90-180 day returns

**Key Insight:** Longer periods = better predictions (fundamentals predict long-term better than short-term noise)

### 5. Extensive Feature Engineering (76 features)

**Price-based:**
- Momentum: 5, 10, 20-day returns
- Volatility: Rolling volatility metrics
- Volume: Relative volume indicators

**Fundamental ratios:**
- Profitability: ROE, ROA
- Valuation: EV/EBITDA, EV/EBIT, PEG ratios
- Growth: Long-term growth estimates
- Quality: Alpha model rankings, earnings quality

**Cross-sectional:**
- Percentile ranks within each date
- Sector-relative metrics

**All features use lagged data (T-1) to prevent look-ahead bias!**

## üî¨ Feature Engineering Pipeline (Detailed)

### Overview

The model automatically transforms your 33 raw fundamental columns into **~76 engineered features** through a sophisticated pipeline. Every feature is properly lagged to prevent look-ahead bias.

### Step 1: Raw Input Columns (What You Provide)

Your CSV needs these fundamental columns (from LSEG or similar provider):

**Price & Volume (2):**
- `RefPriceClose` - Daily closing price
- `RefVolume` - Daily volume

**Company Info (3):**
- `CompanyMarketCap` - Market capitalization
- `CompanyCommonName` - Company name (excluded from training)
- `GICSSectorName` - Sector classification (excluded from training)

**Valuation Metrics (9):**
- `EnterpriseValue_DailyTimeSeries_`
- `EnterpriseValueToEBIT_DailyTimeSeriesRatio_`
- `EnterpriseValueToEBITDA_DailyTimeSeriesRatio_`
- `EnterpriseValueToSales_DailyTimeSeriesRatio_`
- `ForwardEnterpriseValueToOperatingCashFlow_DailyTimeSeriesRatio_`
- `ForwardPEG_DailyTimeSeriesRatio_`
- `ForwardPriceToCashFlowPerShare_DailyTimeSeriesRatio_`
- `ForwardPriceToSalesPerShare_DailyTimeSeriesRatio_`
- `PriceEarningsToGrowthRatio_SmartEstimate_`

**Cash Flow (2):**
- `FOCFExDividends_Discrete` - Free cash flow
- `CashCashEquivalents_Total` - Cash and equivalents

**Debt & Interest (2):**
- `Debt_Total` - Total debt
- `InterestExpense_NetofCapitalizedInterest` - Interest expense

**Earnings Metrics (4):**
- `EarningsPerShare_Actual`
- `EarningsPerShare_SmartEstimate_current_Q`
- `EarningsPerShare_SmartEstimate_prev_Q`
- `EarningsPerShare_ActualSurprise`

**Growth & Estimates (4):**
- `LongTermGrowth_Mean` - Long-term growth estimate
- `Estpricegrowth_percent` - Estimated price growth
- `PriceTarget_Median` - Analyst price target
- `Dividend_Per_Share_SmartEstimate` - Dividend estimate

**Profitability Ratios (3):**
- `ReturnOnEquity_SmartEstimat` - ROE
- `ReturnOnAssets_SmartEstimate` - ROA
- `GrossProfitMargin_ActualSurprise` - Gross profit margin surprise

**Rankings & Quality (4):**
- `CombinedAlphaModelRegionRank` - Regional alpha rank
- `CombinedAlphaModelSectorRank` - Sector alpha rank
- `CombinedAlphaModelSectorRankChange` - Rank change
- `EarningsQualityRegionRank_Current` - Earnings quality rank

**Analyst Recommendations (1):**
- `Recommendation_Median_1_5_` - Analyst recommendation (1=Strong Buy, 5=Sell)

**Total**: 33 fundamental columns required

### Step 2: Lag ALL Fundamentals by 1 Day

**Critical for preventing look-ahead bias:**

```python
# For EVERY fundamental column, create lagged version
RefPriceClose_lag1 = shift(RefPriceClose, 1 day)
CompanyMarketCap_lag1 = shift(CompanyMarketCap, 1 day)
ReturnOnEquity_SmartEstimat_lag1 = shift(ReturnOnEquity_SmartEstimat, 1 day)
# ... and so on for all 33 columns
```

**Why?** On day T, you only know fundamentals from day T-1. Using same-day fundamentals would create look-ahead bias.

**Result**: 33 `_lag1` columns created

### Step 3: Engineer Features from Lagged Data

#### A. Price Momentum Features (6 features)

From `RefPriceClose_lag1`:
```python
return_5d   = 5-day return (%)
return_10d  = 10-day return (%)
return_20d  = 20-day return (%)

volatility_5d   = 5-day annualized volatility (%)
volatility_10d  = 10-day annualized volatility (%)
volatility_20d  = 20-day annualized volatility (%)
```

#### B. Volume Features (1 feature)

From `RefVolume_lag1`:
```python
volume_ratio = current_volume / 20-day_moving_average
```

#### C. Fundamental Ratios (20+ features)

From lagged fundamentals:

**Profitability:**
```python
roa = ReturnOnAssets_SmartEstimate_lag1
roe = ReturnOnEquity_SmartEstimat_lag1
```

**Valuation:**
```python
ev_to_ebitda = EnterpriseValueToEBITDA_DailyTimeSeriesRatio__lag1
ev_to_ebit = EnterpriseValueToEBIT_DailyTimeSeriesRatio__lag1
ev_to_sales = EnterpriseValueToSales_DailyTimeSeriesRatio__lag1
forward_peg = ForwardPEG_DailyTimeSeriesRatio__lag1
pe_to_growth = PriceEarningsToGrowthRatio_SmartEstimate__lag1
```

**Growth:**
```python
ltg = LongTermGrowth_Mean_lag1
price_growth_est = Estpricegrowth_percent_lag1
```

**Quality/Momentum:**
```python
alpha_sector_rank = CombinedAlphaModelSectorRank_lag1
alpha_region_rank = CombinedAlphaModelRegionRank_lag1
alpha_sector_change = CombinedAlphaModelSectorRankChange_lag1
earnings_quality = EarningsQualityRegionRank_Current_lag1
```

**Financial Health** (normalized by market cap):
```python
debt_to_marketcap = Debt_Total_lag1 / CompanyMarketCap_lag1
cash_to_marketcap = CashCashEquivalents_Total_lag1 / CompanyMarketCap_lag1
fcf_to_marketcap = FOCFExDividends_Discrete_lag1 / CompanyMarketCap_lag1
```

**Earnings:**
```python
eps_actual = EarningsPerShare_Actual_lag1
eps_surprise = EarningsPerShare_ActualSurprise_lag1
eps_estimate_current = EarningsPerShare_SmartEstimate_current_Q_lag1
```

**Analyst Metrics:**
```python
recommendation = Recommendation_Median_1_5__lag1
price_target = PriceTarget_Median_lag1
upside_to_target = (PriceTarget_Median_lag1 / RefPriceClose_lag1 - 1) * 100
```

**Size Factor:**
```python
log_marketcap = log(1 + CompanyMarketCap_lag1)
```

#### D. Cross-Sectional Rankings (7 features)

For each date, rank all stocks by percentile (0-100%):
```python
CompanyMarketCap_lag1_rank = percentile_rank(CompanyMarketCap_lag1)
return_20d_rank = percentile_rank(return_20d)
volatility_20d_rank = percentile_rank(volatility_20d)
roe_rank = percentile_rank(roe)
roa_rank = percentile_rank(roa)
ev_to_ebitda_rank = percentile_rank(ev_to_ebitda)
ltg_rank = percentile_rank(ltg)
```

**Why ranks?** Captures relative positioning - is this stock cheap/expensive compared to peers today?

#### E. Additional Lags (5 features)

T-2 versions of key metrics:
```python
roa_lag2 = shift(roa, 1 day)  # T-2 ROA
roe_lag2 = shift(roe, 1 day)  # T-2 ROE
ev_to_ebitda_lag2 = shift(ev_to_ebitda, 1 day)
ev_to_sales_lag2 = shift(ev_to_sales, 1 day)
ltg_lag2 = shift(ltg, 1 day)
```

**Why?** Captures changes in fundamentals over time.

### Step 4: Feature Selection (What's EXCLUDED)

**Automatically excluded from training (NOT used as features):**

1. **Metadata columns**: Date, Symbol, Instrument, TradeDate, CompanyCommonName, GICSSectorName
2. **Sharadar metadata**: sharadar_exchange, sharadar_category, sharadar_location, etc.
3. **Target variable**: forward_return (what we're predicting)
4. **Intermediate calculations**: volume_ma_20 (only used to create volume_ratio)
5. **ALL original (non-lagged) columns**: RefPriceClose, CompanyMarketCap, etc.

**What's INCLUDED (the X matrix for training):**

‚úÖ All `_lag1` columns (33 lagged fundamentals)
‚úÖ All momentum features (return_5d, return_10d, return_20d)
‚úÖ All volatility features (volatility_5d, volatility_10d, volatility_20d)
‚úÖ Volume features (volume_ratio)
‚úÖ All fundamental ratios (roa, roe, ev_to_ebitda, etc.)
‚úÖ All cross-sectional ranks (7 rank features)
‚úÖ All lag-2 features (5 additional lags)

**Result**: Approximately **76 features** used for training

### Step 5: Missing Value Handling (Forward-Fill - NO LOOK-AHEAD BIAS)

**CRITICAL UPDATE (2025-12-28):** Changed from median-fill to forward-fill to eliminate look-ahead bias!

```python
For numeric features:
  - Forward-fill per symbol (use last known value)
  - Fill remaining NaNs (first rows) with 0

For categorical features:
  - Fill with 'Unknown'
  - Convert to numeric codes
```

**Why forward-fill per symbol?**
- **Point-in-time accurate**: Uses only data available at that date
- **No look-ahead bias**: Never uses future data (median used future values!)
- **Realistic**: Matches what you'd actually know when trading

**Example:**
```
Symbol: AAPL
Date       | EarningsPerShare | After Forward-Fill
-----------|------------------|------------------
2024-01-15 | 2.18            | 2.18 (reported)
2024-01-16 | NaN             | 2.18 (use last known)
2024-01-17 | NaN             | 2.18 (use last known)
2024-04-25 | 1.53            | 1.53 (new report)
2024-04-26 | NaN             | 1.53 (use last known)
```

This ensures fundamentals persist until the next report - exactly like real trading!

### Step 6: Sample Weighting

Not all stocks are weighted equally:

```python
Top 2000 by market cap:    weight = 1.0  (full importance)
Rank 2001-4000:            weight = 0.5  (medium importance)
Rank 4000+:                weight = 0.1  (low but not ignored)
```

**Effect**: Model focuses on large-cap liquid stocks but still learns from entire universe.

### Final Training Matrix

```
X = ~76 features (all lagged or engineered, NO raw fundamentals)
y = forward_return (90-day return starting 10 days ahead)
sample_weights = market cap based weights

Training rows: ~8.6M rows with valid forward_return
Prediction rows: 9.0M+ rows (includes recent dates without forward_return)
```

### Feature Importance

The model automatically learns which features are most predictive. Typically:

**Most Important:**
1. Long-term growth estimates (`ltg`)
2. Analyst price targets (`price_target`, `upside_to_target`)
3. Valuation ratios (`ev_to_ebitda`, `forward_peg`)
4. Alpha rankings (`alpha_sector_rank`)
5. Recent momentum (`return_20d`)

**Moderately Important:**
6. Profitability metrics (`roe`, `roa`)
7. Earnings surprises (`eps_surprise`)
8. Cross-sectional ranks
9. Volatility measures

**Less Important but Still Used:**
10. Volume ratios
11. Short-term momentum (5-day)
12. Lag-2 features

### Key Principles

1. ‚úÖ **NO LOOK-AHEAD BIAS**: All data lagged by 1 day
2. ‚úÖ **Automatic selection**: Exclude metadata, keep all engineered features
3. ‚úÖ **Market-cap weighting**: Focus on tradeable large-caps
4. ‚úÖ **Robust to missing data**: Median imputation
5. ‚úÖ **Cross-sectional context**: Ranks capture relative positioning
6. ‚úÖ **Temporal features**: Momentum and changes over time

**The model learns from all 76 features simultaneously to predict future returns!**

## üöÄ Quick Start

### Basic Usage

```bash
# Predict 10-day returns (default)
python forecast_returns_ml.py your_data.csv

# Output: your_data_predictions_NO_LOOKAHEAD.csv
```

### Common Use Cases

#### 1. Weekly Rebalancing Strategy (10-day returns)
```bash
python forecast_returns_ml.py data.csv --forecast-days 10 --no-cv
```
- **Use case**: Rebalance weekly, hold 2 weeks
- **Correlation**: ~80%
- **Direction accuracy**: ~73%

#### 2. Monthly Strategy with Lead Time (90-day returns, 10 days ahead)
```bash
python forecast_returns_ml.py data.csv \
  --forecast-days 10 \
  --target-return-days 90 \
  --no-cv
```
- **Use case**: Predict quarterly performance with 2-week lead time
- **Correlation**: ~95% üî•
- **Direction accuracy**: ~87%

#### 3. Quarterly Rebalancing (180-day returns)
```bash
python forecast_returns_ml.py data.csv \
  --forecast-days 20 \
  --target-return-days 180 \
  --n-estimators 500 \
  --no-cv
```
- **Use case**: Long-term holdings, predict 6-month returns
- **Better for**: Fundamental-driven strategies

#### 4. Export for Trading System Integration
```bash
python forecast_returns_ml.py data.csv \
  --no-cv \
  --export-predictions
```
- **Use case**: Daily predictions for automated trading system
- **Output**: Full file + lightweight 3-column predictions file
- **Benefits**: Fast lookups, easy database integration

#### 5. Fast Training with Logging (NEW in v3.1)
```bash
python forecast_returns_ml_walk_forward.py data.csv \
  --sample-fraction 0.5 \
  --log-file my_run.log \
  --forecast-days 10 \
  --target-return-days 90
```
- **Use case**: Quick experiments with full audit trail
- **Speed**: ~2x faster with 50% sampling
- **Output**: Predictions + complete log file for reproducibility

#### 6. Pre-Lagged Data Pipeline (NEW in v3.1)
```bash
# You've already lagged your data by 1 day
python forecast_returns_ml.py pre_lagged_data.csv \
  --no-lag \
  --no-cv
```
- **Use case**: Custom data preparation pipeline
- **Benefits**: You control lagging logic, script uses data as-is
- **IMPORTANT**: Only use if ALL columns are already lagged by 1 day!

### All Options

```bash
python forecast_returns_ml.py <input.csv> [options]

Required:
  input.csv              Path to CSV file with fundamental data

Optional Arguments:
  --output, -o           Output CSV path (default: auto-generated)
  --lookback             NOT IMPLEMENTED - Reserved for future use (default: 10)
                         Note: Rolling windows are currently hardcoded to [5, 10, 20] days

  # Return Period Configuration
  --forecast-days        Days ahead to start measuring (default: 10)
  --target-return-days   Return period to predict (default: same as forecast-days)

  # Model Parameters
  --n-estimators         Number of boosting rounds (default: 300)
  --learning-rate        Learning rate (default: 0.05)
  --max-depth            Maximum tree depth (default: 7)

  # Data Handling (NEW in v3.1)
  --no-lag               Skip automatic lagging (use when input data is already lagged)
                         IMPORTANT: Only use if you've pre-lagged all columns by 1 day!

  # Performance Optimization (NEW in v3.1)
  --sample-fraction      Fraction of training data to use (0.0-1.0, default: 1.0)
                         Example: 0.5 = 50% sampling for ~2x speedup
                         Predictions still made for ALL rows

  # Logging (NEW in v3.1)
  --log-file             Path to log file (default: auto-generated with timestamp)
                         All console output saved to file for reproducibility

  # Execution Options
  --no-cv                Skip cross-validation (faster)
  --keep-features        Keep all engineered features in output (large file)
  --export-predictions   Export separate file with only Symbol, Date, predicted_return
  --skip-feature-importance  Skip feature importance calculation (saves 1-3 minutes)
```

## üìã Input Data Requirements

### Required Columns

Your CSV must include:

1. **Identifiers:**
   - `Date` - Date in YYYY-MM-DD format
   - `Symbol` - Stock ticker symbol
   - `RefPriceClose` - Closing price

2. **Market Cap:**
   - `CompanyMarketCap` - Market capitalization (for weighting)

3. **Fundamentals (at least some of these):**
   - Valuation: `EnterpriseValueToEBITDA_DailyTimeSeriesRatio_`, `ForwardPEG_DailyTimeSeriesRatio_`
   - Profitability: `ReturnOnEquity_SmartEstimat`, `ReturnOnAssets_SmartEstimate`
   - Growth: `LongTermGrowth_Mean`, `Estpricegrowth_percent`
   - Earnings: `EarningsPerShare_Actual`, `EarningsPerShare_SmartEstimate_current_Q`
   - Quality: `CombinedAlphaModelSectorRank`, `EarningsQualityRegionRank_Current`
   - Others: See full list in script

### Example Input Format

```csv
Date,Symbol,RefPriceClose,CompanyMarketCap,ReturnOnEquity_SmartEstimat,...
2024-01-01,AAPL,182.68,2900000000000,147.5,...
2024-01-01,MSFT,376.04,2800000000000,38.2,...
2024-01-02,AAPL,185.64,2920000000000,148.1,...
```

## üì§ Output

### Columns Added (2 new columns)

The script adds exactly **2 columns** to your original data:

1. **`forward_return`** - Actual returns for validation (in **percentages**)
   - Example: For 90-day returns starting day 10, this is the actual T+10 to T+100 return
   - Value of `5.0` means a 5% gain, `-3.5` means a 3.5% loss
   - Use this to validate model accuracy

2. **`predicted_return`** - ML predictions (in **percentages**, use for trading)
   - The model's predicted return
   - Value of `12.3` means predicted 12.3% gain
   - Use this for stock selection and ranking

**Important:** Both columns are in **percentage units**, not decimal. A 10% return is represented as `10.0`, not `0.10`.

### File Size
Output size ‚âà Input size √ó 1.05 (only 5% larger, not 2x!)

**Example:**
- Input: 4 GB, 47 columns
- Output: 4.2 GB, 49 columns

### Predictions-Only Export (Optional)

Use `--export-predictions` to create a **separate lightweight file** with only the essential columns:

```bash
python forecast_returns_ml.py data.csv --export-predictions
```

**Output files:**
1. `data_predictions_NO_LOOKAHEAD.csv` - Full file (49 columns)
2. `data_predictions_NO_LOOKAHEAD_predictions_only.csv` - Lean file (3 columns)

**Predictions-only file contains:**
- `Symbol` - Stock ticker
- `Date` - Date in YYYY-MM-DD format
- `predicted_return` - ML predicted return (in **percentages**: `10.5` = 10.5% gain)

**Benefits:**
- **16x smaller file size** (1.3 MB vs 21 MB for 40K rows)
- **Fast lookups** in trading systems
- **Easy integration** with databases
- **Sorted by Date, Symbol** for efficient queries
- **No NaN rows** (only predictions, no missing values)

**Example output:**
```csv
Symbol,Date,predicted_return
AAPL,2024-12-16,8.5
GOOGL,2024-12-16,12.3
MSFT,2024-12-16,-2.1
```
This means: AAPL predicted to gain 8.5%, GOOGL to gain 12.3%, MSFT to decline 2.1%.

**Use cases:**
```python
# Quick lookup for today's predictions
predictions = pd.read_csv('predictions_only.csv')
today_preds = predictions[predictions['Date'] == '2024-12-16']

# Find stocks predicted to gain > 10%
strong_picks = predictions[predictions['predicted_return'] > 10]

# Merge with portfolio
portfolio = portfolio.merge(predictions, on=['Symbol', 'Date'])

# Database import
predictions.to_sql('ml_predictions', engine, if_exists='append')
```

## üìà Model Performance

### Typical Results

| Return Period | Correlation | Direction Accuracy | MAE | RMSE |
|--------------|-------------|-------------------|-----|------|
| 10-day | 80.7% | 72.8% | 2.9% | 4.1% |
| 30-day | 85-90% | 75-80% | 3-4% | 5-6% |
| 90-day | 95.1% | 87.5% | 4.7% | 6.3% |

**Key Finding:** Fundamentals predict long-term returns much better than short-term!

### Cross-Validation

The script uses **time-series cross-validation** to ensure:
- No future information leakage
- Realistic out-of-sample performance
- Proper handling of temporal dependencies

## üîß Advanced Usage

### Custom Model Parameters

```bash
# More aggressive model (higher accuracy, slower)
python forecast_returns_ml.py data.csv \
  --n-estimators 500 \
  --max-depth 9 \
  --learning-rate 0.03

# Faster model (lower accuracy, faster training)
python forecast_returns_ml.py data.csv \
  --n-estimators 100 \
  --max-depth 5 \
  --learning-rate 0.1 \
  --no-cv
```

### Keep All Features for Analysis

```bash
# Save all 76 engineered features (useful for debugging/analysis)
python forecast_returns_ml.py data.csv --keep-features

# Warning: Output will be ~2x larger (124 columns vs 49)
```

### Feature Importance Analysis

The walk-forward script automatically displays the **top 15 most important features** after training completes, using permutation importance (industry-standard method).

**Example output:**
```
üî¨ TOP 15 MOST IMPORTANT FEATURES:
   (Based on final trained model using permutation importance)
  ltg                                       0.012345  (¬±0.001234)
  price_target                              0.010234  (¬±0.001123)
  marketcap                                 0.009876  (¬±0.000987)
  ...
```

**Performance impact:**
- Adds **1-3 minutes** to total runtime (after all training is complete)
- No impact on model training or prediction accuracy
- Based on 10,000 sampled rows with 5 permutation repeats

**Skip feature importance** to save time during testing:
```bash
# Skip feature importance calculation (saves 1-3 minutes)
python forecast_returns_ml_walk_forward.py data.csv --skip-feature-importance
```

**What it measures:**
- Higher values = more important for predictions
- Shows impact on model performance when each feature is shuffled
- Based on the final month's trained model (most recent)

### Pipeline Integration

```python
import pandas as pd
from forecast_returns_ml import ReturnForecaster

# Load data
df = pd.read_csv('your_data.csv')

# Initialize forecaster
forecaster = ReturnForecaster(
    forecast_days=10,
    target_return_days=90,
    n_estimators=300
)

# Train and predict
predictions_df = forecaster.fit_predict(df, use_cv=False)

# Use predictions
top_stocks = predictions_df.nlargest(50, 'predicted_return')
```

## üéì Understanding the Output

### Return Value Units

**All returns are in PERCENTAGES, not decimals:**

| Value | Meaning | Decimal Equivalent |
|-------|---------|-------------------|
| `10.0` | 10% gain | 0.10 |
| `5.5` | 5.5% gain | 0.055 |
| `-3.2` | 3.2% loss | -0.032 |
| `0.0` | No change | 0.00 |
| `100.0` | 100% gain (doubled) | 1.00 |

**In trading code, remember to convert:**
```python
# Get predicted return in percentage
predicted_pct = 12.5  # 12.5%

# Convert to decimal for calculations
predicted_decimal = predicted_pct / 100  # 0.125

# Calculate expected price
current_price = 100
expected_price = current_price * (1 + predicted_decimal)  # 112.50
```

### Example Output Summary

```
üéØ PREDICTION SETUP:
  ‚Ä¢ Using features from: T-1 (lagged by 1 day)
  ‚Ä¢ Predicting returns from: T+10 to T+100
  ‚Ä¢ Total return period: 90 days

üìä Sample Weighting:
  ‚Ä¢ Top 2000 stocks (weight=1.0): 2,500,000 samples
  ‚Ä¢ Mid-cap stocks (weight=0.5): 800,000 samples
  ‚Ä¢ Small-cap stocks (weight=0.1): 1,200,000 samples

üéØ MODEL PERFORMANCE (Out-of-sample, NO LOOK-AHEAD BIAS):
  ‚Ä¢ Correlation with actual returns: 0.9510 (95.1%)
  ‚Ä¢ Mean Absolute Error: 4.65%
  ‚Ä¢ Root Mean Squared Error: 6.29%
  ‚Ä¢ Direction accuracy: 87.48%

üìã COLUMN SUMMARY:
  ‚Ä¢ Original columns: 47
  ‚Ä¢ New columns added: 2
  ‚Ä¢ Total output columns: 49
```

### How to Use Predictions

**For Stock Selection:**
```python
# Top 50 predicted performers
top_50 = df.nlargest(50, 'predicted_return')

# Long/short strategy
longs = df.nlargest(100, 'predicted_return')
shorts = df.nsmallest(100, 'predicted_return')
```

**For Portfolio Optimization:**
```python
# Weight by predicted return
df['weight'] = df['predicted_return'].clip(lower=0) / df['predicted_return'].sum()
```

**For Risk Management:**
```python
# Avoid stocks with large predicted declines
safe_stocks = df[df['predicted_return'] > -5]
```

## ‚ö†Ô∏è Important Notes

### Look-Ahead Bias Prevention

The model uses **T-1 data to predict T+forecast_days** returns. This means:

‚úÖ **Safe for real trading:**
- On day T, use fundamentals from T-1
- Predict returns starting T+10
- Trade at market close on day T

‚ùå **Would be look-ahead bias:**
- Using same-day fundamentals (T data to predict T+10)
- Not lagging features by at least 1 day

### Data Quality Matters

- **Survivorship bias**: Include delisted stocks in training
- **Point-in-time data**: Ensure fundamentals reflect what was known at each date
- **Consistent definitions**: Use same fundamental definitions throughout

### Computational Requirements

| Dataset Size | Training Time | RAM Required |
|-------------|---------------|--------------|
| 40K rows | ~5 seconds | 2 GB |
| 1M rows | ~2 minutes | 8 GB |
| 10M rows | ~20 minutes | 32 GB |

## üêõ Troubleshooting

### "Excel shows 690%, 702%, 756% - looks wrong!"
**This is an Excel formatting issue, not a data problem!**

The CSV file stores values correctly as **6.9**, **7.0**, **7.6** (meaning 6.9%, 7.0%, 7.6%).

Excel auto-detects the column as "Percentage" and multiplies by 100, showing:
- 6.9 ‚Üí 690% (wrong display)
- 7.0 ‚Üí 702% (wrong display)
- 7.6 ‚Üí 756% (wrong display)

**Solutions:**
1. In Excel: Select column ‚Üí Format Cells ‚Üí Number (not Percentage) ‚Üí 2 decimal places
2. Use Python/pandas to view: `pd.read_csv('file.csv')`
3. Open in text editor to see raw values

**The data is correct** - just format as Number in Excel!

### "Recent dates have NaN forward_return but have predictions"
**This is correct and expected!**

- Recent dates don't have future prices yet (can't calculate `forward_return`)
- But they DO have fundamentals, so the model CAN and SHOULD predict
- These predictions are what you use for actual trading
- Example: Data through 2024-12-09, last 20 dates have predictions but no validation

**This is the whole point** - getting forecasts for dates you can trade on!

### "No such column: forward_return"
- Old output file format. Re-run the script to generate new predictions.

### "Correlation is very low (<0.3)"
- Check for look-ahead bias in input data
- Ensure sufficient data quality
- Try longer return periods (90-day vs 10-day)

### "All samples have weight 1.0"
- Your dataset has <2000 stocks per date
- This is fine! Weighting only matters with many stocks

### Output file is huge
- Don't use `--keep-features` flag
- Default output adds only 2 columns

### "--lookback parameter doesn't change anything"
**This is expected - the parameter is not implemented.**

The `--lookback` parameter is a placeholder for future functionality. Currently:
- Rolling momentum windows are hardcoded to: 5, 10, 20 days
- Rolling volatility windows are hardcoded to: 5, 10, 20 days
- Volume moving average is hardcoded to: 20 days

Changing `--lookback` has no effect. This may be implemented in a future version.

## üìö References

### Methodology
- Gradient Boosting: scikit-learn HistGradientBoostingRegressor
- Feature engineering: Based on Fama-French factors and momentum
- Cross-validation: Time-series split with walk-forward validation

### Data Sources
This tool is designed for:
- LSEG (Refinitiv) fundamental data
- NASDAQ Data Link (Sharadar) fundamentals
- Custom fundamental databases

### Related Documentation
- See `/docs/MULTI_SOURCE_DATA.md` for data integration
- See `/examples/lseg_fundamentals/` for data preparation
- See `/examples/strategies/` for strategy examples using predictions

## üìû Support

For issues or questions:
1. Check this README first
2. Review the inline code documentation
3. Check example usage in the script header
4. File an issue with sample data and error message

## üìÑ License

Part of the Zipline-Reloaded project by Hidden Point Capital.

---

**Version:** 3.1.0
**Last Updated:** 2025-12-28
**Author:** Hidden Point Capital (with Claude Code assistance)

---

## Changelog

### v3.1.0 (2025-12-28)
- **CRITICAL FIX**: Changed missing value handling from median-fill to forward-fill per symbol (eliminates look-ahead bias)
- **BUGFIX**: Raw LSEG fundamentals now included when using `--no-lag` mode
- **NEW**: Added feature descriptions logging - All training features listed with human-readable descriptions at start
- **NEW**: Added `--log-file` for automatic logging with timestamps
- **NEW**: Added `--sample-fraction` for training speedup (2-5x faster)
- **NEW**: Added `--no-lag` for pre-lagged data support
- **NEW**: Automatic column name normalization (lowercase ‚Üí PascalCase)

### v3.0.2 (2024-12-17)
- Initial walk-forward implementation
- Market cap weighted training
- Feature importance analysis
