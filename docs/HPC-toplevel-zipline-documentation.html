<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hidden Point Capital - Zipline-Reloaded Documentation</title>
    <style>
        :root {
            --bg-primary: #1a1b26;
            --bg-secondary: #24283b;
            --bg-tertiary: #414868;
            --text-primary: #a9b1d6;
            --text-secondary: #7aa2f7;
            --text-muted: #565f89;
            --accent-blue: #7aa2f7;
            --accent-green: #9ece6a;
            --accent-yellow: #e0af68;
            --accent-red: #f7768e;
            --accent-purple: #bb9af7;
            --accent-cyan: #7dcfff;
            --border-color: #3b4261;
            --code-bg: #1f2335;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background-color: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.6;
        }

        /* Layout */
        .container {
            display: flex;
            min-height: 100vh;
        }

        /* Sidebar Navigation */
        .sidebar {
            width: 280px;
            background-color: var(--bg-secondary);
            border-right: 1px solid var(--border-color);
            position: fixed;
            top: 0;
            left: 0;
            height: 100vh;
            overflow-y: auto;
            padding: 20px 0;
        }

        .sidebar-header {
            padding: 0 20px 20px;
            border-bottom: 1px solid var(--border-color);
            margin-bottom: 15px;
        }

        .sidebar-header h1 {
            color: var(--accent-cyan);
            font-size: 1.4em;
            margin-bottom: 5px;
        }

        .sidebar-header p {
            color: var(--text-muted);
            font-size: 0.85em;
        }

        .nav-section {
            margin-bottom: 20px;
        }

        .nav-section-title {
            padding: 8px 20px;
            font-size: 0.75em;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--text-muted);
        }

        .nav-item {
            display: block;
            padding: 8px 20px;
            color: var(--text-primary);
            text-decoration: none;
            font-size: 0.9em;
            transition: all 0.2s;
            border-left: 3px solid transparent;
        }

        .nav-item:hover {
            background-color: var(--bg-tertiary);
            color: var(--accent-blue);
            border-left-color: var(--accent-blue);
        }

        .nav-item.active {
            background-color: var(--bg-tertiary);
            color: var(--accent-cyan);
            border-left-color: var(--accent-cyan);
        }

        .nav-subitem {
            padding-left: 35px;
            font-size: 0.85em;
            color: var(--text-muted);
        }

        .nav-subitem:hover {
            color: var(--text-primary);
        }

        /* Main Content */
        .main-content {
            flex: 1;
            margin-left: 280px;
            padding: 40px 60px;
            max-width: 1200px;
        }

        /* Typography */
        h1, h2, h3, h4 {
            color: var(--text-secondary);
            margin-bottom: 15px;
        }

        h1 {
            font-size: 2.2em;
            border-bottom: 2px solid var(--accent-cyan);
            padding-bottom: 15px;
            margin-bottom: 30px;
        }

        h2 {
            font-size: 1.6em;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid var(--border-color);
        }

        h3 {
            font-size: 1.3em;
            color: var(--accent-green);
            margin-top: 25px;
        }

        h4 {
            font-size: 1.1em;
            color: var(--accent-yellow);
        }

        p {
            margin-bottom: 15px;
        }

        /* Section containers */
        .section {
            margin-bottom: 60px;
            scroll-margin-top: 20px;
        }

        /* Code blocks */
        pre {
            background-color: var(--code-bg);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 15px;
            overflow-x: auto;
            margin: 15px 0;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 0.85em;
            line-height: 1.5;
        }

        code {
            background-color: var(--code-bg);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 0.9em;
            color: var(--accent-cyan);
        }

        pre code {
            background: none;
            padding: 0;
            color: var(--text-primary);
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
            font-size: 0.9em;
        }

        th, td {
            padding: 12px 15px;
            text-align: left;
            border: 1px solid var(--border-color);
        }

        th {
            background-color: var(--bg-secondary);
            color: var(--accent-blue);
            font-weight: 600;
        }

        tr:nth-child(even) {
            background-color: var(--bg-secondary);
        }

        /* Lists */
        ul, ol {
            margin: 15px 0;
            padding-left: 25px;
        }

        li {
            margin-bottom: 8px;
        }

        /* Links */
        a {
            color: var(--accent-blue);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
            color: var(--accent-cyan);
        }

        /* Callouts */
        .callout {
            padding: 15px 20px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid;
        }

        .callout-info {
            background-color: rgba(122, 162, 247, 0.1);
            border-left-color: var(--accent-blue);
        }

        .callout-warning {
            background-color: rgba(224, 175, 104, 0.1);
            border-left-color: var(--accent-yellow);
        }

        .callout-success {
            background-color: rgba(158, 206, 106, 0.1);
            border-left-color: var(--accent-green);
        }

        .callout-danger {
            background-color: rgba(247, 118, 142, 0.1);
            border-left-color: var(--accent-red);
        }

        /* Badge */
        .badge {
            display: inline-block;
            padding: 3px 8px;
            border-radius: 4px;
            font-size: 0.75em;
            font-weight: 600;
            margin-left: 8px;
        }

        .badge-time {
            background-color: var(--accent-purple);
            color: var(--bg-primary);
        }

        /* Feature cards */
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .feature-card {
            background-color: var(--bg-secondary);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 20px;
        }

        .feature-card h4 {
            margin-bottom: 10px;
        }

        /* Top button */
        .back-to-top {
            position: fixed;
            bottom: 30px;
            right: 30px;
            background-color: var(--accent-blue);
            color: var(--bg-primary);
            width: 45px;
            height: 45px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            text-decoration: none;
            font-size: 1.2em;
            opacity: 0;
            transition: opacity 0.3s;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        }

        .back-to-top.visible {
            opacity: 1;
        }

        .back-to-top:hover {
            background-color: var(--accent-cyan);
            text-decoration: none;
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .sidebar {
                width: 240px;
            }
            .main-content {
                margin-left: 240px;
                padding: 30px 40px;
            }
        }

        @media (max-width: 768px) {
            .sidebar {
                transform: translateX(-100%);
                transition: transform 0.3s;
                z-index: 1000;
            }
            .sidebar.open {
                transform: translateX(0);
            }
            .main-content {
                margin-left: 0;
                padding: 20px;
            }
        }

        /* Command reference styling */
        .command-block {
            background-color: var(--code-bg);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }

        .command-block .comment {
            color: var(--text-muted);
        }

        .command-block .command {
            color: var(--accent-green);
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Sidebar Navigation -->
        <nav class="sidebar">
            <div class="sidebar-header">
                <h1>Hidden Point Capital</h1>
                <p>Zipline-Reloaded v1.0</p>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Getting Started</div>
                <a href="#overview" class="nav-item">Overview</a>
                <a href="#quick-start" class="nav-item">Quick Start</a>
                <a href="#installation" class="nav-item">Installation Guide</a>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Data Management</div>
                <a href="#data-setup" class="nav-item">Initial Setup</a>
                <a href="#daily-updates" class="nav-item">Daily Updates</a>
                <a href="#bundle-cleanup" class="nav-item">Bundle Cleanup</a>
                <a href="#alternative-bundles" class="nav-item">Alternative Bundles</a>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Fundamental Data</div>
                <a href="#sharadar-fundamentals" class="nav-item">Sharadar Overview</a>
                <a href="#sharadar-columns" class="nav-item nav-subitem">Sharadar Columns</a>
                <a href="#pipeline-usage" class="nav-item">Pipeline Usage</a>
                <a href="#lseg-fundamentals" class="nav-item">LSEG Data</a>
                <a href="#lseg-columns" class="nav-item nav-subitem">LSEG Columns</a>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Multi-Source Data</div>
                <a href="#multi-source-overview" class="nav-item">Overview</a>
                <a href="#custom-databases" class="nav-item">Custom Databases</a>
                <a href="#auto-loader" class="nav-item">AutoLoader</a>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Symbol Mapping</div>
                <a href="#symbol-changes" class="nav-item">Symbol Changes</a>
                <a href="#temporal-mapping" class="nav-item">Temporal Mapping</a>
                <a href="#auto-mapper" class="nav-item">Auto Mapper</a>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Backtesting</div>
                <a href="#backtest-helpers" class="nav-item">Backtest Helpers</a>
                <a href="#backtest-function" class="nav-item nav-subitem">backtest()</a>
                <a href="#analyze-function" class="nav-item nav-subitem">analyze_results()</a>
                <a href="#quick-backtest" class="nav-item nav-subitem">quick_backtest()</a>
                <a href="#pyfolio-integration" class="nav-item">Pyfolio Integration</a>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Monitoring</div>
                <a href="#flightlog" class="nav-item">FlightLog</a>
                <a href="#log-levels" class="nav-item">Log Levels</a>
                <a href="#best-practices" class="nav-item">Best Practices</a>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Development</div>
                <a href="#docker-setup" class="nav-item">Docker Setup</a>
                <a href="#build-optimization" class="nav-item">Build Optimization</a>
                <a href="#troubleshooting" class="nav-item">Troubleshooting</a>
            </div>

            <div class="nav-section">
                <div class="nav-section-title">Reference</div>
                <a href="#command-reference" class="nav-item">Command Reference</a>
                <a href="#resource-requirements" class="nav-item">Resources</a>
            </div>
        </nav>

        <!-- Main Content -->
        <main class="main-content">
            <!-- Overview -->
            <section id="overview" class="section">
                <h1>Hidden Point Capital - Zipline-Reloaded</h1>

                <div class="callout callout-info">
                    <strong>What is Zipline-Reloaded?</strong>
                    <p style="margin-bottom: 0;">A professional-grade algorithmic trading backtesting platform built on the original Quantopian Zipline framework. This enhanced version provides institutional-quality data integration, multi-source fundamental analysis, and real-time monitoring capabilities for developing and testing quantitative trading strategies.</p>
                </div>

                <h3>Purpose & Capabilities</h3>
                <p>Zipline-Reloaded is designed for quantitative researchers, algorithmic traders, and data scientists who need a robust, production-ready backtesting environment. It provides:</p>
                <ul>
                    <li><strong>Institutional-Grade Data</strong>: Integration with Sharadar's point-in-time accurate fundamental data covering 8,000+ US equities since 1998</li>
                    <li><strong>Alternative Data Integration</strong>: Native support for LSEG (Refinitiv), custom databases, and third-party data sources through a unified Pipeline API</li>
                    <li><strong>Factor-Based Screening</strong>: Powerful Pipeline system for creating complex multi-factor screens combining price, fundamental, and alternative data</li>
                    <li><strong>Real-Time Monitoring</strong>: FlightLog streaming system for live backtest progress and debugging</li>
                    <li><strong>Dockerized Environment</strong>: Fully containerized setup ensuring reproducible results across different machines</li>
                </ul>

                <h3>Key Features</h3>
                <div class="feature-grid">
                    <div class="feature-card">
                        <h4>Sharadar Fundamentals</h4>
                        <p>150+ fundamental metrics with point-in-time accuracy. Income statements, balance sheets, cash flows, and valuation ratios - all properly aligned to avoid look-ahead bias.</p>
                    </div>
                    <div class="feature-card">
                        <h4>LSEG & Alternative Data</h4>
                        <p>Integrate LSEG (Refinitiv) smart estimates, alpha models, and custom alternative data sources. Combine multiple data providers in a single trading strategy.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Multi-Source Pipelines</h4>
                        <p>Unified API for combining Sharadar fundamentals with LSEG analytics, custom databases, and proprietary signals. AutoLoader handles routing automatically.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Incremental Updates</h4>
                        <p>Daily data updates in 30 seconds instead of re-downloading everything. Smart incremental ingestion saves time and bandwidth.</p>
                    </div>
                    <div class="feature-card">
                        <h4>FlightLog Monitoring</h4>
                        <p>Real-time log streaming with color-coded levels, progress bars, and portfolio metrics. Monitor long-running backtests in a separate terminal.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Symbol Mapping</h4>
                        <p>Automatic handling of ticker changes (FB→META, GOOG→GOOGL) with temporal SID mapping. Maintains data continuity across corporate actions.</p>
                    </div>
                </div>

                <h3>Who Should Use This?</h3>
                <ul>
                    <li><strong>Institutional Quantitative Traders</strong>: Professional trading desks requiring production-grade backtesting with institutional data</li>
                    <li><strong>Quantitative Researchers</strong>: Testing factor-based investment strategies with point-in-time accurate fundamentals</li>
                    <li><strong>Portfolio Managers</strong>: Backtesting portfolio construction and risk management methodologies</li>
                    <li><strong>Hedge Fund Analysts</strong>: Developing and validating systematic alpha signals across multiple data sources</li>
                </ul>
            </section>

            <!-- Quick Start -->
            <section id="quick-start" class="section">
                <h2>Quick Start <span class="badge badge-time">5 min</span></h2>
                
                <h3>1. Get API Key</h3>
                <ol>
                    <li>Subscribe at: <a href="https://data.nasdaq.com/databases/SFA">data.nasdaq.com/databases/SFA</a></li>
                    <li>Copy your API key from Account Settings</li>
                </ol>

                <h3>2. Configure Key</h3>
                <pre><code># Create .env file
cd /path/to/zipline-reloaded
echo 'NASDAQ_DATA_LINK_API_KEY=your-key-here' > .env</code></pre>

                <h3>3. Initial Download</h3>
                <pre><code># Start container
docker compose up -d

# Download all historical data (takes 10-20 minutes)
docker compose exec zipline-jupyter zipline ingest -b sharadar</code></pre>

                <div class="callout callout-info">
                    <strong>Expected:</strong> Time: 10-20 minutes | Storage: ~10 GB | Date range: 1998 to today | Tickers: ~8,000
                </div>

                <h3>4. Daily Updates</h3>
                <pre><code># Run after market close (6 PM ET or later)
docker compose exec zipline-jupyter zipline ingest -b sharadar</code></pre>
                <p>Takes only <strong>10-30 seconds</strong> (incremental updates)!</p>
            </section>

            <!-- Installation -->
            <section id="installation" class="section">
                <h2>Installation & Setup Guide <span class="badge badge-time">30 min</span></h2>
                <p>Complete step-by-step guide to set up Zipline-Reloaded on a new machine from scratch.</p>

                <h3>System Requirements</h3>
                <table>
                    <tr>
                        <th>Requirement</th>
                        <th>Minimum</th>
                        <th>Recommended</th>
                    </tr>
                    <tr>
                        <td>Operating System</td>
                        <td>macOS 10.15+, Ubuntu 20.04+, Windows 10+</td>
                        <td>macOS 12+ or Ubuntu 22.04</td>
                    </tr>
                    <tr>
                        <td>RAM</td>
                        <td>16 GB</td>
                        <td>64 GB</td>
                    </tr>
                    <tr>
                        <td>Disk Space</td>
                        <td>50 GB free</td>
                        <td>100 GB free</td>
                    </tr>
                    <tr>
                        <td>CPU</td>
                        <td>4 cores</td>
                        <td>8+ cores</td>
                    </tr>
                </table>

                <h3>Step 1: Install Required Software</h3>

                <h4>macOS</h4>
                <pre><code># Install Homebrew (if not already installed)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install Git
brew install git

# Install Docker Desktop
brew install --cask docker

# Launch Docker Desktop
open -a Docker

# Wait for Docker to start (check menu bar for whale icon)
# Then verify installation
docker --version
docker compose version</code></pre>

                <h4>Ubuntu/Debian Linux</h4>
                <pre><code># Update package index
sudo apt update

# Install Git
sudo apt install -y git

# Install Docker
sudo apt install -y docker.io docker-compose-v2

# Add user to docker group (avoid sudo for docker commands)
sudo usermod -aG docker $USER

# Apply group changes (or logout/login)
newgrp docker

# Start Docker service
sudo systemctl start docker
sudo systemctl enable docker

# Verify installation
docker --version
docker compose version</code></pre>

                <h4>Windows</h4>
                <pre><code># Install Git for Windows
# Download from: https://git-scm.com/download/win
# Run installer with default options

# Install Docker Desktop for Windows
# Download from: https://www.docker.com/products/docker-desktop
# Run installer, enable WSL 2 when prompted

# Restart computer after installation

# Open PowerShell and verify
docker --version
docker compose version</code></pre>

                <h3>Step 2: Enable Docker BuildKit</h3>
                <p>BuildKit provides faster builds with better caching. Add to your shell configuration:</p>

                <h4>macOS/Linux (bash/zsh)</h4>
                <pre><code># Add to ~/.zshrc (macOS) or ~/.bashrc (Linux)
echo 'export DOCKER_BUILDKIT=1' >> ~/.zshrc
echo 'export COMPOSE_DOCKER_CLI_BUILD=1' >> ~/.zshrc

# Reload shell config
source ~/.zshrc</code></pre>

                <h4>Windows (PowerShell)</h4>
                <pre><code># Set environment variables
[Environment]::SetEnvironmentVariable("DOCKER_BUILDKIT", "1", "User")
[Environment]::SetEnvironmentVariable("COMPOSE_DOCKER_CLI_BUILD", "1", "User")

# Restart PowerShell to apply changes</code></pre>

                <h3>Step 3: Clone the Repository</h3>
                <pre><code># Clone the repository
git clone https://github.com/ksokhanvari/zipline-reloaded.git

# Navigate to project directory
cd zipline-reloaded

# Verify you're in the right directory
ls -la</code></pre>

                <h3>Step 4: Configure API Keys</h3>
                <p>You need a NASDAQ Data Link API key to download Sharadar data.</p>

                <h4>Get Your API Key</h4>
                <ol>
                    <li>Go to <a href="https://data.nasdaq.com/sign-up">data.nasdaq.com/sign-up</a> and create an account</li>
                    <li>Subscribe to Sharadar Core US Fundamentals: <a href="https://data.nasdaq.com/databases/SFA">data.nasdaq.com/databases/SFA</a></li>
                    <li>Go to Account Settings → API Key and copy your key</li>
                </ol>

                <h4>Create Environment File</h4>
                <pre><code># Create .env file with your API key
echo 'NASDAQ_DATA_LINK_API_KEY=your-api-key-here' > .env

# Verify the file was created
cat .env</code></pre>

                <div class="callout callout-warning">
                    <strong>Important:</strong> Never commit your .env file to git. It's already in .gitignore.
                </div>

                <h3>Step 5: Build Docker Image</h3>
                <pre><code># Build the Docker image (takes 15-20 minutes first time)
docker compose build

# Watch for any errors during build
# If successful, you'll see "Successfully built" message</code></pre>

                <div class="callout callout-info">
                    <strong>Build Times:</strong>
                    <ul style="margin-bottom: 0;">
                        <li>First build: 15-20 minutes (downloads all dependencies)</li>
                        <li>Subsequent builds: 2-5 minutes (uses cache)</li>
                    </ul>
                </div>

                <h3>Step 6: Start the Containers</h3>
                <pre><code># Start all services in background
docker compose up -d

# Verify containers are running
docker compose ps

# You should see:
# - zipline-reloaded-jupyter (Jupyter notebook server)
# - Other services as configured</code></pre>

                <h3>Step 7: Download Market Data</h3>
                <pre><code># Initial data download (takes 10-20 minutes)
docker compose exec zipline-jupyter zipline ingest -b sharadar

# This downloads:
# - Price data for 8,000+ US equities
# - 150+ fundamental metrics from 1998 to today
# - Corporate actions and splits data</code></pre>

                <h3>Step 8: Verify Installation</h3>
                <pre><code># Check that data bundle was created
docker compose exec zipline-jupyter zipline bundles

# You should see output like:
# sharadar 2024-XX-XX XX:XX:XX.XXXXXX</code></pre>

                <h3>Step 9: Access Jupyter Notebook</h3>
                <pre><code># Get Jupyter URL with token
docker compose logs zipline-jupyter | grep "http://127.0.0.1:8888"

# Open the URL in your browser
# Default: http://localhost:8888</code></pre>

                <h3>Step 10: Run Your First Backtest</h3>
                <p>Open a new notebook in Jupyter and run:</p>
                <pre><code>import pandas as pd
from zipline import run_algorithm
from zipline.api import order_target_percent, symbol

def initialize(context):
    context.stock = symbol('AAPL')

def handle_data(context, data):
    if data.can_trade(context.stock):
        order_target_percent(context.stock, 1.0)

results = run_algorithm(
    start=pd.Timestamp('2020-01-01', tz='UTC'),
    end=pd.Timestamp('2021-01-01', tz='UTC'),
    initialize=initialize,
    handle_data=handle_data,
    capital_base=10000,
    bundle='sharadar',
)

print(f"Total Return: {results['algorithm_period_return'].iloc[-1]*100:.2f}%")</code></pre>

                <h3>Common Docker Commands</h3>
                <table>
                    <tr>
                        <th>Command</th>
                        <th>Description</th>
                    </tr>
                    <tr>
                        <td><code>docker compose up -d</code></td>
                        <td>Start all services in background</td>
                    </tr>
                    <tr>
                        <td><code>docker compose down</code></td>
                        <td>Stop all services</td>
                    </tr>
                    <tr>
                        <td><code>docker compose ps</code></td>
                        <td>List running containers</td>
                    </tr>
                    <tr>
                        <td><code>docker compose logs -f</code></td>
                        <td>View logs (follow mode)</td>
                    </tr>
                    <tr>
                        <td><code>docker compose restart</code></td>
                        <td>Restart all services</td>
                    </tr>
                    <tr>
                        <td><code>docker compose build --no-cache</code></td>
                        <td>Rebuild without cache</td>
                    </tr>
                    <tr>
                        <td><code>docker compose exec zipline-jupyter bash</code></td>
                        <td>Enter container shell</td>
                    </tr>
                </table>

                <h3>Troubleshooting Installation</h3>

                <h4>Docker Not Starting (macOS)</h4>
                <pre><code># Reset Docker to factory defaults
# Docker Desktop → Troubleshoot → Reset to factory defaults

# Or restart Docker service
killall Docker && open -a Docker</code></pre>

                <h4>Permission Denied (Linux)</h4>
                <pre><code># Add user to docker group
sudo usermod -aG docker $USER

# Log out and back in, or run:
newgrp docker</code></pre>

                <h4>Build Fails with Memory Error</h4>
                <pre><code># Increase Docker memory allocation
# Docker Desktop → Settings → Resources → Memory → Set to 8GB+

# Or try building with less parallelism
DOCKER_BUILDKIT=0 docker compose build</code></pre>

                <h4>Port Already in Use</h4>
                <pre><code># Find process using port 8888
lsof -i :8888

# Kill the process
kill -9 &lt;PID&gt;

# Or change port in docker-compose.yml</code></pre>
            </section>

            <!-- Data Setup -->
            <section id="data-setup" class="section">
                <h2>Sharadar Data Specifications</h2>

                <h3>Data Coverage</h3>
                <table>
                    <tr>
                        <th>Specification</th>
                        <th>Details</th>
                    </tr>
                    <tr>
                        <td>Universe</td>
                        <td>8,000+ US equities (NYSE, NASDAQ, AMEX)</td>
                    </tr>
                    <tr>
                        <td>Historical Depth</td>
                        <td>1998 to present</td>
                    </tr>
                    <tr>
                        <td>Price Data</td>
                        <td>Daily OHLCV, adjusted for splits and dividends</td>
                    </tr>
                    <tr>
                        <td>Fundamental Metrics</td>
                        <td>150+ metrics (income, balance sheet, cash flow, ratios)</td>
                    </tr>
                    <tr>
                        <td>Point-in-Time</td>
                        <td>Yes - uses filing dates to prevent look-ahead bias</td>
                    </tr>
                    <tr>
                        <td>Corporate Actions</td>
                        <td>Splits, dividends, mergers, spin-offs</td>
                    </tr>
                    <tr>
                        <td>Update Frequency</td>
                        <td>Daily (after market close)</td>
                    </tr>
                    <tr>
                        <td>Storage Size</td>
                        <td>~10 GB per ingestion</td>
                    </tr>
                </table>

                <div class="callout callout-info">
                    <strong>Complete Column Reference:</strong> For a full list of all 66+ available Sharadar fundamental columns with descriptions, see the <a href="#sharadar-columns">Sharadar SF1 Columns</a> section in the Data Reference.
                </div>

                <h3>Verify Data</h3>
                <pre><code># Check ingestion status
docker compose exec zipline-jupyter zipline bundles

# Check in Python
from zipline.data import bundles
bundle = bundles.load('sharadar')
sessions = bundle.equity_daily_bar_reader.sessions
print(f"First: {sessions[0].date()}, Last: {sessions[-1].date()}")</code></pre>
            </section>

            <!-- Daily Updates -->
            <section id="daily-updates" class="section">
                <h2>Daily Updates</h2>

                <h3>When to Run</h3>
                <table>
                    <tr>
                        <th>Time (ET)</th>
                        <th>Status</th>
                        <th>Action</th>
                    </tr>
                    <tr>
                        <td>Before 5:00 PM</td>
                        <td>Data not ready</td>
                        <td>Don't run yet</td>
                    </tr>
                    <tr>
                        <td>5:00-6:00 PM</td>
                        <td>Processing</td>
                        <td>May be incomplete</td>
                    </tr>
                    <tr>
                        <td>After 6:00 PM</td>
                        <td>Ready</td>
                        <td>Safe to run</td>
                    </tr>
                </table>

                <h3>Automation with Cron</h3>
                <pre><code># Edit crontab
crontab -e

# Add line (runs Mon-Fri at 6 PM ET)
0 18 * * 1-5 cd /path/to/zipline-reloaded && \
    docker compose exec -T zipline-jupyter zipline ingest -b sharadar \
    >> /var/log/sharadar-update.log 2>&1</code></pre>
            </section>

            <!-- Bundle Cleanup -->
            <section id="bundle-cleanup" class="section">
                <h2>Bundle Cleanup</h2>

                <p>Each ingestion creates a new timestamped directory. Cleanup saves disk space.</p>

                <pre><code># Keep only the 2 most recent ingestions
docker exec zipline-reloaded-jupyter zipline clean -b sharadar --keep-last 2

# Keep only the most recent
docker exec zipline-reloaded-jupyter zipline clean -b sharadar --keep-last 1</code></pre>

                <h3>Recommended Keep Count</h3>
                <table>
                    <tr>
                        <th>Scenario</th>
                        <th>Keep Last</th>
                        <th>Disk Usage</th>
                    </tr>
                    <tr>
                        <td>Development</td>
                        <td>1-2</td>
                        <td>~1.2 GB</td>
                    </tr>
                    <tr>
                        <td>Production</td>
                        <td>2-3</td>
                        <td>~1.8 GB</td>
                    </tr>
                    <tr>
                        <td>Critical</td>
                        <td>5-7</td>
                        <td>~4.2 GB</td>
                    </tr>
                </table>
            </section>

            <!-- Alternative Bundles -->
            <section id="alternative-bundles" class="section">
                <h2>Alternative Bundles</h2>

                <h3>Tech Stocks Only (Fast Testing)</h3>
                <pre><code># Takes 30 seconds instead of 20 minutes
docker exec zipline-reloaded-jupyter zipline ingest -b sharadar-tech

# Includes: AAPL, MSFT, GOOGL, AMZN, META, NVDA, TSLA, NFLX, etc.</code></pre>

                <h3>Custom Ticker List</h3>
                <pre><code># Edit ~/.zipline/extension.py
from zipline.data.bundles import register
from zipline.data.bundles.sharadar_bundle import sharadar_bundle

register('my-stocks', sharadar_bundle(
    tickers=['SPY', 'QQQ', 'AAPL', 'MSFT', 'TSLA'],
    incremental=True,
))</code></pre>
            </section>

            <!-- Sharadar Fundamentals -->
            <section id="sharadar-fundamentals" class="section">
                <h2>Sharadar Fundamentals</h2>

                <p>Access 150+ quarterly fundamental metrics from Sharadar's SF1 table through Zipline's Pipeline API.</p>

                <h3>Key Features</h3>
                <ul>
                    <li><strong>Point-in-Time Correct</strong>: Uses filing dates to prevent look-ahead bias</li>
                    <li><strong>150+ Metrics</strong>: Revenue, earnings, ratios, cash flow, and more</li>
                    <li><strong>Automatic Forward-Filling</strong>: Quarterly data persists until next quarter</li>
                    <li><strong>Pipeline Integration</strong>: Works with Zipline's factor library</li>
                </ul>

                <div class="callout callout-info">
                    <strong>Complete Column Reference:</strong> See <a href="#sharadar-columns">Sharadar SF1 Columns</a> for the full list of 66+ available metrics with descriptions.
                </div>

                <h3>Basic Usage</h3>
                <pre><code>from zipline.pipeline import Pipeline
from zipline.pipeline.data.sharadar import SharadarFundamentals

pipeline = Pipeline(
    columns={
        'revenue': SharadarFundamentals.revenue.latest,
        'net_income': SharadarFundamentals.netinc.latest,
        'roe': SharadarFundamentals.roe.latest,
        'pe_ratio': SharadarFundamentals.pe.latest,
    }
)</code></pre>
            </section>

            <!-- Pipeline Usage -->
            <section id="pipeline-usage" class="section">
                <h2>Pipeline Usage</h2>

                <h3>Screening</h3>
                <pre><code>from zipline.pipeline.data.sharadar import SharadarFundamentals

# Value screen
value_screen = (
    (SharadarFundamentals.pe.latest < 15) &
    (SharadarFundamentals.pb.latest < 2) &
    (SharadarFundamentals.dps.latest > 1.0)
)

# Quality screen
quality_screen = (
    (SharadarFundamentals.roe.latest > 15) &
    (SharadarFundamentals.de.latest < 1.0) &
    (SharadarFundamentals.currentratio.latest > 1.5)
)

pipeline = Pipeline(
    columns={
        'pe': SharadarFundamentals.pe.latest,
        'roe': SharadarFundamentals.roe.latest,
    },
    screen=value_screen | quality_screen,
)</code></pre>
            </section>

            <!-- LSEG Fundamentals Overview -->
            <section id="lseg-fundamentals" class="section">
                <h2>LSEG Data</h2>

                <p>Integrate LSEG (formerly Refinitiv) fundamental data, smart estimates, and alpha model scores through the custom database system.</p>

                <h3>About LSEG Data</h3>
                <p>LSEG (London Stock Exchange Group) provides comprehensive institutional data through its Entity Data and Ownership services, which offer detailed information on millions of global legal entities, corporate structures, and institutional holdings.</p>

                <h4>LSEG Entity Data</h4>
                <p>LSEG Entity Data offers a detailed view of complex global corporate structures. It covers millions of entities across 250 markets, including public and relevant private companies, public sector organizations, and various fund types. The data includes legal entity identifiers, official names, risk fields, and complete corporate hierarchies, all sourced from auditable sources like exchanges and company reports.</p>

                <h4>LSEG Ownership and Profiles</h4>
                <p>This service provides information on ownership in public equities and intelligence on investment managers. It includes data on holdings by investment firms, strategic holdings, and corporate insiders. Profiles offer biographies and employment history for key market decision-makers. The data is gathered globally from sources like U.S. SEC filings and international notifications.</p>

                <h4>Delivery Platforms</h4>
                <p>This institutional data can be accessed through platforms such as LSEG DataScope Select, which provides various delivery options including APIs and SFTP for integration into workflows.</p>

                <p><strong>Learn more:</strong> <a href="https://www.lseg.com/en/data-analytics" target="_blank">LSEG Data & Analytics</a></p>

                <h3>Key Features</h3>
                <ul>
                    <li><strong>Smart Estimates</strong>: Consensus analyst estimates for ROE, ROA, EPS, and growth</li>
                    <li><strong>Alpha Model Scores</strong>: Combined factor scores and sector rankings</li>
                    <li><strong>Forward-Looking Metrics</strong>: Forward PE, PEG ratios, target prices</li>
                    <li><strong>Custom Database Integration</strong>: Seamlessly combine with Sharadar data in pipelines</li>
                </ul>

                <div class="callout callout-info">
                    <strong>Complete Column Reference:</strong> See <a href="#lseg-columns">LSEG Custom Columns</a> for the full list of 50+ available metrics with descriptions.
                </div>

                <h3>Basic Usage</h3>
                <pre><code>from zipline.pipeline import multi_source as ms

class LSEGFundamentals(ms.Database):
    CODE = "lseg_fundamentals"
    LOOKBACK_WINDOW = 252

    ReturnOnEquity_SmartEstimate = ms.Column(float)
    CombinedAlphaModelSectorRank = ms.Column(float)
    ForwardPEG = ms.Column(float)

# Use in pipeline
pipeline = ms.Pipeline(
    columns={
        'roe_estimate': LSEGFundamentals.ReturnOnEquity_SmartEstimate.latest,
        'sector_rank': LSEGFundamentals.CombinedAlphaModelSectorRank.latest,
    }
)</code></pre>
            </section>

            <!-- Multi-Source Overview -->
            <section id="multi-source-overview" class="section">
                <h2>Multi-Source Data <span class="badge badge-time">15 min</span></h2>

                <p>A simple, clean architecture for combining multiple fundamental data sources (Sharadar, LSEG, custom databases) in Zipline backtests.</p>

                <h3>One-Line Import</h3>
                <pre><code>from zipline.pipeline import multi_source as ms

# Available components:
# ms.Pipeline - Pipeline class
# ms.Database - Custom database base class
# ms.Column - Column definition
# ms.sharadar - Sharadar datasets
# ms.setup_auto_loader() - Automatic loader setup</code></pre>

                <h3>Three-Step Pattern</h3>
                <pre><code># 1. Define Custom Database
class CustomFundamentals(ms.Database):
    CODE = "fundamentals"  # Must match SQLite filename
    LOOKBACK_WINDOW = 252
    ROE = ms.Column(float)
    PEG = ms.Column(float)

# 2. Create Pipeline mixing sources
def make_pipeline():
    s_fcf = ms.SharadarFundamentals.fcf.latest
    c_roe = CustomFundamentals.ROE.latest
    
    return ms.Pipeline(
        columns={'s_fcf': s_fcf, 'c_roe': c_roe},
        screen=(s_fcf > 0) & (c_roe > 15),
    )

# 3. Run Backtest
results = run_algorithm(
    ...,
    custom_loader=ms.setup_auto_loader(),  # Magic!
)</code></pre>
            </section>

            <!-- Custom Databases -->
            <section id="custom-databases" class="section">
                <h2>Custom Databases</h2>

                <h3>Database Schema</h3>
                <pre><code>CREATE TABLE Price (
    Date TEXT NOT NULL,      -- YYYY-MM-DD format
    Sid INTEGER NOT NULL,    -- Use bundle SIDs
    ROE REAL,
    PEG REAL,
    PRIMARY KEY (Date, Sid)
);

CREATE INDEX idx_date ON Price(Date);
CREATE INDEX idx_sid ON Price(Sid);</code></pre>

                <h3>Database Location</h3>
                <pre><code>~/.zipline/data/custom/{CODE}.sqlite

# Example: CODE = "fundamentals"
# Location: ~/.zipline/data/custom/fundamentals.sqlite</code></pre>

                <h3>Column Types</h3>
                <pre><code>Revenue = ms.Column(float)   # Numeric data
Count = ms.Column(int)       # Integer data
Sector = ms.Column(object)   # Text data</code></pre>
            </section>

            <!-- AutoLoader -->
            <section id="auto-loader" class="section">
                <h2>AutoLoader</h2>

                <p>The AutoLoader automatically detects and routes columns to the appropriate data source.</p>

                <h3>Configuration Options</h3>
                <pre><code># Custom database directory
loader = ms.setup_auto_loader(
    custom_db_dir='/path/to/databases',
)

# Different bundle
loader = ms.setup_auto_loader(
    bundle_name='my_bundle',
)

# Disable SID translation
loader = ms.setup_auto_loader(
    enable_sid_translation=False,
)</code></pre>
            </section>

            <!-- Symbol Changes -->
            <section id="symbol-changes" class="section">
                <h2>Symbol Changes <span class="badge badge-time">10 min</span></h2>

                <p>When companies change ticker symbols (like FB → META), naive mapping creates discontinuous data.</p>

                <h3>The Problem</h3>
                <pre><code># Wrong approach:
FB rows (2012-2021)   → SID 644713
META rows (2022-2025) → SID 194817

# Result: Two separate securities, broken continuity</code></pre>

                <h3>The Solution</h3>
                <p>Use temporal lookups to get the correct SID for each row's date:</p>
                <pre><code>asset = asset_finder.lookup_symbol('FB', as_of_date='2020-01-01')
# Returns: SID 194817 (Meta/Facebook)

asset = asset_finder.lookup_symbol('META', as_of_date='2023-01-01')
# Returns: SID 194817 (same company!)</code></pre>
            </section>

            <!-- Temporal Mapping -->
            <section id="temporal-mapping" class="section">
                <h2>Temporal SID Mapping</h2>

                <pre><code>from temporal_sid_mapper import TemporalSIDMapper

# Initialize with asset finder
mapper = TemporalSIDMapper(asset_finder)

# Map dataframe automatically
custom_data['Sid'] = mapper.map_dataframe_auto(
    custom_data,
    symbol_col='Symbol',
    date_col='Date',
    verbose=True
)</code></pre>

                <h3>What It Handles</h3>
                <ul>
                    <li><strong>FB → META</strong> (Facebook rebranded)</li>
                    <li><strong>GOOG → GOOGL</strong> (Google ticker changes)</li>
                    <li>Mergers and acquisitions</li>
                    <li>Spin-offs</li>
                    <li>Any temporal symbol change in Zipline's database</li>
                </ul>
            </section>

            <!-- Auto Mapper -->
            <section id="auto-mapper" class="section">
                <h2>Auto Symbol Mapper</h2>

                <p>For symbols not in the bundle, use intelligent fuzzy matching based on company names.</p>

                <pre><code>from symbol_mapper_auto import AutoSymbolMapper

auto_mapper = AutoSymbolMapper(asset_finder)

custom_data = auto_mapper.auto_learn_and_map(
    custom_data,
    symbol_col='Symbol',
    name_col='CompanyCommonName',
    auto_threshold=0.85,
    verbose=True
)</code></pre>

                <h3>Confidence Scoring</h3>
                <ul>
                    <li><strong>≥0.85</strong>: Auto-apply (high confidence)</li>
                    <li><strong>0.70-0.85</strong>: Manual review</li>
                    <li><strong>&lt;0.70</strong>: Skip (no good match)</li>
                </ul>

                <h3>Mapping File Location</h3>
                <code>/root/.zipline/data/custom/symbol_mappings.json</code>
            </section>

            <!-- Backtest Helpers -->
            <section id="backtest-helpers" class="section">
                <h2>Backtest Helpers <span class="badge badge-time">15 min</span></h2>

                <p>Easy-to-use helper functions for running Zipline backtests and analyzing results with pyfolio. These utilities streamline the backtest workflow by handling file management, result saving, and performance analysis automatically.</p>

                <h3>Key Features</h3>
                <ul>
                    <li><strong>Automatic File Management</strong>: Results saved to CSV, pickle, and metadata JSON</li>
                    <li><strong>Pyfolio Integration</strong>: Full tearsheet generation with performance metrics</li>
                    <li><strong>Custom Database Detection</strong>: Automatically configures loaders for Database classes</li>
                    <li><strong>Reproducible Results</strong>: Metadata tracking for every backtest run</li>
                </ul>

                <h3>Quick Start</h3>
                <pre><code>from backtest_helpers import backtest, analyze_results

# Run backtest and save results
backtest(
    "my_strategy.py",              # Algorithm file
    "my-strategy-v1",               # Name/identifier
    bundle="sharadar",
    start_date="2021-01-01",
    end_date="2025-01-01",
    capital_base=5000000,
    filepath_or_buffer="results.csv"  # Output filename
)

# Analyze results with pyfolio tearsheet
analyze_results("./backtest_results/results.csv", benchmark_symbol="SPY")</code></pre>

                <div class="callout callout-info">
                    <strong>Important:</strong> Jupyter notebooks don't automatically load bundle extensions. Register the sharadar bundle manually before running backtests:
                    <pre style="margin-bottom: 0;"><code>from zipline.data.bundles import register
from zipline.data.bundles.sharadar_bundle import sharadar_bundle

register('sharadar', sharadar_bundle(tickers=None, incremental=True, include_funds=True))</code></pre>
                </div>
            </section>

            <!-- backtest() Function -->
            <section id="backtest-function" class="section">
                <h2>backtest() Function</h2>

                <p>Run a Zipline backtest and save results to disk with automatic metadata tracking.</p>

                <h3>Function Signature</h3>
                <pre><code>backtest(
    algo_filename,           # Path to algorithm .py file
    name,                    # Backtest identifier/name
    bundle="sharadar",       # Data bundle name
    data_frequency='daily',  # 'daily' or 'minute'
    segment=None,            # Optional segment identifier
    progress='D',            # Progress bar: 'D', 'W', 'M', or None
    start_date="2020-01-01", # Start date (YYYY-MM-DD)
    end_date="2023-12-31",   # End date (YYYY-MM-DD)
    capital_base=100000,     # Starting capital
    filepath_or_buffer=None, # Output filename (defaults to {name}.csv)
    output_dir="./backtest_results",  # Output directory
    save_pickle=True,        # Also save as pickle
    **kwargs                 # Additional args for run_algorithm()
) -> pd.DataFrame</code></pre>

                <h3>What It Does</h3>
                <ol>
                    <li>Loads your algorithm from file</li>
                    <li>Detects and configures custom database loaders automatically</li>
                    <li>Runs the backtest with progress tracking</li>
                    <li>Saves results to CSV and pickle</li>
                    <li>Saves metadata JSON with configuration</li>
                    <li>Prints summary statistics</li>
                    <li>Returns performance DataFrame</li>
                </ol>

                <h3>Output Files</h3>
                <pre><code>backtest_results/
├── my-strategy-v1.csv      # CSV format (easy to read)
├── my-strategy-v1.pkl      # Pickle format (preserves all data types)
└── my-strategy-v1.json     # Metadata (config, timestamps, etc.)</code></pre>

                <h3>Example Usage</h3>
                <pre><code>perf = backtest(
    "backtest_with_fundamentals.py",
    "quality-strat-2023",
    bundle="sharadar",
    start_date="2023-01-01",
    end_date="2023-12-31",
    capital_base=1000000,
    filepath_or_buffer="quality-2023.csv"
)

# perf is a DataFrame with columns:
#  - portfolio_value
#  - returns
#  - positions
#  - transactions
#  - orders
#  - sharpe, max_drawdown, etc.</code></pre>

                <h3>Algorithm File Requirements</h3>
                <p>Your algorithm file must define an <code>initialize</code> function. Other functions are optional:</p>
                <pre><code>def initialize(context):
    """Called once at start of backtest"""
    context.my_var = 10
    # ... setup code ...

def handle_data(context, data):
    """Called every bar (optional)"""
    # ... trading logic ...

def before_trading_start(context, data):
    """Called before market open (optional)"""
    # ... pre-market logic ...

def analyze(context, perf):
    """Called after backtest completes (optional)"""
    # ... analysis code ...</code></pre>
            </section>

            <!-- analyze_results() Function -->
            <section id="analyze-function" class="section">
                <h2>analyze_results() Function</h2>

                <p>Load saved backtest results and generate comprehensive pyfolio analysis with performance metrics and visualizations.</p>

                <h3>Function Signature</h3>
                <pre><code>analyze_results(
    filepath_or_buffer,          # Path to CSV or pickle file
    benchmark_symbol='SPY',      # Benchmark ticker
    output_file=None,            # Save plots to file
    live_start_date=None,        # Separate in-sample vs out-of-sample
    show_plots=True,             # Display plots
    save_plots=True,             # Save plots to disk
    figsize=(14, 10),            # Figure size
    return_dict=False,           # Return detailed results dict
) -> dict (optional)</code></pre>

                <h3>What It Does</h3>
                <ol>
                    <li>Loads results from CSV or pickle</li>
                    <li>Extracts returns and metrics</li>
                    <li>Generates pyfolio tearsheet (if installed)</li>
                    <li>Creates performance plots:
                        <ul>
                            <li>Portfolio value over time</li>
                            <li>Cumulative returns</li>
                            <li>Drawdown chart</li>
                            <li>Monthly returns heatmap</li>
                        </ul>
                    </li>
                    <li>Calculates comprehensive metrics</li>
                </ol>

                <h3>Example Usage</h3>
                <pre><code># Basic analysis
analyze_results("./backtest_results/quality-2023.csv")

# Get detailed results for custom analysis
results = analyze_results(
    "./backtest_results/quality-2023.csv",
    benchmark_symbol="SPY",
    live_start_date="2024-01-01",  # Out-of-sample starts here
    return_dict=True
)

# Access components
returns = results['returns']
metrics = results['metrics']
perf = results['perf']

# Print metrics
for metric, value in metrics.items():
    print(f"{metric}: {value}")</code></pre>

                <h3>Metrics Calculated</h3>
                <table>
                    <tr><th>Metric</th><th>Description</th></tr>
                    <tr><td>Total Return</td><td>Cumulative return over period</td></tr>
                    <tr><td>Annual Return</td><td>Annualized return (CAGR)</td></tr>
                    <tr><td>Annual Volatility</td><td>Annualized standard deviation</td></tr>
                    <tr><td>Sharpe Ratio</td><td>Risk-adjusted return (assumes 0% risk-free rate)</td></tr>
                    <tr><td>Max Drawdown</td><td>Largest peak-to-trough decline</td></tr>
                    <tr><td>Calmar Ratio</td><td>Annual return / max drawdown</td></tr>
                    <tr><td>Win Rate</td><td>Percentage of positive return days</td></tr>
                    <tr><td>Final Portfolio Value</td><td>Ending capital</td></tr>
                </table>
            </section>

            <!-- quick_backtest() Function -->
            <section id="quick-backtest" class="section">
                <h2>quick_backtest() Function</h2>

                <p>Convenience function to run a backtest and immediately analyze results in one step.</p>

                <h3>Function Signature</h3>
                <pre><code>quick_backtest(
    algo_filename,
    name=None,                   # Defaults to algo filename
    start_date="2021-01-01",
    end_date="2023-12-31",
    capital_base=100000,
    analyze=True,                # Run analysis after backtest
    **kwargs
) -> pd.DataFrame</code></pre>

                <h3>Example Usage</h3>
                <pre><code># Run and analyze in one step
perf = quick_backtest(
    "my_strategy.py",
    start_date="2023-01-01",
    end_date="2023-12-31",
    capital_base=100000,
    bundle="sharadar"
)</code></pre>
            </section>

            <!-- Pyfolio Integration -->
            <section id="pyfolio-integration" class="section">
                <h2>Pyfolio Integration</h2>

                <p>If <code>pyfolio-reloaded</code> is installed, you get full tearsheet analysis with comprehensive metrics.</p>

                <h3>Install Pyfolio</h3>
                <pre><code>pip install pyfolio-reloaded</code></pre>

                <h3>Tearsheet Features</h3>
                <ul>
                    <li><strong>Returns analysis</strong>: Daily, monthly, yearly returns</li>
                    <li><strong>Risk metrics</strong>: Sharpe, Sortino, Calmar ratios</li>
                    <li><strong>Drawdown analysis</strong>: Underwater plot, top drawdowns</li>
                    <li><strong>Rolling metrics</strong>: Rolling Sharpe, volatility</li>
                    <li><strong>Monthly returns heatmap</strong></li>
                    <li><strong>Distribution analysis</strong>: Return distribution, Q-Q plot</li>
                    <li><strong>Worst periods</strong>: Worst 5 drawdowns with details</li>
                </ul>

                <div class="callout callout-success">
                    <strong>Note:</strong> Even without pyfolio, basic plots and metrics are still generated. The helper functions fall back gracefully to built-in visualizations.
                </div>

                <h3>Multiple Scenarios Comparison</h3>
                <pre><code># Define different test scenarios
scenarios = [
    {'name': 'bear-market', 'start': '2022-01-01', 'end': '2022-12-31'},
    {'name': 'bull-market', 'start': '2023-01-01', 'end': '2023-12-31'},
]

results = {}
for scenario in scenarios:
    perf = backtest(
        "my_strategy.py",
        scenario['name'],
        start_date=scenario['start'],
        end_date=scenario['end'],
        capital_base=100000,
        filepath_or_buffer=f"{scenario['name']}.csv"
    )
    results[scenario['name']] = perf

# Compare results
for name, perf in results.items():
    total_return = (perf['portfolio_value'].iloc[-1] / 100000 - 1) * 100
    print(f"{name}: {total_return:.2f}%")</code></pre>

                <h3>Custom Analysis</h3>
                <pre><code># Load results for custom analysis
results = analyze_results(
    "./backtest_results/my-strategy.csv",
    show_plots=False,
    return_dict=True
)

# Access data
returns = results['returns']
perf = results['perf']
metrics = results['metrics']

# Custom plot: Rolling Sharpe ratio
import matplotlib.pyplot as plt
import numpy as np

rolling_sharpe = (
    returns.rolling(window=60)
    .apply(lambda x: x.mean() / x.std() * np.sqrt(252) if x.std() > 0 else 0)
)

fig, ax = plt.subplots(figsize=(14, 6))
ax.plot(rolling_sharpe.index, rolling_sharpe, linewidth=2)
ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)
ax.axhline(y=1, color='green', linestyle='--', alpha=0.3, label='Sharpe = 1')
ax.set_title('60-Day Rolling Sharpe Ratio', fontweight='bold')
ax.set_ylabel('Sharpe Ratio')
ax.legend()
ax.grid(True, alpha=0.3)
plt.show()</code></pre>

                <h3>Best Practices</h3>
                <div class="feature-grid">
                    <div class="feature-card">
                        <h4>Always Save Results</h4>
                        <p>Running backtests is time-consuming. Always save results so you can re-analyze later without re-running.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Use Descriptive Names</h4>
                        <p>Use clear names like "momentum-top20-monthly" instead of "test1" for easy identification.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Save Pickle for Complex Data</h4>
                        <p>CSV files lose some data types. Pickle preserves everything including positions and transactions.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Separate In/Out-of-Sample</h4>
                        <p>Use <code>live_start_date</code> to separate training and testing periods for more realistic performance evaluation.</p>
                    </div>
                </div>
            </section>

            <!-- FlightLog -->
            <section id="flightlog" class="section">
                <h2>FlightLog <span class="badge badge-time">10 min</span></h2>

                <p>Real-time log streaming system that displays backtest logs in a separate terminal, with channel separation for clean output.</p>

                <h3>Channel Separation</h3>
                <table>
                    <tr>
                        <th>Channel</th>
                        <th>Port</th>
                        <th>Purpose</th>
                    </tr>
                    <tr>
                        <td>LOG</td>
                        <td>9020</td>
                        <td>Progress bars, log_to_flightlog() calls, algorithm logs</td>
                    </tr>
                    <tr>
                        <td>PRINT</td>
                        <td>9021</td>
                        <td>All print statements (redirected from notebook)</td>
                    </tr>
                </table>

                <h3>Start FlightLog - IPython Magic (Recommended)</h3>
                <pre><code># In Jupyter notebook cell
%load_ext flightlog_commands
%flightlog both

# Available commands:
# %flightlog log      - Start LOG server on port 9020
# %flightlog print    - Start PRINT server on port 9021
# %flightlog both     - Start both servers
# %flightlog status   - Check server status
# %flightlog stop     - Stop all servers</code></pre>

                <h3>Start FlightLog - Docker Compose</h3>
                <pre><code># Option 1: Simple (LOG channel only)
docker compose run --rm flightlog

# Option 2: Two-channel setup (recommended for debugging)
# Terminal 1: LOG channel (important logs)
docker compose run --rm flightlog python /app/scripts/flightlog.py --port 9020

# Terminal 2: PRINT channel (all print output)
docker compose run --rm flightlog python /app/scripts/flightlog.py --port 9021</code></pre>

                <h3>Start FlightLog - Docker Exec (If Container Running)</h3>
                <pre><code># LOG channel (port 9020)
docker exec -it zipline-reloaded-jupyter python /app/scripts/flightlog.py --port 9020

# PRINT channel (port 9021)
docker exec -it zipline-reloaded-jupyter python /app/scripts/flightlog.py --port 9021</code></pre>

                <h3>FlightLog Options</h3>
                <pre><code># Hide progress bars (algorithm logs only)
docker compose run --rm flightlog python /app/scripts/flightlog.py --filter-progress

# Save to file
docker compose run --rm flightlog python /app/scripts/flightlog.py --file /logs/backtest.log

# Different log level
docker compose run --rm flightlog python /app/scripts/flightlog.py --level DEBUG

# Fix port already in use
lsof -i :9020
kill -9 &lt;PID&gt;</code></pre>

                <h3>Using backtest_helpers (Automatic Integration)</h3>
                <pre><code>from examples.utils.backtest_helpers import backtest

# FlightLog is automatically configured
results = backtest(
    algo_filename='/app/examples/strategies/LS-ZR-ported.py',
    start='2023-01-01',
    end='2024-01-01',
    capital_base=1000000,
    bundle='sharadar'
)

# Benefits:
# - Connects to both LOG (9020) and PRINT (9021) channels
# - Suppresses print output in notebook when FlightLog connected
# - Shows daily progress updates with strategy name</code></pre>

                <h3>Manual Setup (Alternative)</h3>
                <pre><code>import logging
from zipline.utils.flightlog_client import enable_flightlog, log_to_flightlog
from zipline.utils.progress import enable_progress_logging

logging.basicConfig(level=logging.INFO, force=True)
enable_flightlog(host='localhost', port=9020)
enable_progress_logging(algo_name='My-Strategy', update_interval=5)

# Log events
log_to_flightlog('Strategy initialized', level='INFO')
log_to_flightlog('Portfolio rebalanced', level='INFO')</code></pre>
            </section>

            <!-- Log Levels -->
            <section id="log-levels" class="section">
                <h2>Log Levels</h2>

                <table>
                    <tr>
                        <th>Level</th>
                        <th>Color</th>
                        <th>When to Use</th>
                    </tr>
                    <tr>
                        <td>DEBUG</td>
                        <td style="color: var(--accent-cyan);">Cyan</td>
                        <td>Detailed debugging</td>
                    </tr>
                    <tr>
                        <td>INFO</td>
                        <td style="color: var(--accent-green);">Green</td>
                        <td>Normal operations</td>
                    </tr>
                    <tr>
                        <td>WARNING</td>
                        <td style="color: var(--accent-yellow);">Yellow</td>
                        <td>Unusual conditions</td>
                    </tr>
                    <tr>
                        <td>ERROR</td>
                        <td style="color: var(--accent-red);">Red</td>
                        <td>Failures</td>
                    </tr>
                    <tr>
                        <td>CRITICAL</td>
                        <td style="color: var(--accent-purple);">Magenta</td>
                        <td>Critical issues</td>
                    </tr>
                </table>
            </section>

            <!-- Best Practices -->
            <section id="best-practices" class="section">
                <h2>Logging Best Practices</h2>

                <h3>Do</h3>
                <ul>
                    <li>Log strategic events (trades, rebalances)</li>
                    <li>Include context in messages</li>
                    <li>Log summary metrics at end</li>
                </ul>

                <h3>Don't</h3>
                <ul>
                    <li>Log on every bar (too noisy)</li>
                    <li>Duplicate progress information</li>
                    <li>Log sensitive information (API keys)</li>
                </ul>

                <h3>Update Intervals</h3>
                <pre><code># Short backtests (< 1 year)
enable_progress_logging(update_interval=1)  # Daily

# Medium backtests (1-5 years)
enable_progress_logging(update_interval=5)  # Weekly

# Long backtests (5+ years)
enable_progress_logging(update_interval=20)  # Monthly</code></pre>
            </section>

            <!-- Docker Setup -->
            <section id="docker-setup" class="section">
                <h2>Docker Setup</h2>

                <h3>Volume Mounts</h3>
                <pre><code>volumes:
  - ./data:/data                    # Strategy output
  - zipline-data:/root/.zipline     # Bundles
  - pip-cache:/root/.cache/pip      # Package cache</code></pre>

                <h3>When to Rebuild vs Restart</h3>
                <table>
                    <tr>
                        <th>Change Type</th>
                        <th>Action</th>
                    </tr>
                    <tr>
                        <td>Python source code</td>
                        <td>Rebuild container</td>
                    </tr>
                    <tr>
                        <td>Requirements/dependencies</td>
                        <td>Rebuild container</td>
                    </tr>
                    <tr>
                        <td>Strategy code (mounted)</td>
                        <td>Restart container</td>
                    </tr>
                    <tr>
                        <td>Data files</td>
                        <td>Restart container</td>
                    </tr>
                </table>
            </section>

            <!-- Build Optimization -->
            <section id="build-optimization" class="section">
                <h2>Build Optimization</h2>

                <h3>Enable BuildKit</h3>
                <pre><code># Run setup script
./scripts/setup-buildkit.sh

# Reload shell config
source ~/.zshrc  # Mac
source ~/.bashrc  # Linux</code></pre>

                <h3>Build Performance</h3>
                <table>
                    <tr>
                        <th>Scenario</th>
                        <th>Without Caching</th>
                        <th>With Caching</th>
                    </tr>
                    <tr>
                        <td>Clean build</td>
                        <td>15-20 min</td>
                        <td>15-20 min</td>
                    </tr>
                    <tr>
                        <td>Rebuild (no changes)</td>
                        <td>15-20 min</td>
                        <td>2-3 min</td>
                    </tr>
                    <tr>
                        <td>Rebuild (code only)</td>
                        <td>15-20 min</td>
                        <td>2-3 min</td>
                    </tr>
                </table>
            </section>

            <!-- Troubleshooting -->
            <section id="troubleshooting" class="section">
                <h2>Troubleshooting</h2>

                <h3>API Key Issues</h3>
                <pre><code># Check .env file
cat .env

# If missing
echo 'NASDAQ_DATA_LINK_API_KEY=your-key' > .env
docker compose restart</code></pre>

                <h3>Out of Memory</h3>
                <p>Increase Docker memory to <strong>16 GB</strong> for initial ingestion.</p>
                <p>Docker Desktop → Settings → Resources → Memory</p>

                <h3>FlightLog Not Connecting</h3>
                <pre><code># Check if running
docker ps | grep flightlog

# Test connection
import socket
sock = socket.socket()
result = sock.connect_ex(('localhost', 9020))
print("Open" if result == 0 else "Closed")</code></pre>

                <h3>No Data for Today</h3>
                <p>Wait 1-2 hours after market close (safe after 6 PM ET).</p>
            </section>

            <!-- Sharadar Columns -->
            <section id="sharadar-columns" class="section">
                <h2>Sharadar SF1 Columns</h2>
                <p>66 fundamental metrics available from Sharadar's SF1 (Core US Fundamentals) table. Access via <code>SharadarFundamentals.{column}.latest</code>.</p>

                <h3>Income Statement</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>revenue</code></td><td>Total revenue - top-line sales</td></tr>
                    <tr><td><code>cor</code></td><td>Cost of revenue</td></tr>
                    <tr><td><code>grossprofit</code></td><td>Gross profit (revenue minus cost of revenue)</td></tr>
                    <tr><td><code>sgna</code></td><td>Selling, general, and administrative expenses</td></tr>
                    <tr><td><code>rnd</code></td><td>Research and development expenses</td></tr>
                    <tr><td><code>opex</code></td><td>Operating expenses</td></tr>
                    <tr><td><code>opinc</code></td><td>Operating income</td></tr>
                    <tr><td><code>intexp</code></td><td>Interest expense</td></tr>
                    <tr><td><code>taxexp</code></td><td>Tax expense</td></tr>
                    <tr><td><code>netinc</code></td><td>Net income - bottom-line profit</td></tr>
                    <tr><td><code>ebit</code></td><td>Earnings before interest and taxes</td></tr>
                    <tr><td><code>ebitda</code></td><td>Earnings before interest, taxes, depreciation, and amortization</td></tr>
                    <tr><td><code>consolinc</code></td><td>Consolidated net income</td></tr>
                    <tr><td><code>netincnci</code></td><td>Net income to non-controlling interests</td></tr>
                    <tr><td><code>netincdis</code></td><td>Net income from discontinued operations</td></tr>
                    <tr><td><code>prefdivis</code></td><td>Preferred dividends</td></tr>
                </table>

                <h3>Balance Sheet - Assets</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>assets</code></td><td>Total assets</td></tr>
                    <tr><td><code>cashneq</code></td><td>Cash and cash equivalents</td></tr>
                    <tr><td><code>investments</code></td><td>Investments</td></tr>
                    <tr><td><code>investmentsc</code></td><td>Current investments</td></tr>
                    <tr><td><code>investmentsnc</code></td><td>Non-current investments</td></tr>
                    <tr><td><code>receivables</code></td><td>Accounts receivable</td></tr>
                    <tr><td><code>inventory</code></td><td>Inventory</td></tr>
                    <tr><td><code>ppnenet</code></td><td>Property, plant, and equipment (net)</td></tr>
                    <tr><td><code>intangibles</code></td><td>Intangible assets</td></tr>
                    <tr><td><code>goodwill</code></td><td>Goodwill (not in Zipline class)</td></tr>
                    <tr><td><code>assetsc</code></td><td>Current assets</td></tr>
                    <tr><td><code>assetsnc</code></td><td>Non-current assets</td></tr>
                </table>

                <h3>Balance Sheet - Liabilities & Equity</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>liabilities</code></td><td>Total liabilities</td></tr>
                    <tr><td><code>liabilitiesc</code></td><td>Current liabilities</td></tr>
                    <tr><td><code>liabilitiesnc</code></td><td>Non-current liabilities</td></tr>
                    <tr><td><code>payables</code></td><td>Accounts payable</td></tr>
                    <tr><td><code>debtc</code></td><td>Current debt</td></tr>
                    <tr><td><code>debtnc</code></td><td>Non-current debt</td></tr>
                    <tr><td><code>debt</code></td><td>Total debt</td></tr>
                    <tr><td><code>equity</code></td><td>Shareholders' equity</td></tr>
                    <tr><td><code>retearn</code></td><td>Retained earnings</td></tr>
                    <tr><td><code>accoci</code></td><td>Accumulated other comprehensive income</td></tr>
                </table>

                <h3>Cash Flow Statement</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>ncfo</code></td><td>Net cash flow from operating activities</td></tr>
                    <tr><td><code>ncfi</code></td><td>Net cash flow from investing activities</td></tr>
                    <tr><td><code>ncff</code></td><td>Net cash flow from financing activities</td></tr>
                    <tr><td><code>ncfx</code></td><td>Effect of exchange rate changes on cash</td></tr>
                    <tr><td><code>ncfbus</code></td><td>Net cash flow - business acquisitions and disposals</td></tr>
                    <tr><td><code>ncfinv</code></td><td>Net cash flow - investment acquisitions and disposals</td></tr>
                    <tr><td><code>ncfcommon</code></td><td>Issuance (retirement) of common stock</td></tr>
                    <tr><td><code>ncfdebt</code></td><td>Issuance (retirement) of debt securities</td></tr>
                    <tr><td><code>capex</code></td><td>Capital expenditures</td></tr>
                    <tr><td><code>fcf</code></td><td>Free cash flow</td></tr>
                    <tr><td><code>depamor</code></td><td>Depreciation and amortization</td></tr>
                    <tr><td><code>sbcomp</code></td><td>Stock-based compensation</td></tr>
                </table>

                <h3>Valuation Ratios</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>pe</code></td><td>Price to earnings ratio</td></tr>
                    <tr><td><code>pe1</code></td><td>Price to earnings ratio (alternative)</td></tr>
                    <tr><td><code>pb</code></td><td>Price to book ratio</td></tr>
                    <tr><td><code>ps</code></td><td>Price to sales ratio</td></tr>
                    <tr><td><code>ps1</code></td><td>Price to sales ratio (alternative)</td></tr>
                    <tr><td><code>marketcap</code></td><td>Market capitalization</td></tr>
                    <tr><td><code>ev</code></td><td>Enterprise value</td></tr>
                    <tr><td><code>evebit</code></td><td>Enterprise value to EBIT</td></tr>
                    <tr><td><code>evebitda</code></td><td>Enterprise value to EBITDA</td></tr>
                </table>

                <h3>Profitability Ratios</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>roe</code></td><td>Return on equity (%)</td></tr>
                    <tr><td><code>roa</code></td><td>Return on assets (%)</td></tr>
                    <tr><td><code>roic</code></td><td>Return on invested capital (%)</td></tr>
                    <tr><td><code>ros</code></td><td>Return on sales (%)</td></tr>
                    <tr><td><code>grossmargin</code></td><td>Gross margin (%)</td></tr>
                    <tr><td><code>netmargin</code></td><td>Net margin (%)</td></tr>
                    <tr><td><code>ebitdamargin</code></td><td>EBITDA margin (%)</td></tr>
                </table>

                <h3>Liquidity & Leverage Ratios</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>de</code></td><td>Debt to equity ratio</td></tr>
                    <tr><td><code>currentratio</code></td><td>Current ratio (current assets / current liabilities)</td></tr>
                    <tr><td><code>workingcapital</code></td><td>Working capital</td></tr>
                    <tr><td><code>tangibles</code></td><td>Tangible assets</td></tr>
                </table>

                <h3>Per-Share Metrics</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>eps</code></td><td>Earnings per share (diluted)</td></tr>
                    <tr><td><code>epsdil</code></td><td>Earnings per share (diluted)</td></tr>
                    <tr><td><code>epsusd</code></td><td>Earnings per share in USD</td></tr>
                    <tr><td><code>bvps</code></td><td>Book value per share</td></tr>
                    <tr><td><code>dps</code></td><td>Dividends per share</td></tr>
                    <tr><td><code>fcfps</code></td><td>Free cash flow per share</td></tr>
                    <tr><td><code>sps</code></td><td>Sales per share</td></tr>
                    <tr><td><code>revenueusd</code></td><td>Revenue in USD</td></tr>
                    <tr><td><code>sharesbas</code></td><td>Shares outstanding (basic)</td></tr>
                    <tr><td><code>shareswa</code></td><td>Weighted average shares outstanding</td></tr>
                    <tr><td><code>shareswadil</code></td><td>Weighted average shares outstanding (diluted)</td></tr>
                    <tr><td><code>sharesfactor</code></td><td>Share factor for stock splits</td></tr>
                </table>

                <h3>Growth Metrics</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>revenuegrowth</code></td><td>Revenue growth rate (%)</td></tr>
                    <tr><td><code>netincgrowth</code></td><td>Net income growth rate (%)</td></tr>
                    <tr><td><code>epsgrowth</code></td><td>EPS growth rate (%)</td></tr>
                    <tr><td><code>assetturnover</code></td><td>Asset turnover ratio</td></tr>
                </table>

                <h3>Other Metrics</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>payoutratio</code></td><td>Dividend payout ratio</td></tr>
                    <tr><td><code>divyield</code></td><td>Dividend yield</td></tr>
                    <tr><td><code>invcapavg</code></td><td>Average invested capital</td></tr>
                    <tr><td><code>equityavg</code></td><td>Average equity</td></tr>
                    <tr><td><code>assetsavg</code></td><td>Average assets</td></tr>
                    <tr><td><code>debtusd</code></td><td>Total debt in USD</td></tr>
                    <tr><td><code>equityusd</code></td><td>Shareholders' equity in USD</td></tr>
                    <tr><td><code>cashnequsd</code></td><td>Cash and equivalents in USD</td></tr>
                </table>

                <div class="callout callout-info">
                    <strong>Usage Example:</strong>
                    <pre><code>from zipline.pipeline.data.sharadar import SharadarFundamentals

# Screen for value stocks
value_screen = (
    (SharadarFundamentals.pe.latest < 15) &
    (SharadarFundamentals.roe.latest > 15) &
    (SharadarFundamentals.de.latest < 1.0)
)</code></pre>
                </div>
            </section>

            <!-- LSEG Columns -->
            <section id="lseg-columns" class="section">
                <h2>LSEG Custom Database Columns</h2>
                <p>36 fundamental and analytics columns available from LSEG (formerly Refinitiv) custom database, enriched with Sharadar metadata. Access via custom database class definition.</p>

                <h3>Price & Volume (2 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>RefPriceClose</code></td><td>Reference closing price</td></tr>
                    <tr><td><code>RefVolume</code></td><td>Reference trading volume</td></tr>
                </table>

                <h3>Company Information (3 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>CompanyCommonName</code></td><td>Company common name</td></tr>
                    <tr><td><code>CompanyMarketCap</code></td><td>Company market capitalization</td></tr>
                    <tr><td><code>GICSSectorName</code></td><td>GICS sector classification</td></tr>
                </table>

                <h3>Valuation Metrics (9 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>EnterpriseValue_DailyTimeSeries_</code></td><td>Enterprise value (daily time series)</td></tr>
                    <tr><td><code>EnterpriseValueToEBIT_DailyTimeSeriesRatio_</code></td><td>EV to EBIT ratio (daily)</td></tr>
                    <tr><td><code>EnterpriseValueToEBITDA_DailyTimeSeriesRatio_</code></td><td>EV to EBITDA ratio (daily)</td></tr>
                    <tr><td><code>EnterpriseValueToSales_DailyTimeSeriesRatio_</code></td><td>EV to sales ratio (daily)</td></tr>
                    <tr><td><code>ForwardEnterpriseValueToOperatingCashFlow_DailyTimeSeriesRatio_</code></td><td>Forward EV to operating cash flow ratio</td></tr>
                    <tr><td><code>ForwardPEG_DailyTimeSeriesRatio_</code></td><td>Forward PEG ratio (daily)</td></tr>
                    <tr><td><code>ForwardPriceToCashFlowPerShare_DailyTimeSeriesRatio_</code></td><td>Forward price to cash flow per share</td></tr>
                    <tr><td><code>ForwardPriceToSalesPerShare_DailyTimeSeriesRatio_</code></td><td>Forward price to sales per share</td></tr>
                    <tr><td><code>PriceEarningsToGrowthRatio_SmartEstimate_</code></td><td>PE to growth ratio smart estimate</td></tr>
                </table>

                <h3>Cash Flow & Balance Sheet (4 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>CashCashEquivalents_Total</code></td><td>Total cash and cash equivalents</td></tr>
                    <tr><td><code>Debt_Total</code></td><td>Total debt</td></tr>
                    <tr><td><code>FOCFExDividends_Discrete</code></td><td>Free operating cash flow excluding dividends</td></tr>
                    <tr><td><code>InterestExpense_NetofCapitalizedInterest</code></td><td>Net interest expense after capitalization</td></tr>
                </table>

                <h3>Earnings Metrics (5 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>EarningsPerShare_Actual</code></td><td>Actual reported EPS</td></tr>
                    <tr><td><code>EarningsPerShare_ActualSurprise</code></td><td>EPS surprise (actual vs estimate)</td></tr>
                    <tr><td><code>EarningsPerShare_SmartEstimate_current_Q</code></td><td>EPS smart estimate for current quarter</td></tr>
                    <tr><td><code>EarningsPerShare_SmartEstimate_prev_Q</code></td><td>EPS smart estimate for previous quarter</td></tr>
                    <tr><td><code>GrossProfitMargin_ActualSurprise</code></td><td>Gross profit margin surprise</td></tr>
                </table>

                <h3>Growth & Target Estimates (4 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>LongTermGrowth_Mean</code></td><td>Mean long-term growth estimate</td></tr>
                    <tr><td><code>PriceTarget_Median</code></td><td>Median analyst target price</td></tr>
                    <tr><td><code>Estpricegrowth_percent</code></td><td>Estimated price growth percentage</td></tr>
                    <tr><td><code>Dividend_Per_Share_SmartEstimate</code></td><td>Dividend per share smart estimate</td></tr>
                </table>

                <h3>Profitability Ratios (2 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>ReturnOnEquity_SmartEstimat</code></td><td>ROE consensus smart estimate</td></tr>
                    <tr><td><code>ReturnOnAssets_SmartEstimate</code></td><td>ROA consensus smart estimate</td></tr>
                </table>

                <h3>Alpha Model Rankings (4 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>CombinedAlphaModelRegionRank</code></td><td>Alpha model rank within region</td></tr>
                    <tr><td><code>CombinedAlphaModelSectorRank</code></td><td>Alpha model rank within sector</td></tr>
                    <tr><td><code>CombinedAlphaModelSectorRankChange</code></td><td>Change in sector rank</td></tr>
                    <tr><td><code>EarningsQualityRegionRank_Current</code></td><td>Current earnings quality rank in region</td></tr>
                </table>

                <h3>Analyst Recommendations (1 column)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>Recommendation_Median_1_5_</code></td><td>Median analyst recommendation (1-5 scale: 1=Strong Buy, 5=Strong Sell)</td></tr>
                </table>

                <h3>Custom Signals (2 columns)</h3>
                <table>
                    <tr><th>Column</th><th>Description</th></tr>
                    <tr><td><code>pred</code></td><td>VIX prediction signal</td></tr>
                    <tr><td><code>bc1</code></td><td>BC sentiment indicator</td></tr>
                </table>

                <div class="callout callout-info">
                    <strong>Usage Example:</strong>
                    <pre><code>from zipline.pipeline import multi_source as ms

class LSEGFundamentals(ms.Database):
    CODE = "fundamentals"  # Matches fundamentals.sqlite filename
    LOOKBACK_WINDOW = 252

    # Price & Volume
    RefPriceClose = ms.Column(float)
    RefVolume = ms.Column(float)

    # Company Information
    CompanyCommonName = ms.Column(str)
    CompanyMarketCap = ms.Column(float)
    GICSSectorName = ms.Column(str)

    # Valuation Metrics
    EnterpriseValue_DailyTimeSeries_ = ms.Column(float)
    ForwardPEG_DailyTimeSeriesRatio_ = ms.Column(float)

    # Profitability
    ReturnOnEquity_SmartEstimat = ms.Column(float)
    ReturnOnAssets_SmartEstimate = ms.Column(float)

    # Alpha Rankings
    CombinedAlphaModelSectorRank = ms.Column(float)
    EarningsQualityRegionRank_Current = ms.Column(float)

    # Earnings
    EarningsPerShare_Actual = ms.Column(float)
    EarningsPerShare_ActualSurprise = ms.Column(float)

    # Growth & Targets
    LongTermGrowth_Mean = ms.Column(float)
    PriceTarget_Median = ms.Column(float)

    # Custom Signals
    pred = ms.Column(float)  # VIX prediction
    bc1 = ms.Column(float)   # BC sentiment

# Use in pipeline
def make_pipeline():
    # Quality filters
    high_roe = LSEGFundamentals.ReturnOnEquity_SmartEstimat.latest > 15
    low_debt = LSEGFundamentals.Debt_Total.latest / LSEGFundamentals.CompanyMarketCap.latest < 0.5

    # Alpha ranking
    top_sector = LSEGFundamentals.CombinedAlphaModelSectorRank.latest <= 20

    return ms.Pipeline(
        columns={
            'roe': LSEGFundamentals.ReturnOnEquity_SmartEstimat.latest,
            'sector_rank': LSEGFundamentals.CombinedAlphaModelSectorRank.latest,
            'target_price': LSEGFundamentals.PriceTarget_Median.latest,
            'vix_signal': LSEGFundamentals.pred.latest,
        },
        screen=(high_roe & low_debt & top_sector)
    )</code></pre>
                </div>

                <div class="callout callout-success">
                    <strong>Total Available:</strong> 36 LSEG columns + 9 Sharadar metadata columns (exchange, category, sector, industry, location, ADR status, market cap scale, SIC classifications) = 45 total columns for advanced stock screening.
                </div>
            </section>

            <!-- Command Reference -->
            <section id="command-reference" class="section">
                <h2>Command Reference</h2>

                <h3>Data Management</h3>
                <pre><code># List bundles
zipline bundles

# Ingest/update data
zipline ingest -b sharadar

# Clean old ingestions
zipline clean -b sharadar --keep-last 2</code></pre>

                <h3>FlightLog</h3>
                <pre><code># Start FlightLog
docker compose run --rm flightlog

# Filter progress bars
docker compose run --rm flightlog python /app/scripts/flightlog.py --filter-progress</code></pre>

                <h3>Docker</h3>
                <pre><code># Start services
docker compose up -d

# Rebuild image
docker compose build zipline-jupyter

# Restart container
docker compose restart zipline-jupyter

# View logs
docker compose logs zipline-jupyter</code></pre>
            </section>

            <!-- Resource Requirements -->
            <section id="resource-requirements" class="section">
                <h2>Resource Requirements</h2>

                <table>
                    <tr>
                        <th>Operation</th>
                        <th>Time</th>
                        <th>Storage</th>
                        <th>RAM</th>
                    </tr>
                    <tr>
                        <td>Initial download</td>
                        <td>60-90 min</td>
                        <td>10-15 GB</td>
                        <td>16 GB</td>
                    </tr>
                    <tr>
                        <td>Daily update</td>
                        <td>2-5 min</td>
                        <td>+50-100 MB</td>
                        <td>4 GB</td>
                    </tr>
                    <tr>
                        <td>Tech bundle</td>
                        <td>30 sec</td>
                        <td>50 MB</td>
                        <td>2 GB</td>
                    </tr>
                </table>
            </section>

            <!-- Footer -->
            <footer style="margin-top: 60px; padding-top: 30px; border-top: 1px solid var(--border-color); color: var(--text-muted); font-size: 0.9em;">
                <p><strong>Last Updated:</strong> 2025-11-19</p>
                <p><strong>Source Files:</strong> Individual markdown files in <code>docs/</code> directory</p>
                <p><strong>License:</strong> Apache 2.0</p>
            </footer>
        </main>
    </div>

    <!-- Back to top button -->
    <a href="#overview" class="back-to-top" id="backToTop">↑</a>

    <script>
        // Back to top button visibility
        const backToTop = document.getElementById('backToTop');
        window.addEventListener('scroll', () => {
            if (window.scrollY > 300) {
                backToTop.classList.add('visible');
            } else {
                backToTop.classList.remove('visible');
            }
        });

        // Smooth scrolling for navigation links
        document.querySelectorAll('.nav-item').forEach(link => {
            link.addEventListener('click', (e) => {
                e.preventDefault();
                const targetId = link.getAttribute('href').substring(1);
                const target = document.getElementById(targetId);
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth' });
                }
                
                // Update active state
                document.querySelectorAll('.nav-item').forEach(item => item.classList.remove('active'));
                link.classList.add('active');
            });
        });

        // Update active nav on scroll
        const sections = document.querySelectorAll('.section');
        const navItems = document.querySelectorAll('.nav-item');

        window.addEventListener('scroll', () => {
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                if (scrollY >= sectionTop - 100) {
                    current = section.getAttribute('id');
                }
            });

            navItems.forEach(item => {
                item.classList.remove('active');
                if (item.getAttribute('href') === '#' + current) {
                    item.classList.add('active');
                }
            });
        });
    </script>
</body>
</html>
