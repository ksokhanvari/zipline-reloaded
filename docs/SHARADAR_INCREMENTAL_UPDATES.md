# Sharadar Incremental Updates - How It Works

## Overview

The Sharadar bundle supports **incremental updates** to make daily data ingestion much faster after the initial download.

## How Incremental Updates Work

### First Ingestion (Initial Download)
When you run `zipline ingest -b sharadar` for the **first time**:

```bash
zipline ingest -b sharadar
```

**Expected behavior:**
- Downloads ALL historical data (1998-present)
- Takes 60-90 minutes for full dataset
- Downloads ~10-20 GB of data
- Progress shows: "Downloading SEP table" (not "incremental")

This is **NORMAL** and **EXPECTED** for the first run!

The bundle needs to download the complete historical dataset before it can do incremental updates.

### Subsequent Ingestions (Incremental)
After the first ingestion completes, running the same command again:

```bash
zipline ingest -b sharadar
```

**Expected behavior:**
- Only downloads NEW data since last ingestion
- Takes 2-5 minutes typically
- Downloads only a few MB
- Progress shows: "Downloading NEW Sharadar Equity Prices (incremental)..."

**How it detects previous data:**
1. Checks for existing bundle data in `~/.zipline/data/sharadar/`
2. Queries the SQLite database to find the last date
3. Only requests data from `last_date + 1 day` onwards
4. Merges new data with existing data

## Verifying Incremental Updates

### Check if you have existing data:
```bash
ls -lh ~/.zipline/data/sharadar/
```

**First time (no data):**
```
ls: cannot access '~/.zipline/data/sharadar/': No such file or directory
```
‚Üí Full download required

**After first ingestion:**
```
drwxr-xr-x  adjustments.sqlite
drwxr-xr-x  daily_equity_pricing.bcolz
drwxr-xr-x  assets-7.db
```
‚Üí Incremental updates enabled

### Check last ingestion date:
```bash
sqlite3 ~/.zipline/data/sharadar/*/assets-7.db \
  "SELECT date(max(end_date), 'unixepoch') as last_date FROM asset_router;"
```

This shows the last date in your bundle. Next ingestion will start from `last_date + 1`.

## Configuration Options

### Force Full Download (Disable Incremental)
If you want to re-download everything (e.g., data corruption):

Edit `~/.zipline/extension.py`:
```python
register(
    'sharadar',
    sharadar_bundle(
        incremental=False,  # ‚Üê Disable incremental
    ),
)
```

### Verify Incremental is Enabled
Default configuration in `extension.py`:
```python
register(
    'sharadar',
    sharadar_bundle(
        incremental=True,  # ‚úÖ Enabled by default
    ),
)
```

## Example Timeline

### Day 1 (First Ingestion)
```bash
$ zipline ingest -b sharadar
Sharadar Bundle Ingestion
Step 1/4: Downloading Sharadar Equity Prices (SEP table)...
  ‚ö†Ô∏è  Dataset too large for get_table(), using bulk export API...
  ‚è≥ File is being generated by NASDAQ servers...
     This can take 60-90 minutes for full historical data (1998-present)
```
**Duration:** 60-90 minutes
**Data downloaded:** 1998-01-01 to 2025-11-03 (~27 years)

### Day 2 (Incremental Update)
```bash
$ zipline ingest -b sharadar
üîÑ INCREMENTAL UPDATE DETECTED
  Last ingestion: 2025-11-03
  Downloading from: 2025-11-04 to 2025-11-03
  Only downloading NEW data since last ingestion

Step 1/4: Downloading NEW Sharadar Equity Prices (incremental)...
  Downloading 1 day of new data...
```
**Duration:** 2-3 minutes
**Data downloaded:** Only Nov 4, 2025 (1 day)

### Day 30 (After 1 Month)
```bash
$ zipline ingest -b sharadar
üîÑ INCREMENTAL UPDATE DETECTED
  Last ingestion: 2025-11-03
  Downloading from: 2025-11-04 to 2025-12-03
  Only downloading NEW data since last ingestion
```
**Duration:** 3-5 minutes
**Data downloaded:** 30 days of new data

## Storage Requirements

### First Ingestion:
- Raw download: ~5-8 GB
- Processed bundle: ~10-15 GB
- Total: ~20 GB free space recommended

### Incremental Updates:
- Each daily update: ~50-100 MB
- Negligible storage impact

## Troubleshooting

### "Downloading full dataset every time"
**Cause:** No existing bundle data found

**Solutions:**
1. Check if first ingestion completed successfully:
   ```bash
   ls ~/.zipline/data/sharadar/
   ```

2. Check bundle name matches:
   ```bash
   # These are different bundles:
   zipline ingest -b sharadar         # ‚úÖ Uses incremental
   zipline ingest -b sharadar-full    # ‚ùå Always full download
   ```

3. Verify incremental is enabled in `~/.zipline/extension.py`:
   ```python
   incremental=True  # Must be True
   ```

### "Want to force re-download"
```bash
# Delete existing data
rm -rf ~/.zipline/data/sharadar/

# Run fresh ingestion
zipline ingest -b sharadar
```

### "How do I know if incremental worked?"
Look for this message:
```
üîÑ INCREMENTAL UPDATE DETECTED
  Last ingestion: 2025-11-03
```

If you see this, incremental updates are working!

## Performance Comparison

| Scenario | Duration | Data Downloaded | Storage Used |
|----------|----------|-----------------|--------------|
| **First Ingestion** | 60-90 min | 27 years (1998-2025) | ~15 GB |
| **Daily Update** | 2-3 min | 1 day | ~50 MB |
| **Weekly Update** | 3-4 min | 7 days | ~200 MB |
| **Monthly Update** | 4-5 min | 30 days | ~800 MB |
| **Yearly Update** | 10-15 min | 252 days | ~2 GB |

## Best Practices

1. **Let first ingestion complete fully** - Don't interrupt it
2. **Run daily updates** - Keeps ingestion fast (2-3 minutes)
3. **Use Docker volumes** - Persist `~/.zipline/data/` between container restarts
4. **Monitor disk space** - Keep 20GB free for initial ingestion
5. **Automate daily ingestion** - Use cron or scheduler

## Example Automation

### Docker Compose with Daily Updates
```yaml
services:
  sharadar-ingest:
    image: your-zipline-image
    volumes:
      - zipline-data:/root/.zipline
    command: zipline ingest -b sharadar
    environment:
      - NASDAQ_DATA_LINK_API_KEY=${NASDAQ_API_KEY}
```

### Cron Job (Daily at 6 AM)
```bash
0 6 * * * docker compose run --rm zipline-ingest
```

## Summary

‚úÖ **First ingestion:** Downloads everything (60-90 min) - THIS IS NORMAL
‚úÖ **Subsequent ingestions:** Only new data (2-5 min) - THIS IS INCREMENTAL
‚úÖ **Automatic detection:** No configuration needed after setup
‚úÖ **Storage efficient:** Only stores incremental changes

The full download you're seeing is **expected and correct** for the first ingestion!
