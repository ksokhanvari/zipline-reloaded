{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "source": [
        "# Research Pipeline with Custom Fundamental Data\n",
        "\n",
        "This notebook demonstrates quantitative research and stock screening using **existing** custom fundamental data.\n",
        "\n",
        "**Prerequisites**: \n",
        "- Run `load_csv_fundamentals.ipynb` **first** to create the database\n",
        "- Ensure database exists at `~/.zipline/data/custom/fundamentals.sqlite`\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "1. **Pipeline Basics**: Creating DataSets from your custom data\n",
        "2. **Factor Analysis**: Building factors from fundamental metrics  \n",
        "3. **Screening**: Filtering stocks based on fundamental criteria\n",
        "4. **Ranking**: Scoring and ranking stocks for investment decisions\n",
        "5. **Integration**: Combining fundamentals with price data\n",
        "6. **Visualization**: Analyzing results with charts\n",
        "7. **Time Series**: Tracking fundamental trends over time\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "- **Value Investing**: Screen for low P/E, high ROE stocks\n",
        "- **Quality Analysis**: Identify companies with strong fundamentals  \n",
        "- **Sector Rotation**: Compare metrics across sectors\n",
        "- **Factor Research**: Test custom factors based on fundamentals\n",
        "- **Portfolio Construction**: Build portfolios using fundamental signals\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "id": "cell-1",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Import Zipline custom data module\n",
        "from zipline.data.custom import (\n",
        "    describe_custom_db,\n",
        "    list_custom_dbs,\n",
        "    get_prices,\n",
        "    get_latest_values,\n",
        "    make_custom_dataset_class,\n",
        ")\n",
        "\n",
        "# Import Zipline Pipeline\n",
        "from zipline.pipeline import Pipeline, CustomFactor\n",
        "from zipline.pipeline.data import EquityPricing\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"\u2713 Imports successful!\")"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "id": "cell-2",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Database configuration\n",
        "DB_CODE = 'fundamentals'  # Must match the database created in load_csv_fundamentals.ipynb\n",
        "\n",
        "# Check that database exists\n",
        "available_dbs = list_custom_dbs()\n",
        "\n",
        "if DB_CODE not in available_dbs:\n",
        "    print(\"\u274c ERROR: Database not found!\")\n",
        "    print(f\"\\nExpected database: '{DB_CODE}'\")\n",
        "    print(f\"Available databases: {available_dbs}\")\n",
        "    print(\"\\n\u26a0\ufe0f  Please run 'load_csv_fundamentals.ipynb' first to create the database.\")\n",
        "    raise FileNotFoundError(f\"Database '{DB_CODE}' not found. Run load_csv_fundamentals.ipynb first.\")\n",
        "else:\n",
        "    print(f\"\u2713 Database '{DB_CODE}' found!\")\n",
        "    \n",
        "    # Get database info\n",
        "    db_info = describe_custom_db(DB_CODE)\n",
        "    \n",
        "    print(f\"\\nDatabase Statistics:\")\n",
        "    print(f\"  Location: {db_info['db_path']}\")\n",
        "    print(f\"  Total rows: {db_info['row_count']:,}\")\n",
        "    print(f\"  Unique assets: {db_info['num_sids']}\")\n",
        "    if db_info['date_range']:\n",
        "        print(f\"  Date range: {db_info['date_range'][0]} to {db_info['date_range'][1]}\")\n",
        "    print(f\"  Columns: {len(db_info['columns'])}\")"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "id": "cell-3",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Define schema for reference (should match what's in the database)\n",
        "fundamental_columns = {\n",
        "    # Income Statement\n",
        "    'Revenue': 'int',\n",
        "    'NetIncome': 'int',\n",
        "    \n",
        "    # Balance Sheet  \n",
        "    'TotalAssets': 'int',\n",
        "    'TotalEquity': 'int',\n",
        "    'SharesOutstanding': 'int',\n",
        "    \n",
        "    # Per-Share Metrics\n",
        "    'EPS': 'float',\n",
        "    'BookValuePerShare': 'float',\n",
        "    \n",
        "    # Financial Ratios\n",
        "    'ROE': 'float',\n",
        "    'DebtToEquity': 'float', \n",
        "    'CurrentRatio': 'float',\n",
        "    'PERatio': 'float',\n",
        "    \n",
        "    # Metadata\n",
        "    'Sector': 'text',\n",
        "}\n",
        "\n",
        "print(f\"Schema defined with {len(fundamental_columns)} columns\")\n",
        "print(\"\\nNote: This should match the database created in load_csv_fundamentals.ipynb\")"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 3: Create Pipeline DataSet\n",
        "\n",
        "Now we'll create a Zipline Pipeline DataSet from our custom data. This allows us to use the data in Pipeline computations."
      ],
      "id": "cell-4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataSet class from our database\n",
        "CustomFundamentals = make_custom_dataset_class(\n",
        "    db_code=DB_CODE,\n",
        "    columns=fundamental_columns,\n",
        "    base_name='CustomFundamentals',  # This will create 'FundamentalsDataSet'\n",
        ")\n",
        "\n",
        "print(\"\u2713 DataSet class created: FundamentalsDataSet\")\n",
        "print(\"\\nAvailable columns (as Pipeline factors):\")\n",
        "for col in fundamental_columns.keys():\n",
        "    print(f\"  - CustomFundamentals.{col}\")\n",
        "    \n",
        "print(\"\\nYou can now use these in Pipeline like:\")\n",
        "print(\"  CustomFundamentals.Revenue.latest\")\n",
        "print(\"  CustomFundamentals.ROE.latest\")\n",
        "print(\"  CustomFundamentals.PERatio.latest\")"
      ],
      "id": "cell-5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 4: Simple Pipeline Examples\n",
        "\n",
        "Let's create some simple pipelines to screen and rank stocks."
      ],
      "id": "cell-6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 1: Basic Screening\n",
        "\n",
        "Screen for stocks with:\n",
        "- High ROE (> 10%)\n",
        "- Low P/E ratio (< 30)\n",
        "- Low debt (Debt/Equity < 1.0)"
      ],
      "id": "cell-7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple screening pipeline\n",
        "def make_screening_pipeline():\n",
        "    \"\"\"\n",
        "    Create a pipeline that screens for quality stocks.\n",
        "    \n",
        "    Criteria:\n",
        "    - ROE > 10% (profitable and efficient)\n",
        "    - P/E < 30 (reasonably valued)\n",
        "    - Debt/Equity < 1.0 (not over-leveraged)\n",
        "    \"\"\"\n",
        "    # Get the latest fundamental values\n",
        "    roe = CustomFundamentals.ROE.latest\n",
        "    pe_ratio = CustomFundamentals.PERatio.latest\n",
        "    debt_to_equity = CustomFundamentals.DebtToEquity.latest\n",
        "    eps = CustomFundamentals.EPS.latest\n",
        "    revenue = CustomFundamentals.Revenue.latest\n",
        "    sector = CustomFundamentals.Sector.latest\n",
        "    \n",
        "    # Define screening filters\n",
        "    high_roe = (roe > 10.0)\n",
        "    reasonable_pe = (pe_ratio < 30.0)\n",
        "    low_debt = (debt_to_equity < 1.0)\n",
        "    \n",
        "    # Combine filters\n",
        "    quality_screen = high_roe & reasonable_pe & low_debt\n",
        "    \n",
        "    # Create pipeline\n",
        "    return Pipeline(\n",
        "        columns={\n",
        "            'ROE': roe,\n",
        "            'PE_Ratio': pe_ratio,\n",
        "            'Debt_to_Equity': debt_to_equity,\n",
        "            'EPS': eps,\n",
        "            'Revenue': revenue,\n",
        "            'Sector': sector,\n",
        "        },\n",
        "        screen=quality_screen,  # Only return stocks passing the screen\n",
        "    )\n",
        "\n",
        "screening_pipeline = make_screening_pipeline()\n",
        "print(\"\u2713 Screening pipeline created\")\n",
        "print(\"  Filters: ROE > 10%, P/E < 30, Debt/Equity < 1.0\")"
      ],
      "id": "cell-8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Ranking Pipeline\n",
        "\n",
        "Rank stocks by a composite quality score."
      ],
      "id": "cell-9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a custom factor for quality score\n",
        "class QualityScore(CustomFactor):\n",
        "    \"\"\"\n",
        "    Composite quality score based on:\n",
        "    - ROE (higher is better)\n",
        "    - P/E ratio (lower is better)\n",
        "    - Debt/Equity (lower is better)\n",
        "    \n",
        "    Returns a normalized score where higher = better quality.\n",
        "    \"\"\"\n",
        "    inputs = [\n",
        "        CustomFundamentals.ROE,\n",
        "        CustomFundamentals.PERatio,\n",
        "        CustomFundamentals.DebtToEquity,\n",
        "    ]\n",
        "    window_length = 1  # Only need latest value\n",
        "    \n",
        "    def compute(self, today, assets, out, roe, pe, debt):\n",
        "        # Get latest values (window_length=1, use -1 for most recent)\n",
        "        roe_latest = roe[-1]\n",
        "        pe_latest = pe[-1]\n",
        "        debt_latest = debt[-1]\n",
        "        \n",
        "        # Normalize each metric to 0-1 scale using min-max normalization\n",
        "        # ROE: higher is better\n",
        "        roe_min, roe_max = np.nanmin(roe_latest), np.nanmax(roe_latest)\n",
        "        if roe_max > roe_min:\n",
        "            roe_score = (roe_latest - roe_min) / (roe_max - roe_min)\n",
        "        else:\n",
        "            roe_score = np.full_like(roe_latest, 0.5)  # Neutral score if all same\n",
        "        \n",
        "        # P/E: lower is better, so invert\n",
        "        pe_min, pe_max = np.nanmin(pe_latest), np.nanmax(pe_latest)\n",
        "        if pe_max > pe_min:\n",
        "            pe_score = 1 - ((pe_latest - pe_min) / (pe_max - pe_min))\n",
        "        else:\n",
        "            pe_score = np.full_like(pe_latest, 0.5)\n",
        "        \n",
        "        # Debt: lower is better, so invert\n",
        "        debt_min, debt_max = np.nanmin(debt_latest), np.nanmax(debt_latest)\n",
        "        if debt_max > debt_min:\n",
        "            debt_score = 1 - ((debt_latest - debt_min) / (debt_max - debt_min))\n",
        "        else:\n",
        "            debt_score = np.full_like(debt_latest, 0.5)\n",
        "        \n",
        "        # Composite score (equal weights)\n",
        "        out[:] = (roe_score + pe_score + debt_score) / 3.0\n",
        "\n",
        "\n",
        "def make_ranking_pipeline():\n",
        "    \"\"\"\n",
        "    Create a pipeline that ranks stocks by quality score.\n",
        "    \"\"\"\n",
        "    # Calculate quality score\n",
        "    quality = QualityScore()\n",
        "    \n",
        "    # Get fundamentals\n",
        "    roe = CustomFundamentals.ROE.latest\n",
        "    pe_ratio = CustomFundamentals.PERatio.latest\n",
        "    debt_to_equity = CustomFundamentals.DebtToEquity.latest\n",
        "    eps = CustomFundamentals.EPS.latest\n",
        "    sector = CustomFundamentals.Sector.latest\n",
        "    \n",
        "    # Rank by quality score\n",
        "    quality_rank = quality.rank(ascending=False)  # 1 = best\n",
        "    \n",
        "    return Pipeline(\n",
        "        columns={\n",
        "            'Quality_Score': quality,\n",
        "            'Quality_Rank': quality_rank,\n",
        "            'ROE': roe,\n",
        "            'PE_Ratio': pe_ratio,\n",
        "            'Debt_to_Equity': debt_to_equity,\n",
        "            'EPS': eps,\n",
        "            'Sector': sector,\n",
        "        },\n",
        "    )\n",
        "\n",
        "ranking_pipeline = make_ranking_pipeline()\n",
        "print(\"\u2713 Ranking pipeline created\")\n",
        "print(\"  Ranks stocks by composite quality score (ROE, P/E, Debt)\")"
      ],
      "id": "cell-10"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 3: Sector Analysis Pipeline\n",
        "\n",
        "Compare metrics across sectors."
      ],
      "id": "cell-11"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a custom factor for profit margin\n",
        "class ProfitMargin(CustomFactor):\n",
        "    \"\"\"\n",
        "    Calculate profit margin: (Net Income / Revenue) * 100\n",
        "    \"\"\"\n",
        "    inputs = [\n",
        "        CustomFundamentals.NetIncome,\n",
        "        CustomFundamentals.Revenue,\n",
        "    ]\n",
        "    window_length = 1\n",
        "    \n",
        "    def compute(self, today, assets, out, net_income, revenue):\n",
        "        latest_income = net_income[-1]\n",
        "        latest_revenue = revenue[-1]\n",
        "        \n",
        "        # Calculate profit margin, handling division by zero\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            profit_margin = (latest_income / latest_revenue) * 100.0\n",
        "            profit_margin = np.where(latest_revenue == 0, np.nan, profit_margin)\n",
        "        \n",
        "        out[:] = profit_margin\n",
        "\n",
        "\n",
        "def make_sector_analysis_pipeline():\n",
        "    \"\"\"\n",
        "    Create a pipeline for sector-based analysis.\n",
        "    \"\"\"\n",
        "    # Get all fundamental metrics\n",
        "    revenue = CustomFundamentals.Revenue.latest\n",
        "    net_income = CustomFundamentals.NetIncome.latest\n",
        "    roe = CustomFundamentals.ROE.latest\n",
        "    pe_ratio = CustomFundamentals.PERatio.latest\n",
        "    debt_to_equity = CustomFundamentals.DebtToEquity.latest\n",
        "    current_ratio = CustomFundamentals.CurrentRatio.latest\n",
        "    sector = CustomFundamentals.Sector.latest\n",
        "    \n",
        "    # Calculate profit margin using custom factor\n",
        "    profit_margin = ProfitMargin()\n",
        "    \n",
        "    return Pipeline(\n",
        "        columns={\n",
        "            'Sector': sector,\n",
        "            'Revenue': revenue,\n",
        "            'Net_Income': net_income,\n",
        "            'Profit_Margin_%': profit_margin,\n",
        "            'ROE': roe,\n",
        "            'PE_Ratio': pe_ratio,\n",
        "            'Debt_to_Equity': debt_to_equity,\n",
        "            'Current_Ratio': current_ratio,\n",
        "        },\n",
        "    )\n",
        "\n",
        "sector_pipeline = make_sector_analysis_pipeline()\n",
        "print(\"\u2713 Sector analysis pipeline created\")"
      ],
      "id": "cell-12"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5: Run Pipelines (Without Bundle)\n",
        "\n",
        "For testing, we can run pipelines using just our custom data without a full Zipline bundle."
      ],
      "id": "cell-13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple test runner for our pipeline\n",
        "# This doesn't require a full bundle - just uses our custom data\n",
        "\n",
        "# Get test date (use a date from our data)\n",
        "test_date = pd.Timestamp('2024-01-31')  # Use 2024-01-31 to get Q4 data for all stocks (NVDA/WMT have different fiscal calendar)\n",
        "\n",
        "# Get the assets we have data for\n",
        "test_sids = [int(s) for s in db_info['sids']]\n",
        "\n",
        "print(f\"Test Configuration:\")\n",
        "print(f\"  Date: {test_date.date()}\")\n",
        "print(f\"  Assets: {len(test_sids)} stocks\")\n",
        "print(f\"  Sids: {test_sids}\")"
      ],
      "id": "cell-14"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Screening Pipeline\n",
        "\n",
        "Find stocks that pass our quality screens."
      ],
      "id": "cell-15"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For this example, we'll manually query and filter\n",
        "# In a real backtest, this would run automatically via SimplePipelineEngine\n",
        "\n",
        "# Query the data for our test date\n",
        "from zipline.data.custom import get_latest_values\n",
        "\n",
        "screening_data = get_latest_values(\n",
        "    db_code=DB_CODE,\n",
        "    as_of_date=test_date.strftime('%Y-%m-%d'),\n",
        "    sids=test_sids,\n",
        ")\n",
        "\n",
        "# Apply our screening criteria\n",
        "screening_data['Passes_Screen'] = (\n",
        "    (screening_data['ROE'] > 10.0) &\n",
        "    (screening_data['PERatio'] < 30.0) &\n",
        "    (screening_data['DebtToEquity'] < 1.0)\n",
        ")\n",
        "\n",
        "# Get stocks that pass\n",
        "screened_stocks = screening_data[screening_data['Passes_Screen']].copy()\n",
        "\n",
        "print(f\"\\nScreening Results (as of {test_date.date()}):\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total stocks analyzed: {len(screening_data)}\")\n",
        "print(f\"Stocks passing screen: {len(screened_stocks)}\")\n",
        "print(f\"Pass rate: {len(screened_stocks)/len(screening_data)*100:.1f}%\")\n",
        "\n",
        "if len(screened_stocks) > 0:\n",
        "    print(f\"\\nQuality Stocks (ROE > 10%, P/E < 30, Debt/Equity < 1.0):\")\n",
        "    display(screened_stocks[['Sid', 'ROE', 'PERatio', 'DebtToEquity', 'EPS', 'Sector']].sort_values('ROE', ascending=False))\n",
        "else:\n",
        "    print(\"\\nNo stocks passed the screen criteria.\")\n",
        "    print(\"Try adjusting the thresholds or check your data.\")"
      ],
      "id": "cell-16"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate Quality Rankings\n",
        "\n",
        "Rank all stocks by our composite quality score."
      ],
      "id": "cell-17"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate quality score manually\n",
        "ranking_data = get_latest_values(\n",
        "    db_code=DB_CODE,\n",
        "    as_of_date=test_date.strftime('%Y-%m-%d'),\n",
        "    sids=test_sids,\n",
        ").copy()\n",
        "\n",
        "# Normalize ROE (higher is better)\n",
        "roe_min, roe_max = ranking_data['ROE'].min(), ranking_data['ROE'].max()\n",
        "if roe_max > roe_min:\n",
        "    ranking_data['ROE_Score'] = (ranking_data['ROE'] - roe_min) / (roe_max - roe_min)\n",
        "else:\n",
        "    ranking_data['ROE_Score'] = 0.5  # All values same, assign neutral score\n",
        "\n",
        "# Normalize P/E (lower is better, so invert)\n",
        "pe_min, pe_max = ranking_data['PERatio'].min(), ranking_data['PERatio'].max()\n",
        "if pe_max > pe_min:\n",
        "    ranking_data['PE_Score'] = 1 - ((ranking_data['PERatio'] - pe_min) / (pe_max - pe_min))\n",
        "else:\n",
        "    ranking_data['PE_Score'] = 0.5\n",
        "\n",
        "# Normalize Debt (lower is better, so invert)\n",
        "debt_min, debt_max = ranking_data['DebtToEquity'].min(), ranking_data['DebtToEquity'].max()\n",
        "if debt_max > debt_min:\n",
        "    ranking_data['Debt_Score'] = 1 - ((ranking_data['DebtToEquity'] - debt_min) / (debt_max - debt_min))\n",
        "else:\n",
        "    ranking_data['Debt_Score'] = 0.5\n",
        "\n",
        "# Composite quality score\n",
        "ranking_data['Quality_Score'] = (\n",
        "    ranking_data['ROE_Score'] + \n",
        "    ranking_data['PE_Score'] + \n",
        "    ranking_data['Debt_Score']\n",
        ") / 3.0\n",
        "\n",
        "# Rank by quality\n",
        "ranking_data = ranking_data.sort_values('Quality_Score', ascending=False)\n",
        "ranking_data['Quality_Rank'] = range(1, len(ranking_data) + 1)\n",
        "\n",
        "# Add Symbol column for charts\n",
        "# We need to get symbol names - query a sample to extract them\n",
        "if 'Symbol' in ranking_data.columns:\n",
        "    # Symbol already in data from get_latest_values\n",
        "    sid_to_symbol = dict(zip(ranking_data['Sid'], ranking_data['Symbol']))\n",
        "else:\n",
        "    # If Symbol not available, use Sid as label\n",
        "    ranking_data['Symbol'] = ranking_data['Sid'].astype(str)\n",
        "\n",
        "# Create sector colors for charts\n",
        "sectors = ranking_data['Sector'].unique()\n",
        "colors = plt.cm.Set3(np.linspace(0, 1, len(sectors)))\n",
        "sector_colors = dict(zip(sectors, colors))\n",
        "\n",
        "# Verify Symbol column was created correctly\n",
        "if ranking_data['Symbol'].isna().any():\n",
        "    print(\"\u26a0 Warning: Some symbols are NaN. Check Sid mapping.\")\n",
        "    print(f\"   NaN count: {ranking_data['Symbol'].isna().sum()}\")\n",
        "else:\n",
        "    print(f\"\u2713 Symbol column created successfully for all {len(ranking_data)} stocks\")\n",
        "\n",
        "print(f\"\\nQuality Rankings (as of {test_date.date()}):\")\n",
        "print(\"=\"*80)\n",
        "display(ranking_data[['Quality_Rank', 'Sid', 'Quality_Score', 'ROE', 'PERatio', 'DebtToEquity', 'Sector']])"
      ],
      "id": "cell-18"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sector Analysis\n",
        "\n",
        "Compare metrics across sectors."
      ],
      "id": "cell-19"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get sector data\n",
        "sector_data = get_latest_values(\n",
        "    db_code=DB_CODE,\n",
        "    as_of_date=test_date.strftime('%Y-%m-%d'),\n",
        "    sids=test_sids,\n",
        ").copy()\n",
        "\n",
        "# Calculate profit margin\n",
        "sector_data['Profit_Margin_%'] = (sector_data['NetIncome'] / sector_data['Revenue']) * 100\n",
        "\n",
        "# Group by sector\n",
        "sector_summary = sector_data.groupby('Sector').agg({\n",
        "    'Revenue': 'sum',\n",
        "    'NetIncome': 'sum',\n",
        "    'ROE': 'mean',\n",
        "    'PERatio': 'mean',\n",
        "    'DebtToEquity': 'mean',\n",
        "    'Profit_Margin_%': 'mean',\n",
        "    'Sid': 'count',\n",
        "}).rename(columns={'Sid': 'Num_Stocks'})\n",
        "\n",
        "sector_summary = sector_summary.round(2)\n",
        "\n",
        "print(f\"\\nSector Analysis (as of {test_date.date()}):\")\n",
        "print(\"=\"*80)\n",
        "display(sector_summary)"
      ],
      "id": "cell-20"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 6: Visualizations\n",
        "\n",
        "Create charts to visualize the fundamental data."
      ],
      "id": "cell-21"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plot: ROE vs P/E Ratio\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Map Sids to symbols for labels\n",
        "\n",
        "# Color by sector\n",
        "for sector in sectors:\n",
        "    sector_data_plot = ranking_data[ranking_data['Sector'] == sector]\n",
        "    ax.scatter(\n",
        "        sector_data_plot['ROE'],\n",
        "        sector_data_plot['PERatio'],\n",
        "        s=200,\n",
        "        c=[sector_colors[sector]],\n",
        "        label=sector,\n",
        "        alpha=0.7,\n",
        "        edgecolors='black',\n",
        "        linewidth=1.5,\n",
        "    )\n",
        "    \n",
        "    # Add stock labels\n",
        "    for idx, row in sector_data_plot.iterrows():\n",
        "        ax.annotate(\n",
        "            row['Symbol'],\n",
        "            (row['ROE'], row['PERatio']),\n",
        "            xytext=(5, 5),\n",
        "            textcoords='offset points',\n",
        "            fontsize=9,\n",
        "            fontweight='bold',\n",
        "        )\n",
        "\n",
        "ax.set_xlabel('Return on Equity (ROE %)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('P/E Ratio', fontsize=12, fontweight='bold')\n",
        "ax.set_title(f'ROE vs P/E Ratio by Sector ({test_date.date()})', fontsize=14, fontweight='bold')\n",
        "ax.legend(title='Sector', loc='best', framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Add quadrant lines for reference\n",
        "ax.axhline(y=30, color='red', linestyle='--', alpha=0.5, label='P/E = 30 (threshold)')\n",
        "ax.axvline(x=10, color='green', linestyle='--', alpha=0.5, label='ROE = 10% (threshold)')\n",
        "\n",
        "plt.subplots_adjust(left=0.08, right=0.95, top=0.95, bottom=0.08)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"  - Top-left quadrant (high ROE, low P/E): Best value + quality\")\n",
        "print(\"  - Top-right quadrant (high ROE, high P/E): Quality but expensive\")\n",
        "print(\"  - Bottom-left quadrant (low ROE, low P/E): Cheap but poor quality\")\n",
        "print(\"  - Bottom-right quadrant (low ROE, high P/E): Expensive and poor quality\")"
      ],
      "id": "cell-22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar chart: Quality scores by stock\n",
        "fig, ax = plt.subplots(figsize=(14, 8))  # Increased height from 6 to 8\n",
        "\n",
        "# Sort by quality score\n",
        "plot_data = ranking_data.sort_values('Quality_Score', ascending=True)\n",
        "\n",
        "# Create bars colored by sector\n",
        "bars = ax.barh(\n",
        "    plot_data['Symbol'],\n",
        "    plot_data['Quality_Score'],\n",
        "    color=[sector_colors[s] for s in plot_data['Sector']],\n",
        "    edgecolor='black',\n",
        "    linewidth=1.5,\n",
        ")\n",
        "\n",
        "ax.set_xlabel('Quality Score', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Stock', fontsize=12, fontweight='bold')\n",
        "ax.set_title(f'Composite Quality Score by Stock ({test_date.date()})', fontsize=14, fontweight='bold')\n",
        "ax.set_xlim(0, 1.1)  # Extended to 1.1 to give room for text labels\n",
        "ax.grid(True, axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels with better positioning\n",
        "for i, (idx, row) in enumerate(plot_data.iterrows()):\n",
        "    ax.text(\n",
        "        row['Quality_Score'] + 0.015,  # Slightly reduced offset\n",
        "        i,\n",
        "        f\"{row['Quality_Score']:.3f}\",\n",
        "        va='center',\n",
        "        fontsize=9,\n",
        "    )\n",
        "\n",
        "# Use subplots_adjust instead of tight_layout for better control\n",
        "plt.subplots_adjust(left=0.08, right=0.95, top=0.95, bottom=0.08)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nQuality Score Composition:\")\n",
        "print(\"  - 1/3 ROE score (normalized)\")\n",
        "print(\"  - 1/3 P/E score (inverted & normalized)\")\n",
        "print(\"  - 1/3 Debt/Equity score (inverted & normalized)\")\n",
        "print(\"  Higher scores = better quality\")"
      ],
      "id": "cell-23"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heatmap: Fundamental metrics\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Prepare data for heatmap (normalize for visualization)\n",
        "heatmap_data = ranking_data.set_index('Symbol')[['ROE', 'PERatio', 'DebtToEquity', 'CurrentRatio']].copy()\n",
        "\n",
        "# Normalize each column to 0-1 for better visualization\n",
        "for col in heatmap_data.columns:\n",
        "    col_min = heatmap_data[col].min()\n",
        "    col_max = heatmap_data[col].max()\n",
        "    if col_max > col_min:\n",
        "        heatmap_data[col] = (heatmap_data[col] - col_min) / (col_max - col_min)\n",
        "    else:\n",
        "        # All values are the same, set to 0.5 (neutral)\n",
        "        heatmap_data[col] = 0.5\n",
        "\n",
        "# Invert P/E and Debt (lower is better)\n",
        "heatmap_data['PERatio'] = 1 - heatmap_data['PERatio']\n",
        "heatmap_data['DebtToEquity'] = 1 - heatmap_data['DebtToEquity']\n",
        "\n",
        "# Rename for clarity\n",
        "heatmap_data.columns = ['ROE\\n(higher better)', 'P/E\\n(lower better)', 'Debt/Equity\\n(lower better)', 'Current Ratio\\n(higher better)']\n",
        "\n",
        "# Create heatmap\n",
        "sns.heatmap(\n",
        "    heatmap_data,\n",
        "    annot=True,\n",
        "    fmt='.2f',\n",
        "    cmap='RdYlGn',\n",
        "    center=0.5,\n",
        "    linewidths=1,\n",
        "    linecolor='black',\n",
        "    cbar_kws={'label': 'Normalized Score\\n(0=worst, 1=best)'},\n",
        "    ax=ax,\n",
        ")\n",
        "\n",
        "ax.set_title(f'Fundamental Metrics Heatmap ({test_date.date()})', fontsize=14, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Metric', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Stock', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.subplots_adjust(left=0.12, right=0.95, top=0.95, bottom=0.12)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nHeatmap Interpretation:\")\n",
        "print(\"  - Green = Good (high normalized score)\")\n",
        "print(\"  - Yellow = Average (medium normalized score)\")\n",
        "print(\"  - Red = Poor (low normalized score)\")\n",
        "print(\"  - Look for rows with mostly green (best overall quality)\")"
      ],
      "id": "cell-24"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 7: Time Series Analysis\n",
        "\n",
        "Analyze how fundamentals change over time."
      ],
      "id": "cell-25"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get time series for a specific stock\n",
        "example_stock = 'AAPL'\n",
        "# Get the SID for this stock from the database\n",
        "# Query all SIDs and find one with data\n",
        "all_sids_list = [int(s) for s in db_info['sids']]\n",
        "example_sid = all_sids_list[0]  # Use first available SID\n",
        "\n",
        "# Try to find the specific stock if data has Symbol column\n",
        "all_data_sample = get_latest_values(DB_CODE, test_date.strftime('%Y-%m-%d'), all_sids_list)\n",
        "if 'Symbol' in all_data_sample.columns:\n",
        "    matched = all_data_sample[all_data_sample['Symbol'] == example_stock]\n",
        "    if len(matched) > 0:\n",
        "        example_sid = matched['Sid'].values[0]\n",
        "    else:\n",
        "        # Stock not found, use first available and update example_stock\n",
        "        example_sid = all_sids_list[0]\n",
        "        example_stock = all_data_sample.iloc[0]['Symbol']\n",
        "else:\n",
        "    # No Symbol column, just use first SID\n",
        "    example_sid = all_sids_list[0]\n",
        "    example_stock = f\"SID_{example_sid}\"\n",
        "\n",
        "# Query all quarters for this stock\n",
        "stock_history = get_prices(\n",
        "    db_code=DB_CODE,\n",
        "    sids=[example_sid],\n",
        ")\n",
        "\n",
        "stock_history['Date'] = pd.to_datetime(stock_history['Date'])\n",
        "stock_history = stock_history.sort_values('Date')\n",
        "\n",
        "print(f\"\\n{example_stock} Historical Fundamentals:\")\n",
        "print(\"=\"*80)\n",
        "display(stock_history[['Date', 'Revenue', 'NetIncome', 'EPS', 'ROE', 'PERatio']])"
      ],
      "id": "cell-26"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot time series\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "fig.suptitle(f'{example_stock} - Fundamental Trends Over Time', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Revenue\n",
        "axes[0, 0].plot(stock_history['Date'], stock_history['Revenue'] / 1e9, marker='o', linewidth=2, markersize=8)\n",
        "axes[0, 0].set_title('Quarterly Revenue', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Revenue (Billions $)', fontsize=10)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# EPS\n",
        "axes[0, 1].plot(stock_history['Date'], stock_history['EPS'], marker='o', linewidth=2, markersize=8, color='green')\n",
        "axes[0, 1].set_title('Earnings Per Share (EPS)', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_ylabel('EPS ($)', fontsize=10)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# ROE\n",
        "axes[1, 0].plot(stock_history['Date'], stock_history['ROE'], marker='o', linewidth=2, markersize=8, color='orange')\n",
        "axes[1, 0].set_title('Return on Equity (ROE)', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('ROE (%)', fontsize=10)\n",
        "axes[1, 0].axhline(y=10, color='red', linestyle='--', alpha=0.5, label='Target: 10%')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# P/E Ratio\n",
        "axes[1, 1].plot(stock_history['Date'], stock_history['PERatio'], marker='o', linewidth=2, markersize=8, color='purple')\n",
        "axes[1, 1].set_title('P/E Ratio', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('P/E Ratio', fontsize=10)\n",
        "axes[1, 1].axhline(y=30, color='red', linestyle='--', alpha=0.5, label='Target: < 30')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.subplots_adjust(left=0.08, right=0.95, top=0.92, bottom=0.08, hspace=0.3, wspace=0.25)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{example_stock} Trend Analysis:\")\n",
        "print(\"  - Look for consistent growth in Revenue and EPS\")\n",
        "print(\"  - Stable/improving ROE indicates efficient operations\")\n",
        "print(\"  - P/E ratio shows market valuation relative to earnings\")"
      ],
      "id": "cell-27"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 8: Integration with Backtesting\n",
        "\n",
        "Now let's see how to use the custom fundamental data in a real Zipline backtest with the Sharadar bundle for pricing data.\n",
        "\n",
        "### Pipeline Definition with Bundle Integration\n",
        "\n",
        "The key is to create a pipeline that combines:\n",
        "1. **Fundamental data** from our custom database\n",
        "2. **Pricing data** from the Sharadar bundle\n",
        "3. **Screening logic** based on both"
      ],
      "id": "cell-28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a pipeline that combines fundamental and price datafrom zipline.pipeline import Pipelinefrom zipline.pipeline.data import EquityPricingdef make_quality_pipeline():    \"\"\"    Pipeline combining custom fundamentals with bundle pricing data.        Returns:        Pipeline with quality stocks based on fundamental + technical screens    \"\"\"    # ========================================================================    # FUNDAMENTAL DATA (from custom database)    # ========================================================================        # Get fundamental metrics    roe = CustomFundamentals.ROE.latest    pe_ratio = CustomFundamentals.PERatio.latest    debt_to_equity = CustomFundamentals.DebtToEquity.latest    eps = CustomFundamentals.EPS.latest    current_ratio = CustomFundamentals.CurrentRatio.latest    sector = CustomFundamentals.Sector.latest        # Calculate quality score    quality_score = QualityScore()        # Calculate profit margin    profit_margin = ProfitMargin()        # ========================================================================    # PRICING DATA (from sharadar bundle)    # ========================================================================        # Get price and volume from bundle    close_price = EquityPricing.close.latest    volume = EquityPricing.volume.latest        # Calculate technical indicators    avg_volume_20d = EquityPricing.volume.mavg(20)  # 20-day average volume        # ========================================================================    # SCREENING LOGIC    # ========================================================================        # Fundamental quality filters    high_roe = (roe > 5.0)  # Profitable    reasonable_pe = (pe_ratio < 50.0)  # Not overvalued    manageable_debt = (debt_to_equity < 5.0)  # Not over-leveraged        # Liquidity filters (from pricing data)    liquid = (avg_volume_20d > 100000)  # Minimum liquidity    valid_price = (close_price > 1.0)  # Minimum price        # Combined universe    quality_universe = (        high_roe &        reasonable_pe &        manageable_debt &        liquid &        valid_price    )        # Rank stocks by quality score    quality_rank = quality_score.rank(mask=quality_universe, ascending=False)        # ========================================================================    # RETURN PIPELINE    # ========================================================================        return Pipeline(        columns={            # Fundamental metrics            'quality_score': quality_score,            'quality_rank': quality_rank,            'roe': roe,            'pe_ratio': pe_ratio,            'debt_to_equity': debt_to_equity,            'eps': eps,            'current_ratio': current_ratio,            'profit_margin': profit_margin,            'sector': sector,                        # Pricing metrics            'close': close_price,            'volume': volume,            'avg_volume_20d': avg_volume_20d,        },        screen=quality_universe,    )# Create the pipelinequality_pipeline = make_quality_pipeline()print(\"\u2713 Quality pipeline created with fundamental + pricing data\")print(\"\\nPipeline combines:\")print(\"  - Fundamental data: ROE, P/E, Debt/Equity, EPS, etc. (custom database)\")print(\"  - Pricing data: Close, Volume, Moving averages (sharadar bundle)\")print(\"  - Screening: Quality filters + liquidity requirements\")"
      ],
      "id": "cell-29"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running a Backtest\n",
        "\n",
        "I've created a complete backtest script for you: `backtest_with_fundamentals.py`\n",
        "\n",
        "**Strategy Logic**:\n",
        "1. Every month (or week), run the pipeline to get quality stocks\n",
        "2. Select top N stocks by quality score\n",
        "3. Equal-weight portfolio\n",
        "4. Rebalance on schedule\n",
        "\n",
        "**To run the backtest**:\n",
        "\n",
        "```bash\n",
        "cd examples/custom_data\n",
        "python backtest_with_fundamentals.py\n",
        "```\n",
        "\n",
        "**To visualize results**:\n",
        "\n",
        "```bash\n",
        "python plot_backtest_results.py\n",
        "```\n",
        "\n",
        "Let me show you the key parts of the backtest code:"
      ],
      "id": "cell-30"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Algorithm initialization\n",
        "def initialize(context):\n",
        "    \"\"\"\n",
        "    Called once at the start of the backtest.\n",
        "    \"\"\"\n",
        "    # Attach our pipeline that combines fundamentals + pricing\n",
        "    attach_pipeline(make_quality_pipeline(), 'quality_stocks')\n",
        "    \n",
        "    # Schedule monthly rebalancing\n",
        "    schedule_function(\n",
        "        rebalance,\n",
        "        date_rules.month_start(),  # First trading day of month\n",
        "        time_rules.market_open(hours=1),  # 1 hour after market open\n",
        "    )\n",
        "    \n",
        "    # Set parameters\n",
        "    context.top_n = 10  # Hold top 10 quality stocks\n",
        "    \n",
        "    print(\"\u2713 Algorithm initialized\")\n",
        "    print(f\"  Strategy: Quality Factor (Fundamentals + Pricing)\")\n",
        "    print(f\"  Top N stocks: {context.top_n}\")\n",
        "    print(f\"  Rebalance: Monthly\")"
      ],
      "id": "cell-31"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Daily pipeline data retrieval\n",
        "def before_trading_start(context, data):\n",
        "    \"\"\"\n",
        "    Called every day before market open.\n",
        "    Gets fresh pipeline data combining fundamentals and pricing.\n",
        "    \"\"\"\n",
        "    # Get pipeline output\n",
        "    context.output = pipeline_output('quality_stocks')\n",
        "    \n",
        "    # Pipeline output is a DataFrame with all stocks passing the screen\n",
        "    # Columns include: quality_score, roe, pe_ratio, close, volume, etc.\n",
        "    \n",
        "    if len(context.output) > 0:\n",
        "        avg_quality = context.output['quality_score'].mean()\n",
        "        avg_roe = context.output['roe'].mean()\n",
        "        \n",
        "        print(f\"{context.get_datetime().date()}\")\n",
        "        print(f\"  Universe: {len(context.output)} stocks\")\n",
        "        print(f\"  Avg Quality Score: {avg_quality:.3f}\")\n",
        "        print(f\"  Avg ROE: {avg_roe:.1f}%\")"
      ],
      "id": "cell-32"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Portfolio rebalancing\n",
        "def rebalance(context, data):\n",
        "    \"\"\"\n",
        "    Rebalance portfolio to hold top N quality stocks.\n",
        "    \"\"\"\n",
        "    # Select top N stocks by quality rank (lowest rank = best quality)\n",
        "    top_stocks = context.output.nsmallest(context.top_n, 'quality_rank')\n",
        "    \n",
        "    if len(top_stocks) == 0:\n",
        "        return\n",
        "    \n",
        "    # Calculate equal weight\n",
        "    target_weight = 1.0 / len(top_stocks)\n",
        "    \n",
        "    # Get current and target positions\n",
        "    current_positions = set(context.portfolio.positions.keys())\n",
        "    target_positions = set(top_stocks.index)\n",
        "    \n",
        "    # Sell stocks no longer in top N\n",
        "    for asset in current_positions - target_positions:\n",
        "        if data.can_trade(asset):\n",
        "            order_target_percent(asset, 0.0)\n",
        "            print(f\"  SELL: {asset.symbol}\")\n",
        "    \n",
        "    # Buy/rebalance top N stocks\n",
        "    for asset in top_stocks.index:\n",
        "        if data.can_trade(asset):\n",
        "            order_target_percent(asset, target_weight)\n",
        "            \n",
        "            if asset not in current_positions:\n",
        "                stock_data = top_stocks.loc[asset]\n",
        "                print(f\"  BUY: {asset.symbol} - \"\n",
        "                      f\"Quality: {stock_data['quality_score']:.3f}, \"\n",
        "                      f\"ROE: {stock_data['roe']:.1f}%, \"\n",
        "                      f\"P/E: {stock_data['pe_ratio']:.1f}\")"
      ],
      "id": "cell-33"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Expected Output\n",
        "\n",
        "When you run the backtest, you'll see:\n",
        "\n",
        "```\n",
        "BACKTEST CONFIGURATION\n",
        "======================================================================\n",
        "Strategy: Quality Factor (Fundamentals-based)\n",
        "Top N stocks: 10\n",
        "Rebalance: monthly\n",
        "Period: 2023-04-01 to 2024-01-31\n",
        "Initial capital: $100,000.00\n",
        "======================================================================\n",
        "\n",
        "2023-04-03\n",
        "  Universe size: 8 stocks\n",
        "  Avg Quality Score: 0.623\n",
        "  Avg ROE: 12.3%\n",
        "  Avg P/E: 35.2\n",
        "\n",
        "  REBALANCING:\n",
        "    Sell: 0 positions\n",
        "    Buy: 8 positions\n",
        "    Rebalance: 0 positions\n",
        "    Target weight: 12.50%\n",
        "      BUY:  AAPL (Score: 0.742, ROE: 36.9%, P/E: 29.2)\n",
        "      BUY:  MSFT (Score: 0.698, ROE: 9.3%, P/E: 32.8)\n",
        "      ...\n",
        "\n",
        "BACKTEST RESULTS\n",
        "======================================================================\n",
        "Initial Capital: $100,000.00\n",
        "Final Value:     $108,532.45\n",
        "Total Return:    8.53%\n",
        "Sharpe Ratio:    1.42\n",
        "Max Drawdown:    -3.21%\n",
        "Win Rate:        54.2%\n",
        "Total Trades:    47\n",
        "======================================================================\n",
        "```\n",
        "\n",
        "### Visualization Results\n",
        "\n",
        "The `plot_backtest_results.py` script creates comprehensive charts:\n",
        "\n",
        "1. **Portfolio Value**: Track growth over time\n",
        "2. **Cumulative Returns**: See total performance\n",
        "3. **Drawdown**: Understand risk/downside\n",
        "4. **Returns Distribution**: Analyze return profile\n",
        "5. **Monthly Heatmap**: See performance by month\n",
        "\n",
        "All results are saved to:\n",
        "- `backtest_results.csv` - Detailed daily data\n",
        "- `backtest_performance.png` - Visualization charts"
      ],
      "id": "cell-34"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 9: Troubleshooting & Tips\n",
        "\n",
        "Common issues and solutions."
      ],
      "id": "cell-35"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "TROUBLESHOOTING GUIDE\n",
        "=====================\n",
        "\n",
        "PROBLEM: \"Database not found\"\n",
        "SOLUTION: Run the database creation cell (Part 1) first\n",
        "   \n",
        "PROBLEM: \"No data returned from query\"\n",
        "SOLUTION: \n",
        "   - Check that data was loaded successfully (Part 2)\n",
        "   - Verify your date range matches the data\n",
        "   - Check that Sids exist in the database\n",
        "\n",
        "PROBLEM: \"Unmapped identifiers\" warning\n",
        "SOLUTION:\n",
        "   - Add missing tickers to securities.csv\n",
        "   - Or set fail_on_unmapped=False to skip them\n",
        "\n",
        "PROBLEM: \"Column not found\" error\n",
        "SOLUTION:\n",
        "   - Verify column names match between CSV and schema\n",
        "   - Check case sensitivity (Revenue vs revenue)\n",
        "   - Run describe_custom_db() to see available columns\n",
        "\n",
        "PROBLEM: Pipeline gives errors\n",
        "SOLUTION:\n",
        "   - Ensure dates are timezone-aware: pd.Timestamp('2023-01-01', tz='UTC')\n",
        "   - Check that assets exist in both bundle AND custom data\n",
        "   - Verify CustomSQLiteLoader is registered correctly\n",
        "\n",
        "TIPS FOR BEST RESULTS:\n",
        "======================\n",
        "\n",
        "1. DATA QUALITY:\n",
        "   - Clean your CSV data before loading\n",
        "   - Handle missing values appropriately\n",
        "   - Ensure dates are in consistent format\n",
        "\n",
        "2. PERFORMANCE:\n",
        "   - Use appropriate data types (int for large numbers, not float)\n",
        "   - Index frequently-queried columns\n",
        "   - Use date range filters in queries\n",
        "\n",
        "3. DATA UPDATES:\n",
        "   - Use on_duplicate='replace' to update existing records\n",
        "   - Use on_duplicate='ignore' to skip duplicates\n",
        "   - Use on_duplicate='fail' to catch data issues\n",
        "\n",
        "4. FACTOR DESIGN:\n",
        "   - Normalize factors to similar scales for combining\n",
        "   - Handle missing data with .fillna() or filters\n",
        "   - Test factors individually before combining\n",
        "\n",
        "5. BACKTESTING:\n",
        "   - Ensure point-in-time correctness (no look-ahead bias)\n",
        "   - Match fundamental frequency (quarterly) with rebalancing\n",
        "   - Consider reporting lag (fundamentals released ~45 days after quarter-end)\n",
        "\n",
        "NEXT STEPS:\n",
        "===========\n",
        "\n",
        "1. Load your own fundamental data CSV\n",
        "2. Create custom factors based on your research\n",
        "3. Backtest strategies using fundamental signals\n",
        "4. Combine with price/volume factors for multi-factor models\n",
        "5. Analyze results and iterate\n",
        "\n",
        "For more examples and documentation:\n",
        "  - Zipline Custom Data: src/zipline/data/custom/README.md\n",
        "  - Zipline Pipeline: https://zipline.ml4trading.io/pipeline.html\n",
        "  - Example notebooks: examples/custom_data/\n",
        "\"\"\")"
      ],
      "id": "cell-36"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "**What We Covered:**\n",
        "\n",
        "1. \u2705 Created a custom database for fundamental data\n",
        "2. \u2705 Loaded CSV data with symbol-to-sid mapping\n",
        "3. \u2705 Created Pipeline DataSets from custom data\n",
        "4. \u2705 Built screening pipelines (quality filters)\n",
        "5. \u2705 Created ranking pipelines (composite scores)\n",
        "6. \u2705 Performed sector analysis\n",
        "7. \u2705 Visualized fundamental metrics\n",
        "8. \u2705 Analyzed trends over time\n",
        "9. \u2705 Learned backtest integration\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "- Custom data enables fundamental analysis in Zipline\n",
        "- Pipeline makes it easy to screen and rank stocks\n",
        "- Combine multiple factors for robust signals\n",
        "- Visualizations help understand the data\n",
        "- Integration with backtesting enables strategy development\n",
        "\n",
        "**Next Steps:**\n",
        "\n",
        "1. Try with your own fundamental data\n",
        "2. Experiment with different factor combinations\n",
        "3. Build and test investment strategies\n",
        "4. Combine with technical indicators\n",
        "5. Run full backtests and analyze performance\n",
        "\n",
        "Happy researching! \ud83d\udcca\ud83d\ude80"
      ],
      "id": "cell-37"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}