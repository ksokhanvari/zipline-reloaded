{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Pipeline with Custom Fundamental Data\n",
    "\n",
    "This notebook demonstrates how to load custom fundamental data from CSV files and use it in Zipline Pipeline for quantitative research and stock screening.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Setup**: Creating a custom data database for fundamentals\n",
    "2. **Loading Data**: Importing CSV data with symbol-to-sid mapping\n",
    "3. **Pipeline Basics**: Creating DataSets from your custom data\n",
    "4. **Factor Analysis**: Building factors from fundamental metrics\n",
    "5. **Screening**: Filtering stocks based on fundamental criteria\n",
    "6. **Ranking**: Scoring and ranking stocks for investment decisions\n",
    "7. **Integration**: Combining fundamentals with price data\n",
    "8. **Visualization**: Analyzing results with charts\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "- **Value Investing**: Screen for low P/E, high ROE stocks\n",
    "- **Quality Analysis**: Identify companies with strong fundamentals\n",
    "- **Sector Rotation**: Compare metrics across sectors\n",
    "- **Factor Research**: Test custom factors based on fundamentals\n",
    "- **Portfolio Construction**: Build portfolios using fundamental signals\n",
    "\n",
    "## Data Requirements\n",
    "\n",
    "You'll need two CSV files:\n",
    "\n",
    "1. **Fundamentals CSV** (`sample_fundamentals.csv`): Your fundamental data\n",
    "   - Required: `Ticker`, `Date` columns\n",
    "   - Data columns: Any metrics you want (Revenue, EPS, ROE, etc.)\n",
    "\n",
    "2. **Securities CSV** (`sample_securities.csv`): Symbol-to-Sid mapping\n",
    "   - Required: `Symbol`, `Sid` columns\n",
    "   - Optional: `Name`, `Exchange`, `Sector` for reference\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Database Creation\n",
    "\n",
    "First, we'll import the necessary modules and create a database for our fundamental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import Zipline custom data module\n",
    "from zipline.data.custom import (\n",
    "    create_custom_db,\n",
    "    load_csv_to_db,\n",
    "    describe_custom_db,\n",
    "    list_custom_dbs,\n",
    "    get_prices,\n",
    "    make_custom_dataset_class,\n",
    "    CustomSQLiteLoader,\n",
    ")\n",
    "\n",
    "# Import Zipline Pipeline\n",
    "from zipline.pipeline import Pipeline, CustomFactor\n",
    "from zipline.pipeline.data import EquityPricing\n",
    "from zipline.pipeline.factors import SimpleMovingAverage, Returns\n",
    "from zipline.pipeline.filters import StaticAssets\n",
    "from zipline.pipeline.engine import SimplePipelineEngine\n",
    "from zipline.data.bundles import load as load_bundle\n",
    "from zipline.utils.calendar_utils import get_calendar\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\u2713 Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Fundamental Data Schema\n",
    "\n",
    "Specify the columns in your fundamental data and their types:\n",
    "- `int`: Integer values (e.g., shares outstanding)\n",
    "- `float`: Decimal values (e.g., ratios, percentages)\n",
    "- `text`: String values (e.g., sector names)\n",
    "- `date`: Date values\n",
    "- `datetime`: Timestamp values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for our fundamental data\n",
    "# This should match the columns in your CSV file (excluding Ticker and Date)\n",
    "\n",
    "fundamental_columns = {\n",
    "    # Income Statement\n",
    "    'Revenue': 'int',\n",
    "    'NetIncome': 'int',\n",
    "    \n",
    "    # Balance Sheet\n",
    "    'TotalAssets': 'int',\n",
    "    'TotalEquity': 'int',\n",
    "    'SharesOutstanding': 'int',\n",
    "    \n",
    "    # Per-Share Metrics\n",
    "    'EPS': 'float',\n",
    "    'BookValuePerShare': 'float',\n",
    "    \n",
    "    # Financial Ratios\n",
    "    'ROE': 'float',              # Return on Equity\n",
    "    'DebtToEquity': 'float',     # Debt/Equity ratio\n",
    "    'CurrentRatio': 'float',     # Current Assets/Current Liabilities\n",
    "    'PERatio': 'float',          # Price-to-Earnings ratio\n",
    "    \n",
    "    # Metadata\n",
    "    'Sector': 'text',\n",
    "}\n",
    "\n",
    "print(\"Schema defined with {} columns:\".format(len(fundamental_columns)))\n",
    "for col, dtype in fundamental_columns.items():\n",
    "    print(f\"  - {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Database\n",
    "\n",
    "Create a SQLite database to store our fundamental data. This is a one-time operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration\n",
    "DB_CODE = 'fundamentals'      # Database identifier\n",
    "BAR_SIZE = '1 quarter'        # Data frequency (quarterly fundamentals)\n",
    "\n",
    "# Create the database\n",
    "try:\n",
    "    db_path = create_custom_db(\n",
    "        db_code=DB_CODE,\n",
    "        bar_size=BAR_SIZE,\n",
    "        columns=fundamental_columns,\n",
    "    )\n",
    "    print(f\"\u2713 Database created: {db_path}\")\n",
    "except FileExistsError:\n",
    "    print(f\"\u2139 Database '{DB_CODE}' already exists, will use existing database\")\n",
    "    # Get the database path\n",
    "    from zipline.data.custom.config import get_custom_data_dir, get_db_filename\n",
    "    db_path = get_custom_data_dir() / get_db_filename(DB_CODE)\n",
    "    print(f\"  Location: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Load Data from CSV\n",
    "\n",
    "Now we'll load our fundamental data from CSV files into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the Data Files\n",
    "\n",
    "Let's first look at what our CSV files contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths (adjust these to your actual file locations)\n",
    "FUNDAMENTALS_CSV = 'sample_fundamentals.csv'\n",
    "SECURITIES_CSV = 'sample_securities.csv'\n",
    "\n",
    "# Preview fundamentals data\n",
    "fundamentals_df = pd.read_csv(FUNDAMENTALS_CSV)\n",
    "print(\"Fundamentals Data Preview:\")\n",
    "print(f\"  Shape: {fundamentals_df.shape} (rows, columns)\")\n",
    "print(f\"  Date range: {fundamentals_df['Date'].min()} to {fundamentals_df['Date'].max()}\")\n",
    "print(f\"  Unique tickers: {fundamentals_df['Ticker'].nunique()}\")\n",
    "print(f\"  Tickers: {', '.join(sorted(fundamentals_df['Ticker'].unique()))}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(fundamentals_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview securities mapping\n",
    "securities_df = pd.read_csv(SECURITIES_CSV)\n",
    "print(\"Securities Mapping Preview:\")\n",
    "print(f\"  {len(securities_df)} securities mapped\")\n",
    "print(\"\\nAll securities:\")\n",
    "display(securities_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV into Database\n",
    "\n",
    "This loads the CSV data into the database, mapping ticker symbols to Zipline's internal asset IDs (Sids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "result = load_csv_to_db(\n",
    "    csv_path=FUNDAMENTALS_CSV,\n",
    "    db_code=DB_CODE,\n",
    "    sid_map=securities_df,       # DataFrame with Symbol and Sid columns\n",
    "    id_col='Ticker',              # Column name for ticker in fundamentals CSV\n",
    "    date_col='Date',              # Column name for dates\n",
    "    on_duplicate='replace',       # Replace existing records on conflict\n",
    "    fail_on_unmapped=False,       # Skip tickers not in securities_df\n",
    ")\n",
    "\n",
    "# Report results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA LOADING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\u2713 Rows inserted/updated: {result['rows_inserted']:,}\")\n",
    "print(f\"  Rows skipped: {result['rows_skipped']:,}\")\n",
    "\n",
    "if result['unmapped_ids']:\n",
    "    print(f\"\\n\u26a0 Warning: {len(result['unmapped_ids'])} ticker(s) not mapped:\")\n",
    "    for ticker in result['unmapped_ids']:\n",
    "        print(f\"  - {ticker}\")\n",
    "    print(\"\\n  Add these to your securities.csv file if needed.\")\n",
    "\n",
    "if result['errors']:\n",
    "    print(f\"\\n\u26a0 Errors encountered: {len(result['errors'])}\")\n",
    "    for error in result['errors'][:5]:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "print(\"\\n\u2713 Data loading complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the Database\n",
    "\n",
    "Let's check what's in the database now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get database information\n",
    "db_info = describe_custom_db(DB_CODE)\n",
    "\n",
    "print(\"\\nDatabase Information:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Database: {db_info['db_code']}\")\n",
    "print(f\"Location: {db_info['db_path']}\")\n",
    "print(f\"Frequency: {db_info['bar_size']}\")\n",
    "print(f\"\\nData Statistics:\")\n",
    "print(f\"  Total rows: {db_info['row_count']:,}\")\n",
    "print(f\"  Unique assets (Sids): {db_info['num_sids']}\")\n",
    "if db_info['date_range']:\n",
    "    print(f\"  Date range: {db_info['date_range'][0]} to {db_info['date_range'][1]}\")\n",
    "\n",
    "print(f\"\\nColumns ({len(db_info['columns'])}):\")\n",
    "for col, dtype in db_info['columns'].items():\n",
    "    print(f\"  - {col}: {dtype}\")\n",
    "\n",
    "if db_info['sids']:\n",
    "    print(f\"\\nAsset IDs (Sids):\")\n",
    "    print(f\"  {', '.join(map(str, sorted([int(s) for s in db_info['sids']])))}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Data Directly\n",
    "\n",
    "Before using Pipeline, let's query the data directly to see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query all data\n",
    "all_data = get_prices(\n",
    "    db_code=DB_CODE,\n",
    "    fields=['Revenue', 'NetIncome', 'EPS', 'ROE', 'PERatio', 'Sector']\n",
    ")\n",
    "\n",
    "print(f\"Retrieved {len(all_data):,} records\")\n",
    "print(\"\\nSample data:\")\n",
    "display(all_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(\"=\"*60)\n",
    "display(all_data[['Revenue', 'NetIncome', 'EPS', 'ROE', 'PERatio']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Create Pipeline DataSet\n",
    "\n",
    "Now we'll create a Zipline Pipeline DataSet from our custom data. This allows us to use the data in Pipeline computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataSet class from our database\n",
    "Fundamentals = make_custom_dataset_class(\n",
    "    db_code=DB_CODE,\n",
    "    columns=fundamental_columns,\n",
    "    base_name='Fundamentals',  # This will create 'FundamentalsDataSet'\n",
    ")\n",
    "\n",
    "print(\"\u2713 DataSet class created: FundamentalsDataSet\")\n",
    "print(\"\\nAvailable columns (as Pipeline factors):\")\n",
    "for col in fundamental_columns.keys():\n",
    "    print(f\"  - Fundamentals.{col}\")\n",
    "    \n",
    "print(\"\\nYou can now use these in Pipeline like:\")\n",
    "print(\"  Fundamentals.Revenue.latest\")\n",
    "print(\"  Fundamentals.ROE.latest\")\n",
    "print(\"  Fundamentals.PERatio.latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Simple Pipeline Examples\n",
    "\n",
    "Let's create some simple pipelines to screen and rank stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Basic Screening\n",
    "\n",
    "Screen for stocks with:\n",
    "- High ROE (> 10%)\n",
    "- Low P/E ratio (< 30)\n",
    "- Low debt (Debt/Equity < 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple screening pipeline\n",
    "def make_screening_pipeline():\n",
    "    \"\"\"\n",
    "    Create a pipeline that screens for quality stocks.\n",
    "    \n",
    "    Criteria:\n",
    "    - ROE > 10% (profitable and efficient)\n",
    "    - P/E < 30 (reasonably valued)\n",
    "    - Debt/Equity < 1.0 (not over-leveraged)\n",
    "    \"\"\"\n",
    "    # Get the latest fundamental values\n",
    "    roe = Fundamentals.ROE.latest\n",
    "    pe_ratio = Fundamentals.PERatio.latest\n",
    "    debt_to_equity = Fundamentals.DebtToEquity.latest\n",
    "    eps = Fundamentals.EPS.latest\n",
    "    revenue = Fundamentals.Revenue.latest\n",
    "    sector = Fundamentals.Sector.latest\n",
    "    \n",
    "    # Define screening filters\n",
    "    high_roe = (roe > 10.0)\n",
    "    reasonable_pe = (pe_ratio < 30.0)\n",
    "    low_debt = (debt_to_equity < 1.0)\n",
    "    \n",
    "    # Combine filters\n",
    "    quality_screen = high_roe & reasonable_pe & low_debt\n",
    "    \n",
    "    # Create pipeline\n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            'ROE': roe,\n",
    "            'PE_Ratio': pe_ratio,\n",
    "            'Debt_to_Equity': debt_to_equity,\n",
    "            'EPS': eps,\n",
    "            'Revenue': revenue,\n",
    "            'Sector': sector,\n",
    "        },\n",
    "        screen=quality_screen,  # Only return stocks passing the screen\n",
    "    )\n",
    "\n",
    "screening_pipeline = make_screening_pipeline()\n",
    "print(\"\u2713 Screening pipeline created\")\n",
    "print(\"  Filters: ROE > 10%, P/E < 30, Debt/Equity < 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Ranking Pipeline\n",
    "\n",
    "Rank stocks by a composite quality score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom factor for quality score\n",
    "class QualityScore(CustomFactor):\n",
    "    \"\"\"\n",
    "    Composite quality score based on:\n",
    "    - ROE (higher is better)\n",
    "    - P/E ratio (lower is better)\n",
    "    - Debt/Equity (lower is better)\n",
    "    \n",
    "    Returns a normalized score where higher = better quality.\n",
    "    \"\"\"\n",
    "    inputs = [\n",
    "        Fundamentals.ROE,\n",
    "        Fundamentals.PERatio,\n",
    "        Fundamentals.DebtToEquity,\n",
    "    ]\n",
    "    window_length = 1  # Only need latest value\n",
    "    \n",
    "    def compute(self, today, assets, out, roe, pe, debt):\n",
    "        # Get latest values (window_length=1, so just index 0)\n",
    "        roe_latest = roe[0]\n",
    "        pe_latest = pe[0]\n",
    "        debt_latest = debt[0]\n",
    "        \n",
    "        # Normalize each metric to 0-1 scale using percentile rank\n",
    "        # ROE: higher is better\n",
    "        roe_score = (roe_latest - np.nanmin(roe_latest)) / (np.nanmax(roe_latest) - np.nanmin(roe_latest))\n",
    "        \n",
    "        # P/E: lower is better, so invert\n",
    "        pe_score = 1 - ((pe_latest - np.nanmin(pe_latest)) / (np.nanmax(pe_latest) - np.nanmin(pe_latest)))\n",
    "        \n",
    "        # Debt: lower is better, so invert\n",
    "        debt_score = 1 - ((debt_latest - np.nanmin(debt_latest)) / (np.nanmax(debt_latest) - np.nanmin(debt_latest)))\n",
    "        \n",
    "        # Composite score (equal weights)\n",
    "        out[:] = (roe_score + pe_score + debt_score) / 3.0\n",
    "\n",
    "\n",
    "def make_ranking_pipeline():\n",
    "    \"\"\"\n",
    "    Create a pipeline that ranks stocks by quality score.\n",
    "    \"\"\"\n",
    "    # Calculate quality score\n",
    "    quality = QualityScore()\n",
    "    \n",
    "    # Get fundamentals\n",
    "    roe = Fundamentals.ROE.latest\n",
    "    pe_ratio = Fundamentals.PERatio.latest\n",
    "    debt_to_equity = Fundamentals.DebtToEquity.latest\n",
    "    eps = Fundamentals.EPS.latest\n",
    "    sector = Fundamentals.Sector.latest\n",
    "    \n",
    "    # Rank by quality score\n",
    "    quality_rank = quality.rank(ascending=False)  # 1 = best\n",
    "    \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            'Quality_Score': quality,\n",
    "            'Quality_Rank': quality_rank,\n",
    "            'ROE': roe,\n",
    "            'PE_Ratio': pe_ratio,\n",
    "            'Debt_to_Equity': debt_to_equity,\n",
    "            'EPS': eps,\n",
    "            'Sector': sector,\n",
    "        },\n",
    "    )\n",
    "\n",
    "ranking_pipeline = make_ranking_pipeline()\n",
    "print(\"\u2713 Ranking pipeline created\")\n",
    "print(\"  Ranks stocks by composite quality score (ROE, P/E, Debt)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Sector Analysis Pipeline\n",
    "\n",
    "Compare metrics across sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sector_analysis_pipeline():\n",
    "    \"\"\"\n",
    "    Create a pipeline for sector-based analysis.\n",
    "    \"\"\"\n",
    "    # Get all fundamental metrics\n",
    "    revenue = Fundamentals.Revenue.latest\n",
    "    net_income = Fundamentals.NetIncome.latest\n",
    "    roe = Fundamentals.ROE.latest\n",
    "    pe_ratio = Fundamentals.PERatio.latest\n",
    "    debt_to_equity = Fundamentals.DebtToEquity.latest\n",
    "    current_ratio = Fundamentals.CurrentRatio.latest\n",
    "    sector = Fundamentals.Sector.latest\n",
    "    \n",
    "    # Calculate profit margin\n",
    "    profit_margin = (net_income / revenue) * 100.0\n",
    "    \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            'Sector': sector,\n",
    "            'Revenue': revenue,\n",
    "            'Net_Income': net_income,\n",
    "            'Profit_Margin_%': profit_margin,\n",
    "            'ROE': roe,\n",
    "            'PE_Ratio': pe_ratio,\n",
    "            'Debt_to_Equity': debt_to_equity,\n",
    "            'Current_Ratio': current_ratio,\n",
    "        },\n",
    "    )\n",
    "\n",
    "sector_pipeline = make_sector_analysis_pipeline()\n",
    "print(\"\u2713 Sector analysis pipeline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Run Pipelines (Without Bundle)\n",
    "\n",
    "For testing, we can run pipelines using just our custom data without a full Zipline bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test runner for our pipeline\n",
    "# This doesn't require a full bundle - just uses our custom data\n",
    "\n",
    "# Get test date (use a date from our data)\n",
    "test_date = pd.Timestamp('2023-12-31')\n",
    "\n",
    "# Get the assets we have data for\n",
    "test_sids = [int(s) for s in db_info['sids']]\n",
    "\n",
    "print(f\"Test Configuration:\")\n",
    "print(f\"  Date: {test_date.date()}\")\n",
    "print(f\"  Assets: {len(test_sids)} stocks\")\n",
    "print(f\"  Sids: {test_sids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Screening Pipeline\n",
    "\n",
    "Find stocks that pass our quality screens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, we'll manually query and filter\n",
    "# In a real backtest, this would run automatically via SimplePipelineEngine\n",
    "\n",
    "# Query the data for our test date\n",
    "from zipline.data.custom import get_latest_values\n",
    "\n",
    "screening_data = get_latest_values(\n",
    "    db_code=DB_CODE,\n",
    "    as_of_date=test_date.strftime('%Y-%m-%d'),\n",
    "    sids=test_sids,\n",
    ")\n",
    "\n",
    "# Apply our screening criteria\n",
    "screening_data['Passes_Screen'] = (\n",
    "    (screening_data['ROE'] > 10.0) &\n",
    "    (screening_data['PERatio'] < 30.0) &\n",
    "    (screening_data['DebtToEquity'] < 1.0)\n",
    ")\n",
    "\n",
    "# Get stocks that pass\n",
    "screened_stocks = screening_data[screening_data['Passes_Screen']].copy()\n",
    "\n",
    "print(f\"\\nScreening Results (as of {test_date.date()}):\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total stocks analyzed: {len(screening_data)}\")\n",
    "print(f\"Stocks passing screen: {len(screened_stocks)}\")\n",
    "print(f\"Pass rate: {len(screened_stocks)/len(screening_data)*100:.1f}%\")\n",
    "\n",
    "if len(screened_stocks) > 0:\n",
    "    print(f\"\\nQuality Stocks (ROE > 10%, P/E < 30, Debt/Equity < 1.0):\")\n",
    "    display(screened_stocks[['Sid', 'ROE', 'PERatio', 'DebtToEquity', 'EPS', 'Sector']].sort_values('ROE', ascending=False))\n",
    "else:\n",
    "    print(\"\\nNo stocks passed the screen criteria.\")\n",
    "    print(\"Try adjusting the thresholds or check your data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Quality Rankings\n",
    "\n",
    "Rank all stocks by our composite quality score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quality score manually\n",
    "ranking_data = get_latest_values(\n",
    "    db_code=DB_CODE,\n",
    "    as_of_date=test_date.strftime('%Y-%m-%d'),\n",
    "    sids=test_sids,\n",
    ").copy()\n",
    "\n",
    "# Normalize ROE (higher is better)\n",
    "roe_min, roe_max = ranking_data['ROE'].min(), ranking_data['ROE'].max()\n",
    "ranking_data['ROE_Score'] = (ranking_data['ROE'] - roe_min) / (roe_max - roe_min)\n",
    "\n",
    "# Normalize P/E (lower is better, so invert)\n",
    "pe_min, pe_max = ranking_data['PERatio'].min(), ranking_data['PERatio'].max()\n",
    "ranking_data['PE_Score'] = 1 - ((ranking_data['PERatio'] - pe_min) / (pe_max - pe_min))\n",
    "\n",
    "# Normalize Debt (lower is better, so invert)\n",
    "debt_min, debt_max = ranking_data['DebtToEquity'].min(), ranking_data['DebtToEquity'].max()\n",
    "ranking_data['Debt_Score'] = 1 - ((ranking_data['DebtToEquity'] - debt_min) / (debt_max - debt_min))\n",
    "\n",
    "# Composite quality score\n",
    "ranking_data['Quality_Score'] = (\n",
    "    ranking_data['ROE_Score'] + \n",
    "    ranking_data['PE_Score'] + \n",
    "    ranking_data['Debt_Score']\n",
    ") / 3.0\n",
    "\n",
    "# Rank by quality\n",
    "ranking_data = ranking_data.sort_values('Quality_Score', ascending=False)\n",
    "ranking_data['Quality_Rank'] = range(1, len(ranking_data) + 1)\n",
    "\n",
    "print(f\"\\nQuality Rankings (as of {test_date.date()}):\")\n",
    "print(\"=\"*80)\n",
    "display(ranking_data[['Quality_Rank', 'Sid', 'Quality_Score', 'ROE', 'PERatio', 'DebtToEquity', 'Sector']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector Analysis\n",
    "\n",
    "Compare metrics across sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sector data\n",
    "sector_data = get_latest_values(\n",
    "    db_code=DB_CODE,\n",
    "    as_of_date=test_date.strftime('%Y-%m-%d'),\n",
    "    sids=test_sids,\n",
    ").copy()\n",
    "\n",
    "# Calculate profit margin\n",
    "sector_data['Profit_Margin_%'] = (sector_data['NetIncome'] / sector_data['Revenue']) * 100\n",
    "\n",
    "# Group by sector\n",
    "sector_summary = sector_data.groupby('Sector').agg({\n",
    "    'Revenue': 'sum',\n",
    "    'NetIncome': 'sum',\n",
    "    'ROE': 'mean',\n",
    "    'PERatio': 'mean',\n",
    "    'DebtToEquity': 'mean',\n",
    "    'Profit_Margin_%': 'mean',\n",
    "    'Sid': 'count',\n",
    "}).rename(columns={'Sid': 'Num_Stocks'})\n",
    "\n",
    "sector_summary = sector_summary.round(2)\n",
    "\n",
    "print(f\"\\nSector Analysis (as of {test_date.date()}):\")\n",
    "print(\"=\"*80)\n",
    "display(sector_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Visualizations\n",
    "\n",
    "Create charts to visualize the fundamental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: ROE vs P/E Ratio\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Map Sids to symbols for labels\n",
    "sid_to_symbol = dict(zip(securities_df['Sid'], securities_df['Ticker']))\n",
    "ranking_data['Symbol'] = ranking_data['Sid'].map(sid_to_symbol)\n",
    "\n",
    "# Color by sector\n",
    "sectors = ranking_data['Sector'].unique()\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(sectors)))\n",
    "sector_colors = dict(zip(sectors, colors))\n",
    "\n",
    "for sector in sectors:\n",
    "    sector_data_plot = ranking_data[ranking_data['Sector'] == sector]\n",
    "    ax.scatter(\n",
    "        sector_data_plot['ROE'],\n",
    "        sector_data_plot['PERatio'],\n",
    "        s=200,\n",
    "        c=[sector_colors[sector]],\n",
    "        label=sector,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black',\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "    \n",
    "    # Add stock labels\n",
    "    for idx, row in sector_data_plot.iterrows():\n",
    "        ax.annotate(\n",
    "            row['Symbol'],\n",
    "            (row['ROE'], row['PERatio']),\n",
    "            xytext=(5, 5),\n",
    "            textcoords='offset points',\n",
    "            fontsize=9,\n",
    "            fontweight='bold',\n",
    "        )\n",
    "\n",
    "ax.set_xlabel('Return on Equity (ROE %)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('P/E Ratio', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'ROE vs P/E Ratio by Sector ({test_date.date()})', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Sector', loc='best', framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add quadrant lines for reference\n",
    "ax.axhline(y=30, color='red', linestyle='--', alpha=0.5, label='P/E = 30 (threshold)')\n",
    "ax.axvline(x=10, color='green', linestyle='--', alpha=0.5, label='ROE = 10% (threshold)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Top-left quadrant (high ROE, low P/E): Best value + quality\")\n",
    "print(\"  - Top-right quadrant (high ROE, high P/E): Quality but expensive\")\n",
    "print(\"  - Bottom-left quadrant (low ROE, low P/E): Cheap but poor quality\")\n",
    "print(\"  - Bottom-right quadrant (low ROE, high P/E): Expensive and poor quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: Quality scores by stock\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Sort by quality score\n",
    "plot_data = ranking_data.sort_values('Quality_Score', ascending=True)\n",
    "\n",
    "# Create bars colored by sector\n",
    "bars = ax.barh(\n",
    "    plot_data['Symbol'],\n",
    "    plot_data['Quality_Score'],\n",
    "    color=[sector_colors[s] for s in plot_data['Sector']],\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Quality Score', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Stock', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Composite Quality Score by Stock ({test_date.date()})', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1.0)\n",
    "ax.grid(True, axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(plot_data.iterrows()):\n",
    "    ax.text(\n",
    "        row['Quality_Score'] + 0.02,\n",
    "        i,\n",
    "        f\"{row['Quality_Score']:.3f}\",\n",
    "        va='center',\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nQuality Score Composition:\")\n",
    "print(\"  - 1/3 ROE score (normalized)\")\n",
    "print(\"  - 1/3 P/E score (inverted & normalized)\")\n",
    "print(\"  - 1/3 Debt/Equity score (inverted & normalized)\")\n",
    "print(\"  Higher scores = better quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: Fundamental metrics\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Prepare data for heatmap (normalize for visualization)\n",
    "heatmap_data = ranking_data.set_index('Symbol')[['ROE', 'PERatio', 'DebtToEquity', 'CurrentRatio']].copy()\n",
    "\n",
    "# Normalize each column to 0-1 for better visualization\n",
    "for col in heatmap_data.columns:\n",
    "    col_min = heatmap_data[col].min()\n",
    "    col_max = heatmap_data[col].max()\n",
    "    heatmap_data[col] = (heatmap_data[col] - col_min) / (col_max - col_min)\n",
    "\n",
    "# Invert P/E and Debt (lower is better)\n",
    "heatmap_data['PERatio'] = 1 - heatmap_data['PERatio']\n",
    "heatmap_data['DebtToEquity'] = 1 - heatmap_data['DebtToEquity']\n",
    "\n",
    "# Rename for clarity\n",
    "heatmap_data.columns = ['ROE\\n(higher better)', 'P/E\\n(lower better)', 'Debt/Equity\\n(lower better)', 'Current Ratio\\n(higher better)']\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='RdYlGn',\n",
    "    center=0.5,\n",
    "    linewidths=1,\n",
    "    linecolor='black',\n",
    "    cbar_kws={'label': 'Normalized Score\\n(0=worst, 1=best)'},\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(f'Fundamental Metrics Heatmap ({test_date.date()})', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Metric', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Stock', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHeatmap Interpretation:\")\n",
    "print(\"  - Green = Good (high normalized score)\")\n",
    "print(\"  - Yellow = Average (medium normalized score)\")\n",
    "print(\"  - Red = Poor (low normalized score)\")\n",
    "print(\"  - Look for rows with mostly green (best overall quality)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Time Series Analysis\n",
    "\n",
    "Analyze how fundamentals change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time series for a specific stock\n",
    "example_stock = 'AAPL'\n",
    "example_sid = securities_df[securities_df['Symbol'] == example_stock]['Sid'].values[0]\n",
    "\n",
    "# Query all quarters for this stock\n",
    "stock_history = get_prices(\n",
    "    db_code=DB_CODE,\n",
    "    sids=[example_sid],\n",
    ")\n",
    "\n",
    "stock_history['Date'] = pd.to_datetime(stock_history['Date'])\n",
    "stock_history = stock_history.sort_values('Date')\n",
    "\n",
    "print(f\"\\n{example_stock} Historical Fundamentals:\")\n",
    "print(\"=\"*80)\n",
    "display(stock_history[['Date', 'Revenue', 'NetIncome', 'EPS', 'ROE', 'PERatio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle(f'{example_stock} - Fundamental Trends Over Time', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Revenue\n",
    "axes[0, 0].plot(stock_history['Date'], stock_history['Revenue'] / 1e9, marker='o', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_title('Quarterly Revenue', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Revenue (Billions $)', fontsize=10)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# EPS\n",
    "axes[0, 1].plot(stock_history['Date'], stock_history['EPS'], marker='o', linewidth=2, markersize=8, color='green')\n",
    "axes[0, 1].set_title('Earnings Per Share (EPS)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('EPS ($)', fontsize=10)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ROE\n",
    "axes[1, 0].plot(stock_history['Date'], stock_history['ROE'], marker='o', linewidth=2, markersize=8, color='orange')\n",
    "axes[1, 0].set_title('Return on Equity (ROE)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('ROE (%)', fontsize=10)\n",
    "axes[1, 0].axhline(y=10, color='red', linestyle='--', alpha=0.5, label='Target: 10%')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# P/E Ratio\n",
    "axes[1, 1].plot(stock_history['Date'], stock_history['PERatio'], marker='o', linewidth=2, markersize=8, color='purple')\n",
    "axes[1, 1].set_title('P/E Ratio', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('P/E Ratio', fontsize=10)\n",
    "axes[1, 1].axhline(y=30, color='red', linestyle='--', alpha=0.5, label='Target: < 30')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{example_stock} Trend Analysis:\")\n",
    "print(\"  - Look for consistent growth in Revenue and EPS\")\n",
    "print(\"  - Stable/improving ROE indicates efficient operations\")\n",
    "print(\"  - P/E ratio shows market valuation relative to earnings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Integration with Backtesting\n",
    "\n",
    "Example of how to use fundamental data in a Zipline backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "INTEGRATION WITH ZIPLINE BACKTESTS\n",
    "===================================\n",
    "\n",
    "To use this custom fundamental data in a backtest:\n",
    "\n",
    "1. CREATE A PIPELINE LOADER:\n",
    "   \n",
    "   from zipline.data.custom import CustomSQLiteLoader\n",
    "   \n",
    "   fundamentals_loader = CustomSQLiteLoader('fundamentals')\n",
    "\n",
    "2. REGISTER WITH PIPELINE ENGINE:\n",
    "   \n",
    "   from zipline.pipeline.engine import SimplePipelineEngine\n",
    "   from zipline.data.bundles import load\n",
    "   \n",
    "   bundle_data = load('sharadar')  # Or your bundle\n",
    "   \n",
    "   engine = SimplePipelineEngine(\n",
    "       get_loader=lambda column: fundamentals_loader if column.dataset == Fundamentals else bundle_data.equity_daily_bar_reader,\n",
    "       asset_finder=bundle_data.asset_finder,\n",
    "       default_domain=...,\n",
    "   )\n",
    "\n",
    "3. USE IN YOUR ALGORITHM:\n",
    "   \n",
    "   def initialize(context):\n",
    "       # Define your pipeline with fundamental factors\n",
    "       pipe = Pipeline(\n",
    "           columns={\n",
    "               'roe': Fundamentals.ROE.latest,\n",
    "               'pe': Fundamentals.PERatio.latest,\n",
    "               'close': EquityPricing.close.latest,\n",
    "           },\n",
    "           screen=(Fundamentals.ROE.latest > 10) & (Fundamentals.PERatio.latest < 30)\n",
    "       )\n",
    "       \n",
    "       attach_pipeline(pipe, 'quality_stocks')\n",
    "   \n",
    "   def before_trading_start(context, data):\n",
    "       # Get today's pipeline output\n",
    "       context.output = pipeline_output('quality_stocks')\n",
    "       \n",
    "       # Select top stocks based on fundamentals\n",
    "       context.longs = context.output.nlargest(10, 'roe').index\n",
    "   \n",
    "   def rebalance(context, data):\n",
    "       # Equal-weight portfolio of top quality stocks\n",
    "       for asset in context.longs:\n",
    "           if data.can_trade(asset):\n",
    "               order_target_percent(asset, 1.0 / len(context.longs))\n",
    "\n",
    "4. RUN YOUR BACKTEST:\n",
    "   \n",
    "   from zipline import run_algorithm\n",
    "   \n",
    "   results = run_algorithm(\n",
    "       start=pd.Timestamp('2023-01-01'),\n",
    "       end=pd.Timestamp('2023-12-31'),\n",
    "       initialize=initialize,\n",
    "       before_trading_start=before_trading_start,\n",
    "       capital_base=100000,\n",
    "       bundle='sharadar',\n",
    "   )\n",
    "\n",
    "See the Zipline documentation for complete backtest examples:\n",
    "https://zipline.ml4trading.io/\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Troubleshooting & Tips\n",
    "\n",
    "Common issues and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "TROUBLESHOOTING GUIDE\n",
    "=====================\n",
    "\n",
    "PROBLEM: \"Database not found\"\n",
    "SOLUTION: Run the database creation cell (Part 1) first\n",
    "   \n",
    "PROBLEM: \"No data returned from query\"\n",
    "SOLUTION: \n",
    "   - Check that data was loaded successfully (Part 2)\n",
    "   - Verify your date range matches the data\n",
    "   - Check that Sids exist in the database\n",
    "\n",
    "PROBLEM: \"Unmapped identifiers\" warning\n",
    "SOLUTION:\n",
    "   - Add missing tickers to securities.csv\n",
    "   - Or set fail_on_unmapped=False to skip them\n",
    "\n",
    "PROBLEM: \"Column not found\" error\n",
    "SOLUTION:\n",
    "   - Verify column names match between CSV and schema\n",
    "   - Check case sensitivity (Revenue vs revenue)\n",
    "   - Run describe_custom_db() to see available columns\n",
    "\n",
    "PROBLEM: Pipeline gives errors\n",
    "SOLUTION:\n",
    "   - Ensure dates are timezone-aware: pd.Timestamp('2023-01-01', tz='UTC')\n",
    "   - Check that assets exist in both bundle AND custom data\n",
    "   - Verify CustomSQLiteLoader is registered correctly\n",
    "\n",
    "TIPS FOR BEST RESULTS:\n",
    "======================\n",
    "\n",
    "1. DATA QUALITY:\n",
    "   - Clean your CSV data before loading\n",
    "   - Handle missing values appropriately\n",
    "   - Ensure dates are in consistent format\n",
    "\n",
    "2. PERFORMANCE:\n",
    "   - Use appropriate data types (int for large numbers, not float)\n",
    "   - Index frequently-queried columns\n",
    "   - Use date range filters in queries\n",
    "\n",
    "3. DATA UPDATES:\n",
    "   - Use on_duplicate='replace' to update existing records\n",
    "   - Use on_duplicate='ignore' to skip duplicates\n",
    "   - Use on_duplicate='fail' to catch data issues\n",
    "\n",
    "4. FACTOR DESIGN:\n",
    "   - Normalize factors to similar scales for combining\n",
    "   - Handle missing data with .fillna() or filters\n",
    "   - Test factors individually before combining\n",
    "\n",
    "5. BACKTESTING:\n",
    "   - Ensure point-in-time correctness (no look-ahead bias)\n",
    "   - Match fundamental frequency (quarterly) with rebalancing\n",
    "   - Consider reporting lag (fundamentals released ~45 days after quarter-end)\n",
    "\n",
    "NEXT STEPS:\n",
    "===========\n",
    "\n",
    "1. Load your own fundamental data CSV\n",
    "2. Create custom factors based on your research\n",
    "3. Backtest strategies using fundamental signals\n",
    "4. Combine with price/volume factors for multi-factor models\n",
    "5. Analyze results and iterate\n",
    "\n",
    "For more examples and documentation:\n",
    "  - Zipline Custom Data: src/zipline/data/custom/README.md\n",
    "  - Zipline Pipeline: https://zipline.ml4trading.io/pipeline.html\n",
    "  - Example notebooks: examples/custom_data/\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What We Covered:**\n",
    "\n",
    "1. \u2705 Created a custom database for fundamental data\n",
    "2. \u2705 Loaded CSV data with symbol-to-sid mapping\n",
    "3. \u2705 Created Pipeline DataSets from custom data\n",
    "4. \u2705 Built screening pipelines (quality filters)\n",
    "5. \u2705 Created ranking pipelines (composite scores)\n",
    "6. \u2705 Performed sector analysis\n",
    "7. \u2705 Visualized fundamental metrics\n",
    "8. \u2705 Analyzed trends over time\n",
    "9. \u2705 Learned backtest integration\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- Custom data enables fundamental analysis in Zipline\n",
    "- Pipeline makes it easy to screen and rank stocks\n",
    "- Combine multiple factors for robust signals\n",
    "- Visualizations help understand the data\n",
    "- Integration with backtesting enables strategy development\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. Try with your own fundamental data\n",
    "2. Experiment with different factor combinations\n",
    "3. Build and test investment strategies\n",
    "4. Combine with technical indicators\n",
    "5. Run full backtests and analyze performance\n",
    "\n",
    "Happy researching! \ud83d\udcca\ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}