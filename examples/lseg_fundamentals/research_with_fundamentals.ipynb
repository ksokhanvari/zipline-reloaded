{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Source Fundamentals: Sharadar + Custom LSEG\n",
    "\n",
    "**Working Example**: Using actual LSEG database columns with automatic SID translation\n",
    "\n",
    "This notebook demonstrates combining Sharadar SF1 with your custom LSEG data using available metrics:\n",
    "- **Sharadar**: P/E Ratio, D/E Ratio (ROE not available in current data)\n",
    "- **LSEG**: ROE (ReturnOnEquity_SmartEstimat), PEG Ratio, Market Cap\n",
    "\n",
    "**Data Availability:**\n",
    "- \u2713 Sharadar P/E (s_pe): Has data - measures valuation\n",
    "- \u2713 Sharadar D/E (s_de): Has data - measures leverage\n",
    "- \u2717 Sharadar ROE (s_roe): All NaN - excluded from strategy\n",
    "- \u2713 LSEG ROE (l_roe): Has data - primary profitability metric\n",
    "- \u2713 LSEG PEG (l_peg): Has data - growth-adjusted valuation\n",
    "- \u2713 LSEG MarketCap (l_marketcap): Has data - company size\n",
    "\n",
    "**What This Shows:**\n",
    "1. Load and compare metrics from both sources\n",
    "2. Build a consensus score combining valuation (Sharadar P/E) and profitability (LSEG ROE)\n",
    "3. Run a working backtest using both datasets with **automatic SID translation**\n",
    "\n",
    "**NEW**: The CustomSQLiteLoader now automatically translates between simulation SIDs and bundle SIDs, so custom databases can use bundle SIDs while `run_algorithm()` uses different internal SIDs.\n",
    "\n",
    "**Test Universe**: Stocks from your LSEG database (AAPL, MSFT, GOOGL, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Pyfolio available\n",
      "\u2713 Imports complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5623/2071191602.py:39: UserWarning: Overwriting bundle with name 'sharadar'\n",
      "  register('sharadar', sharadar_bundle())\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add custom_data to path\n",
    "sys.path.insert(0, '/app/examples/shared_modules')\n",
    "\n",
    "from zipline import run_algorithm\n",
    "from zipline.api import (\n",
    "    attach_pipeline,\n",
    "    pipeline_output,\n",
    "    order_target_percent,\n",
    "    record,\n",
    "    schedule_function,\n",
    "    date_rules,\n",
    "    time_rules,\n",
    ")\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.data.sharadar import SharadarFundamentals\n",
    "from zipline.pipeline.filters import StaticAssets\n",
    "from zipline.data.bundles import load as load_bundle, register\n",
    "from zipline.data.bundles.sharadar_bundle import sharadar_bundle\n",
    "from zipline.data.custom import CustomSQLiteLoader\n",
    "from zipline.pipeline.data.db import Database, Column\n",
    "\n",
    "# Pyfolio imports\n",
    "try:\n",
    "    import pyfolio as pf\n",
    "    PYFOLIO_AVAILABLE = True\n",
    "    print(\"\u2713 Pyfolio available\")\n",
    "except ImportError:\n",
    "    PYFOLIO_AVAILABLE = False\n",
    "    print(\"\u26a0 Pyfolio not available - install with: pip install pyfolio-reloaded\")\n",
    "\n",
    "# Register bundle\n",
    "register('sharadar', sharadar_bundle())\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"\u2713 Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom Fundamentals Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Custom database defined\n"
     ]
    }
   ],
   "source": [
    "class CustomFundamentals(Database):\n",
    "    \"\"\"Custom LSEG fundamentals - using actual column names from your database.\"\"\"\n",
    "    CODE = \"fundamentals\"\n",
    "    LOOKBACK_WINDOW = 240\n",
    "    \n",
    "    # Metrics available in your LSEG database\n",
    "    ReturnOnEquity_SmartEstimat = Column(float)  # ROE equivalent\n",
    "    ForwardPEG_DailyTimeSeriesRatio_ = Column(float)  # PEG ratio (P/E to Growth)\n",
    "    Debt_Total = Column(float)  # Total debt\n",
    "    CompanyMarketCap = Column(float)  # Market cap\n",
    "    EarningsPerShare_Actual = Column(float)  # EPS\n",
    "    \n",
    "print(\"\u2713 Custom database defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Custom Loader (Required for Backtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Multi-source loader ready (with SID translation)\n",
      "  - Sharadar: /root/.zipline/data/sharadar/2025-11-29T07;45;23.826120/fundamentals/sf1.h5\n",
      "  - Custom LSEG: /root/data/custom/fundamentals.sqlite\n",
      "  - Custom columns registered: 5\n",
      "  - SID translation: ENABLED\n"
     ]
    }
   ],
   "source": [
    "def setup_multi_source_loader():\n",
    "    \"\"\"Setup loader that handles BOTH Sharadar and Custom LSEG data with SID translation.\"\"\"\n",
    "    from zipline.pipeline.loaders.sharadar_fundamentals import make_sharadar_fundamentals_loader\n",
    "\n",
    "    # Load bundle to get asset_finder for SID translation\n",
    "    bundle_data = load_bundle('sharadar')\n",
    "    asset_finder = bundle_data.asset_finder\n",
    "\n",
    "    class MultiSourceLoaderDict(dict):\n",
    "        def __init__(self, sharadar_loader, custom_loader):\n",
    "            super().__init__()\n",
    "            self.sharadar_loader = sharadar_loader\n",
    "            self.custom_loader = custom_loader\n",
    "\n",
    "        def get(self, key, default=None):\n",
    "            # Check if it's a BoundColumn\n",
    "            if hasattr(key, 'dataset'):\n",
    "                # Get the dataset name from the dataset object\n",
    "                # The dataset has __name__ attribute OR we can use str() representation\n",
    "                if hasattr(key.dataset, '__name__'):\n",
    "                    dataset_name = key.dataset.__name__\n",
    "                else:\n",
    "                    # Parse from string representation: \"<DataSet: 'SharadarFundamentals', ...>\"\n",
    "                    dataset_str = str(key.dataset)\n",
    "                    if \"'\" in dataset_str:\n",
    "                        dataset_name = dataset_str.split(\"'\")[1]\n",
    "                    else:\n",
    "                        dataset_name = dataset_str\n",
    "\n",
    "                # Route based on dataset name\n",
    "                if 'Sharadar' in dataset_name:\n",
    "                    return self.sharadar_loader\n",
    "                elif 'Custom' in dataset_name:\n",
    "                    # For custom columns, check if registered\n",
    "                    if key in self:\n",
    "                        return self[key]\n",
    "                    # Try matching by column name\n",
    "                    for registered_col, loader in self.items():\n",
    "                        if hasattr(registered_col, 'name') and registered_col.name == key.name:\n",
    "                            return loader\n",
    "\n",
    "            raise KeyError(f\"No loader for {key}\")\n",
    "\n",
    "    # Create Sharadar loader\n",
    "    sharadar_loader = make_sharadar_fundamentals_loader('sharadar')\n",
    "\n",
    "    # Create custom LSEG loader WITH SID TRANSLATION\n",
    "    # Pass asset_finder to enable automatic SID translation between\n",
    "    # simulation SIDs (from run_algorithm) and bundle SIDs (in database)\n",
    "    db_dir = Path('/data/custom_databases')\n",
    "    custom_sqlite_loader = CustomSQLiteLoader(\n",
    "        \"fundamentals\",\n",
    "        db_dir=db_dir,\n",
    "        asset_finder=asset_finder  # KEY: Enable SID translation\n",
    "    )\n",
    "\n",
    "    # Create multi-source loader\n",
    "    multi_loader = MultiSourceLoaderDict(sharadar_loader, custom_sqlite_loader)\n",
    "\n",
    "    # Register custom columns\n",
    "    for attr_name in dir(CustomFundamentals):\n",
    "        attr = getattr(CustomFundamentals, attr_name)\n",
    "        if hasattr(attr, 'dataset'):\n",
    "            multi_loader[attr] = custom_sqlite_loader\n",
    "\n",
    "    print(f\"\u2713 Multi-source loader ready (with SID translation)\")\n",
    "    print(f\"  - Sharadar: {sharadar_loader.fundamentals_path}\")\n",
    "    print(f\"  - Custom LSEG: {db_dir / 'fundamentals.sqlite'}\")\n",
    "    print(f\"  - Custom columns registered: {len(multi_loader)}\")\n",
    "    print(f\"  - SID translation: ENABLED\")\n",
    "\n",
    "    return multi_loader\n",
    "\n",
    "custom_loader = setup_multi_source_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Multi-Source Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Pipeline factory defined\n"
     ]
    }
   ],
   "source": [
    "# Strategy configuration\n",
    "TOP_N_STOCKS = 5\n",
    "UNIVERSE_TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'FB', 'JPM', 'V', 'XOM', 'TSLA']\n",
    "\n",
    "def make_pipeline():\n",
    "    \"\"\"Pipeline using both Sharadar and Custom LSEG data.\n",
    "    \n",
    "    Available metrics:\n",
    "    - Sharadar: P/E, D/E (ROE is all NaN, excluded)\n",
    "    - LSEG: ROE, PEG, MarketCap\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load universe from bundle\n",
    "    bundle_data = load_bundle('sharadar')\n",
    "    \n",
    "    # Get assets for our tickers\n",
    "    assets = []\n",
    "    for ticker in UNIVERSE_TICKERS:\n",
    "        try:\n",
    "            asset = bundle_data.asset_finder.lookup_symbol(ticker, as_of_date=None)\n",
    "            assets.append(asset)\n",
    "            print(asset)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    universe = StaticAssets(assets)\n",
    "    \n",
    "    # Sharadar metrics (only those with data)\n",
    "    s_pe = SharadarFundamentals.pe.latest  # \u2713 Has data\n",
    "    s_de = SharadarFundamentals.de.latest  # \u2713 Has data\n",
    "    # NOTE: s_roe is all NaN, excluded from pipeline\n",
    "    \n",
    "    # Custom LSEG metrics (using actual column names)\n",
    "    l_roe = CustomFundamentals.ReturnOnEquity_SmartEstimat.latest  # \u2713 Has data\n",
    "    l_peg = CustomFundamentals.ForwardPEG_DailyTimeSeriesRatio_.latest  # \u2713 Has data\n",
    "    l_marketcap = CustomFundamentals.CompanyMarketCap.latest  # \u2713 Has data\n",
    "    \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            # Sharadar metrics\n",
    "            's_pe': s_pe,\n",
    "            's_de': s_de,\n",
    "            # LSEG metrics\n",
    "            'l_roe': l_roe,\n",
    "            'l_peg': l_peg,\n",
    "            'l_marketcap': l_marketcap,\n",
    "        },\n",
    "        screen=universe,\n",
    "    )\n",
    "\n",
    "print(\"\u2713 Pipeline factory defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Strategy functions defined\n"
     ]
    }
   ],
   "source": [
    "def initialize(context):\n",
    "    \"\"\"Initialize multi-source strategy.\"\"\"\n",
    "    attach_pipeline(make_pipeline(), 'multi_source')\n",
    "    \n",
    "    schedule_function(\n",
    "        rebalance,\n",
    "        date_rules.month_start(),\n",
    "        time_rules.market_open(hours=1)\n",
    "    )\n",
    "    \n",
    "    context.stocks_held = []\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Multi-Source Fundamentals Strategy\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Universe: {len(UNIVERSE_TICKERS)} stocks\")\n",
    "    print(f\"Sharadar: P/E, D/E (ROE excluded - all NaN)\")\n",
    "    print(f\"LSEG: ROE, PEG, MarketCap\")\n",
    "    print(f\"Top N: {TOP_N_STOCKS}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "def before_trading_start(context, data):\n",
    "    #context.pipeline_data = pipeline_output('multi_source')\n",
    "    pass\n",
    "\n",
    "def rebalance(context, data):\n",
    "    \"\"\"Monthly rebalancing with multi-source consensus scoring.\n",
    "    \n",
    "    Scoring logic (updated for available metrics):\n",
    "    - Sharadar P/E < 25 and > 0: +1 point (reasonable valuation)\n",
    "    - Sharadar D/E < 2: +1 point (manageable leverage)\n",
    "    - LSEG ROE > 15%: +2 points (strong profitability)\n",
    "    - LSEG PEG < 2.0 and > 0: +1 point (growth-adjusted value)\n",
    "    - Multi-source bonus: When both Sharadar P/E and LSEG ROE are good: +1 point\n",
    "    \n",
    "    Max score: 6 points\n",
    "    \"\"\"\n",
    "    context.pipeline_data = pipeline_output('multi_source')\n",
    "    df = context.pipeline_data.copy()\n",
    "    print(df)\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        return\n",
    "    \n",
    "    # Initialize scoring\n",
    "    df['score'] = 0\n",
    "    \n",
    "    # Sharadar points (valuation & leverage)\n",
    "    df.loc[(df['s_pe'] < 25) & (df['s_pe'] > 0), 'score'] += 1  # Reasonable P/E\n",
    "    df.loc[(df['s_de'] < 2) & (df['s_de'].notna()), 'score'] += 1  # Low leverage\n",
    "    \n",
    "    # LSEG points (profitability & growth-adjusted value)\n",
    "    df.loc[(df['l_roe'] > 15.0) & (df['l_roe'].notna()), 'score'] += 2  # Strong ROE (LSEG is in %)\n",
    "    df.loc[(df['l_peg'] > 0) & (df['l_peg'] < 2.0), 'score'] += 1  # Good PEG ratio\n",
    "    \n",
    "    # Multi-source consensus bonus: Good valuation (Sharadar P/E) + Good profitability (LSEG ROE)\n",
    "    both_good = ((df['s_pe'] < 25) & (df['s_pe'] > 0)) & ((df['l_roe'] > 15.0) & (df['l_roe'].notna()))\n",
    "    df.loc[both_good, 'score'] += 1\n",
    "    \n",
    "    # Select top N by score\n",
    "    ranked = df.sort_values('score', ascending=False)\n",
    "    target_stocks = ranked.head(TOP_N_STOCKS).index.tolist()\n",
    "    \n",
    "    # Equal weight\n",
    "    weight = 1.0 / len(target_stocks) if target_stocks else 0\n",
    "    \n",
    "    for stock in target_stocks:\n",
    "        if True: #data.can_trade(stock):\n",
    "            order_target_percent(stock, weight)\n",
    "    \n",
    "    for stock in context.portfolio.positions:\n",
    "        if stock not in target_stocks and True: #data.can_trade(stock):\n",
    "            order_target_percent(stock, 0)\n",
    "    \n",
    "    # Log - FIX: Use .loc to avoid reindexing warning\n",
    "    top_n = ranked.head(TOP_N_STOCKS)\n",
    "    lseg_confirmed = top_n['l_roe'].notna().sum()\n",
    "    consensus_stocks = both_good.loc[top_n.index].sum()  # Fixed: align boolean index\n",
    "    print(f\"[{context.datetime.date()}] {len(target_stocks)} stocks, {lseg_confirmed} with LSEG ROE, {consensus_stocks} with multi-source consensus\")\n",
    "\n",
    "def analyze(context, perf):\n",
    "    \"\"\"Analyze results with detailed metrics and pyfolio.\"\"\"\n",
    "    returns = perf['returns']\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    total_return = (perf['portfolio_value'].iloc[-1] / perf['portfolio_value'].iloc[0] - 1) * 100\n",
    "    \n",
    "    # Annualized metrics\n",
    "    days = (perf.index[-1] - perf.index[0]).days\n",
    "    years = days / 365.25\n",
    "    cagr = ((perf['portfolio_value'].iloc[-1] / perf['portfolio_value'].iloc[0]) ** (1/years) - 1) * 100\n",
    "    \n",
    "    # Risk metrics\n",
    "    sharpe = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "    sortino = returns.mean() / returns[returns < 0].std() * np.sqrt(252) if len(returns[returns < 0]) > 0 else 0\n",
    "    \n",
    "    # Drawdown\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    max_dd = drawdown.min() * 100\n",
    "    \n",
    "    # Win rate\n",
    "    winning_days = (returns > 0).sum()\n",
    "    total_days = len(returns)\n",
    "    win_rate = (winning_days / total_days * 100) if total_days > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BACKTEST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nPeriod: {perf.index[0].date()} to {perf.index[-1].date()} ({days} days)\")\n",
    "    print(f\"\\nReturns:\")\n",
    "    print(f\"  Total Return:       {total_return:>10.2f}%\")\n",
    "    print(f\"  CAGR:               {cagr:>10.2f}%\")\n",
    "    print(f\"  Final Value:        ${perf['portfolio_value'].iloc[-1]:>10,.2f}\")\n",
    "    print(f\"\\nRisk Metrics:\")\n",
    "    print(f\"  Sharpe Ratio:       {sharpe:>10.2f}\")\n",
    "    print(f\"  Sortino Ratio:      {sortino:>10.2f}\")\n",
    "    print(f\"  Max Drawdown:       {max_dd:>10.2f}%\")\n",
    "    print(f\"  Volatility (ann):   {returns.std() * np.sqrt(252) * 100:>10.2f}%\")\n",
    "    print(f\"\\nTrading:\")\n",
    "    print(f\"  Win Rate:           {win_rate:>10.2f}%\")\n",
    "    print(f\"  Avg Daily Return:   {returns.mean() * 100:>10.4f}%\")\n",
    "    print(f\"  Best Day:           {returns.max() * 100:>10.2f}%\")\n",
    "    print(f\"  Worst Day:          {returns.min() * 100:>10.2f}%\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return perf\n",
    "\n",
    "print(\"\u2713 Strategy functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running backtest: 2020-01-01 to 2025-11-01\n",
      "\n",
      "Equity(199059 [AAPL])\n",
      "Equity(198508 [MSFT])\n",
      "Equity(195146 [GOOGL])\n",
      "Equity(197029 [AMZN])\n",
      "Equity(196754 [NVDA])\n",
      "Equity(194817 [META])\n",
      "Equity(644713 [FB])\n",
      "Equity(199853 [JPM])\n",
      "Equity(193960 [V])\n",
      "Equity(199739 [XOM])\n",
      "Equity(194897 [TSLA])\n",
      "\n",
      "================================================================================\n",
      "Multi-Source Fundamentals Strategy\n",
      "================================================================================\n",
      "Universe: 11 stocks\n",
      "Sharadar: P/E, D/E (ROE excluded - all NaN)\n",
      "LSEG: ROE, PEG, MarketCap\n",
      "Top N: 5\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\u274c Error: Database not found: /root/data/custom/fundamentals.sqlite\n",
      "Available databases: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/app/src/zipline/algorithm.py\", line 2285, in _pipeline_output\n",
      "    data = self._pipeline_cache.get(name, today)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/utils/cache.py\", line 150, in get\n",
      "    return self._cache[key].unwrap(dt)\n",
      "           ~~~~~~~~~~~^^^^^\n",
      "KeyError: 'multi_source'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5623/1291200646.py\", line 7, in <module>\n",
      "    results = run_algorithm(\n",
      "              ^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/utils/run_algo.py\", line 399, in run_algorithm\n",
      "    return _run(\n",
      "           ^^^^^\n",
      "  File \"/app/src/zipline/utils/run_algo.py\", line 229, in _run\n",
      "    ).run()\n",
      "      ^^^^^\n",
      "  File \"/app/src/zipline/algorithm.py\", line 641, in run\n",
      "    for perf in self.get_generator():\n",
      "  File \"/app/src/zipline/gens/tradesimulation.py\", line 243, in transform\n",
      "    algo.before_trading_start(self.current_data)\n",
      "  File \"/app/src/zipline/algorithm.py\", line 427, in before_trading_start\n",
      "    self.compute_eager_pipelines()\n",
      "  File \"/app/src/zipline/algorithm.py\", line 596, in compute_eager_pipelines\n",
      "    self.pipeline_output(name)\n",
      "  File \"/app/src/zipline/utils/api_support.py\", line 107, in wrapped_method\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/algorithm.py\", line 2278, in pipeline_output\n",
      "    return self._pipeline_output(pipe, chunks, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/algorithm.py\", line 2288, in _pipeline_output\n",
      "    data, valid_until = self.run_pipeline(\n",
      "                        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/algorithm.py\", line 2334, in run_pipeline\n",
      "    self.engine.run_pipeline(pipeline, start_session, end_session),\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/pipeline/engine.py\", line 364, in run_pipeline\n",
      "    return self._run_pipeline_impl(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/pipeline/engine.py\", line 413, in _run_pipeline_impl\n",
      "    results = self.compute_chunk(\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/pipeline/engine.py\", line 662, in compute_chunk\n",
      "    loaded = loader.load_adjusted_array(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/data/custom/pipeline_integration.py\", line 198, in load_adjusted_array\n",
      "    data = self._query_database(dates, sids, columns)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/data/custom/pipeline_integration.py\", line 399, in _query_database\n",
      "    conn = connect_db(self.db_code, self.db_dir)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/data/custom/db_manager.py\", line 216, in connect_db\n",
      "    db_path = get_db_path(db_code, db_dir)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/app/src/zipline/data/custom/db_manager.py\", line 187, in get_db_path\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: Database not found: /root/data/custom/fundamentals.sqlite\n",
      "Available databases: none\n"
     ]
    }
   ],
   "source": [
    "START = pd.Timestamp('2020-01-01')  # No timezone!\n",
    "END = pd.Timestamp('2025-11-01')    # No timezone!\n",
    "\n",
    "print(f\"Running backtest: {START.date()} to {END.date()}\\n\")\n",
    "\n",
    "try:\n",
    "    results = run_algorithm(\n",
    "        start=START,\n",
    "        end=END,\n",
    "        initialize=initialize,\n",
    "        before_trading_start=before_trading_start,\n",
    "        analyze=analyze,\n",
    "        capital_base=100000,\n",
    "        bundle='sharadar',\n",
    "        custom_loader=custom_loader,  # KEY: Pass custom loader here\n",
    "    )\n",
    "    print(\"\\n\u2713 Backtest successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\u274c Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results is not None:\n",
    "    # Export full results to CSV\n",
    "    output_file = '/data/backtest_results/multi_source_backtest_results.csv'\n",
    "    results.to_csv(output_file)\n",
    "    print(f\"\u2713 Results exported to: {output_file}\")\n",
    "    \n",
    "    # Create summary statistics\n",
    "    summary = {\n",
    "        'Metric': [\n",
    "            'Start Date',\n",
    "            'End Date',\n",
    "            'Total Days',\n",
    "            'Initial Capital',\n",
    "            'Final Value',\n",
    "            'Total Return (%)',\n",
    "            'CAGR (%)',\n",
    "            'Sharpe Ratio',\n",
    "            'Sortino Ratio',\n",
    "            'Max Drawdown (%)',\n",
    "            'Volatility (ann %)',\n",
    "            'Win Rate (%)',\n",
    "            'Best Day (%)',\n",
    "            'Worst Day (%)',\n",
    "            'Avg Daily Return (%)'\n",
    "        ],\n",
    "        'Value': [\n",
    "            results.index[0].date(),\n",
    "            results.index[-1].date(),\n",
    "            (results.index[-1] - results.index[0]).days,\n",
    "            results['portfolio_value'].iloc[0],\n",
    "            results['portfolio_value'].iloc[-1],\n",
    "            (results['portfolio_value'].iloc[-1] / results['portfolio_value'].iloc[0] - 1) * 100,\n",
    "            ((results['portfolio_value'].iloc[-1] / results['portfolio_value'].iloc[0]) ** \n",
    "             (365.25 / (results.index[-1] - results.index[0]).days) - 1) * 100,\n",
    "            results['returns'].mean() / results['returns'].std() * np.sqrt(252),\n",
    "            results['returns'].mean() / results['returns'][results['returns'] < 0].std() * np.sqrt(252),\n",
    "            ((1 + results['returns']).cumprod() / \n",
    "             (1 + results['returns']).cumprod().expanding().max() - 1).min() * 100,\n",
    "            results['returns'].std() * np.sqrt(252) * 100,\n",
    "            (results['returns'] > 0).sum() / len(results['returns']) * 100,\n",
    "            results['returns'].max() * 100,\n",
    "            results['returns'].min() * 100,\n",
    "            results['returns'].mean() * 100\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    summary_file = '/data/backtest_results/multi_source_backtest_summary.csv'\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f\"\u2713 Summary exported to: {summary_file}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results is not None and PYFOLIO_AVAILABLE:\n",
    "    print(\"Generating Pyfolio tearsheet...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Extract returns and positions for pyfolio\n",
    "    returns = results['returns']\n",
    "    positions = None  # Pyfolio can work without positions\n",
    "    transactions = None  # Pyfolio can work without transactions\n",
    "    \n",
    "    try:\n",
    "        # Create a simple tearsheet\n",
    "        pf.create_full_tear_sheet(returns, benchmark_rets=None)\n",
    "        print(\"\\n\u2713 Pyfolio analysis complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0 Pyfolio tearsheet generation failed: {e}\")\n",
    "        print(\"Note: This is optional - basic analysis is shown above\")\n",
    "        \n",
    "elif results is not None and not PYFOLIO_AVAILABLE:\n",
    "    print(\"=\"*80)\n",
    "    print(\"Pyfolio not available\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nTo install pyfolio-reloaded:\")\n",
    "    print(\"  pip install pyfolio-reloaded\")\n",
    "    print(\"\\nThis will enable additional tearsheet analysis including:\")\n",
    "    print(\"  - Rolling statistics\")\n",
    "    print(\"  - Exposure analysis\")  \n",
    "    print(\"  - Position concentration\")\n",
    "    print(\"  - Transaction analysis\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyfolio Tearsheet (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results is not None:\n",
    "    # Extract returns and positions\n",
    "    returns = results['returns']\n",
    "    positions = results[[col for col in results.columns if 'positions' in col.lower()]]\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Multi-Source Fundamentals Strategy Performance', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Cumulative Returns\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    axes[0, 0].plot(cumulative.index, cumulative.values, linewidth=2, color='#2E86AB')\n",
    "    axes[0, 0].set_title('Cumulative Returns', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Growth of $1')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Break-even')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Drawdown\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max * 100\n",
    "    axes[0, 1].fill_between(drawdown.index, drawdown.values, 0, alpha=0.3, color='red')\n",
    "    axes[0, 1].plot(drawdown.index, drawdown.values, linewidth=1.5, color='darkred')\n",
    "    axes[0, 1].set_title('Drawdown', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Drawdown (%)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Daily Returns Distribution\n",
    "    axes[1, 0].hist(returns * 100, bins=50, alpha=0.7, color='#06A77D', edgecolor='black')\n",
    "    axes[1, 0].axvline(returns.mean() * 100, color='red', linestyle='--', linewidth=2, label=f'Mean: {returns.mean()*100:.3f}%')\n",
    "    axes[1, 0].set_title('Daily Returns Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Daily Return (%)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Rolling Sharpe (30-day)\n",
    "    rolling_sharpe = returns.rolling(30).mean() / returns.rolling(30).std() * np.sqrt(252)\n",
    "    axes[1, 1].plot(rolling_sharpe.index, rolling_sharpe.values, linewidth=1.5, color='#A23B72')\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[1, 1].axhline(y=1, color='green', linestyle='--', alpha=0.5, label='Sharpe = 1')\n",
    "    axes[1, 1].set_title('Rolling 30-Day Sharpe Ratio', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Sharpe Ratio')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Monthly Returns Heatmap\n",
    "    monthly_returns = returns.resample('M').apply(lambda x: (1 + x).prod() - 1) * 100\n",
    "    monthly_returns.index = monthly_returns.index.to_period('M')\n",
    "    \n",
    "    # Pivot for heatmap\n",
    "    monthly_pivot = monthly_returns.to_frame('returns')\n",
    "    monthly_pivot['year'] = monthly_returns.index.year\n",
    "    monthly_pivot['month'] = monthly_returns.index.month\n",
    "    heatmap_data = monthly_pivot.pivot(index='year', columns='month', values='returns')\n",
    "    \n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='RdYlGn', center=0, \n",
    "                cbar_kws={'label': 'Return (%)'}, ax=axes[2, 0], linewidths=0.5)\n",
    "    axes[2, 0].set_title('Monthly Returns Heatmap (%)', fontsize=12, fontweight='bold')\n",
    "    axes[2, 0].set_xlabel('Month')\n",
    "    axes[2, 0].set_ylabel('Year')\n",
    "    \n",
    "    # 6. Portfolio Value\n",
    "    axes[2, 1].plot(results.index, results['portfolio_value'], linewidth=2, color='#F18F01')\n",
    "    axes[2, 1].set_title('Portfolio Value', fontsize=12, fontweight='bold')\n",
    "    axes[2, 1].set_ylabel('Value ($)')\n",
    "    axes[2, 1].grid(True, alpha=0.3)\n",
    "    axes[2, 1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\u2713 Visualizations complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}