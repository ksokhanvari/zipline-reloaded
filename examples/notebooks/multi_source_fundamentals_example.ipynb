{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Multi-Source Fundamentals: Sharadar + Custom LSEG\n\n**Working Example**: Using actual LSEG database columns\n\nThis notebook demonstrates combining Sharadar SF1 with your custom LSEG data using available metrics:\n- **Sharadar**: ROE, P/E Ratio, D/E Ratio  \n- **LSEG**: ROE (ReturnOnEquity_SmartEstimat), PEG Ratio, Market Cap\n\n**What This Shows:**\n1. Load and compare metrics from both sources\n2. Build a consensus score when both sources agree on quality\n3. Run a working backtest using both datasets\n\n**IMPORTANT**: Both data sources must use the **same SID mappings** for the same stocks. If your custom database was ingested with different SIDs, run:\n```bash\npython examples/custom_data/remap_fundamentals_sids.py\n```\n\n**Test Universe**: Stocks from your LSEG database (AAPL, MSFT, GOOGL, etc.)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Add custom_data to path\nsys.path.insert(0, '/app/examples/custom_data')\n\nfrom zipline import run_algorithm\nfrom zipline.api import (\n    attach_pipeline,\n    pipeline_output,\n    order_target_percent,\n    record,\n    schedule_function,\n    date_rules,\n    time_rules,\n)\nfrom zipline.pipeline import Pipeline\nfrom zipline.pipeline.data.sharadar import SharadarFundamentals\nfrom zipline.pipeline.filters import StaticAssets\nfrom zipline.data.bundles import load as load_bundle, register\nfrom zipline.data.bundles.sharadar_bundle import sharadar_bundle\nfrom zipline.data.custom import CustomSQLiteLoader\nfrom zipline.pipeline.data.db import Database, Column\n\n# Pyfolio imports\ntry:\n    import pyfolio as pf\n    PYFOLIO_AVAILABLE = True\n    print(\"✓ Pyfolio available\")\nexcept ImportError:\n    PYFOLIO_AVAILABLE = False\n    print(\"⚠ Pyfolio not available - install with: pip install pyfolio-reloaded\")\n\n# Register bundle\nregister('sharadar', sharadar_bundle())\n\n# Set plot style\nsns.set_style('darkgrid')\nplt.rcParams['figure.figsize'] = (14, 8)\n\nprint(\"✓ Imports complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom Fundamentals Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Custom database defined\n"
     ]
    }
   ],
   "source": [
    "class CustomFundamentals(Database):\n",
    "    \"\"\"Custom LSEG fundamentals - using actual column names from your database.\"\"\"\n",
    "    CODE = \"fundamentals\"\n",
    "    LOOKBACK_WINDOW = 240\n",
    "    \n",
    "    # Metrics available in your LSEG database\n",
    "    ReturnOnEquity_SmartEstimat = Column(float)  # ROE equivalent\n",
    "    ForwardPEG_DailyTimeSeriesRatio_ = Column(float)  # PEG ratio (P/E to Growth)\n",
    "    Debt_Total = Column(float)  # Total debt\n",
    "    CompanyMarketCap = Column(float)  # Market cap\n",
    "    EarningsPerShare_Actual = Column(float)  # EPS\n",
    "    \n",
    "print(\"✓ Custom database defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Custom Loader (Required for Backtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Multi-source loader ready\n",
      "  - Sharadar: /root/.zipline/data/sharadar/2025-11-17T08;19;43.398169/fundamentals/sf1.h5\n",
      "  - Custom LSEG: /root/.zipline/data/custom/fundamentals.sqlite\n",
      "  - Custom columns registered: 5\n"
     ]
    }
   ],
   "source": [
    "def setup_multi_source_loader():\n",
    "    \"\"\"Setup loader that handles BOTH Sharadar and Custom LSEG data.\"\"\"\n",
    "    from zipline.pipeline.loaders.sharadar_fundamentals import make_sharadar_fundamentals_loader\n",
    "    \n",
    "    class MultiSourceLoaderDict(dict):\n",
    "        def __init__(self, sharadar_loader, custom_loader):\n",
    "            super().__init__()\n",
    "            self.sharadar_loader = sharadar_loader\n",
    "            self.custom_loader = custom_loader\n",
    "        \n",
    "        def get(self, key, default=None):\n",
    "            # Check if it's a BoundColumn\n",
    "            if hasattr(key, 'dataset'):\n",
    "                # Get the dataset name from the dataset object\n",
    "                # The dataset has __name__ attribute OR we can use str() representation\n",
    "                if hasattr(key.dataset, '__name__'):\n",
    "                    dataset_name = key.dataset.__name__\n",
    "                else:\n",
    "                    # Parse from string representation: \"<DataSet: 'SharadarFundamentals', ...>\"\n",
    "                    dataset_str = str(key.dataset)\n",
    "                    if \"'\" in dataset_str:\n",
    "                        dataset_name = dataset_str.split(\"'\")[1]\n",
    "                    else:\n",
    "                        dataset_name = dataset_str\n",
    "                \n",
    "                # Route based on dataset name\n",
    "                if 'Sharadar' in dataset_name:\n",
    "                    return self.sharadar_loader\n",
    "                elif 'Custom' in dataset_name:\n",
    "                    # For custom columns, check if registered\n",
    "                    if key in self:\n",
    "                        return self[key]\n",
    "                    # Try matching by column name\n",
    "                    for registered_col, loader in self.items():\n",
    "                        if hasattr(registered_col, 'name') and registered_col.name == key.name:\n",
    "                            return loader\n",
    "            \n",
    "            raise KeyError(f\"No loader for {key}\")\n",
    "    \n",
    "    # Create Sharadar loader\n",
    "    sharadar_loader = make_sharadar_fundamentals_loader('sharadar')\n",
    "    \n",
    "    # Create custom LSEG loader - USE THE CORRECT DATABASE FILE!\n",
    "    db_dir = Path.home() / '.zipline' / 'data' / 'custom'\n",
    "    # The database is named fundamentals.sqlite, not fundamentals_zipline.db\n",
    "    custom_sqlite_loader = CustomSQLiteLoader(\"fundamentals\", db_dir=db_dir)\n",
    "    \n",
    "    # Create multi-source loader\n",
    "    multi_loader = MultiSourceLoaderDict(sharadar_loader, custom_sqlite_loader)\n",
    "    \n",
    "    # Register custom columns\n",
    "    for attr_name in dir(CustomFundamentals):\n",
    "        attr = getattr(CustomFundamentals, attr_name)\n",
    "        if hasattr(attr, 'dataset'):\n",
    "            multi_loader[attr] = custom_sqlite_loader\n",
    "    \n",
    "    print(f\"✓ Multi-source loader ready\")\n",
    "    print(f\"  - Sharadar: {sharadar_loader.fundamentals_path}\")\n",
    "    print(f\"  - Custom LSEG: {db_dir / 'fundamentals.sqlite'}\")\n",
    "    print(f\"  - Custom columns registered: {len(multi_loader)}\")\n",
    "    \n",
    "    return multi_loader\n",
    "\n",
    "custom_loader = setup_multi_source_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Multi-Source Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pipeline factory defined\n"
     ]
    }
   ],
   "source": [
    "# Strategy configuration\n",
    "TOP_N_STOCKS = 5\n",
    "UNIVERSE_TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'JPM', 'V', 'WMT', 'XOM', 'TSLA']\n",
    "\n",
    "def make_pipeline():\n",
    "    \"\"\"Pipeline using both Sharadar and Custom LSEG data.\"\"\"\n",
    "    \n",
    "    # Load universe from bundle\n",
    "    bundle_data = load_bundle('sharadar')\n",
    "    \n",
    "    # Get assets for our tickers\n",
    "    assets = []\n",
    "    for ticker in UNIVERSE_TICKERS:\n",
    "        try:\n",
    "            asset = bundle_data.asset_finder.lookup_symbol(ticker, as_of_date=None)\n",
    "            assets.append(asset)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    universe = StaticAssets(assets)\n",
    "    \n",
    "    # Sharadar metrics\n",
    "    s_roe = SharadarFundamentals.roe.latest\n",
    "    s_pe = SharadarFundamentals.pe.latest\n",
    "    s_de = SharadarFundamentals.de.latest\n",
    "    \n",
    "    # Custom LSEG metrics (using actual column names)\n",
    "    l_roe = CustomFundamentals.ReturnOnEquity_SmartEstimat.latest\n",
    "    l_peg = CustomFundamentals.ForwardPEG_DailyTimeSeriesRatio_.latest\n",
    "    l_marketcap = CustomFundamentals.CompanyMarketCap.latest\n",
    "    \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            's_roe': s_roe,\n",
    "            's_pe': s_pe,\n",
    "            's_de': s_de,\n",
    "            'l_roe': l_roe,\n",
    "            'l_peg': l_peg,\n",
    "            'l_marketcap': l_marketcap,\n",
    "        },\n",
    "        screen=universe,\n",
    "    )\n",
    "\n",
    "print(\"✓ Pipeline factory defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def initialize(context):\n    \"\"\"Initialize multi-source strategy.\"\"\"\n    attach_pipeline(make_pipeline(), 'multi_source')\n    \n    schedule_function(\n        rebalance,\n        date_rules.month_start(),\n        time_rules.market_open(hours=1)\n    )\n    \n    context.stocks_held = []\n    print(\"\\n\" + \"=\"*80)\n    print(\"Multi-Source Fundamentals Strategy\")\n    print(\"=\"*80)\n    print(f\"Universe: {len(UNIVERSE_TICKERS)} stocks\")\n    print(f\"Sharadar: ROE, P/E, D/E\")\n    print(f\"LSEG: ROE, PEG, MarketCap\")\n    print(f\"Top N: {TOP_N_STOCKS}\")\n    print(\"=\"*80 + \"\\n\")\n\ndef before_trading_start(context, data):\n    context.pipeline_data = pipeline_output('multi_source')\n\ndef rebalance(context, data):\n    \"\"\"Monthly rebalancing with consensus scoring.\"\"\"\n    df = context.pipeline_data.copy()\n    \n    if len(df) == 0:\n        return\n    \n    # Consensus scoring\n    df['score'] = 0\n    \n    # Sharadar points\n    df.loc[(df['s_roe'] > 0.15) & (df['s_roe'].notna()), 'score'] += 1\n    df.loc[(df['s_pe'] < 25) & (df['s_pe'] > 0), 'score'] += 1\n    df.loc[(df['s_de'] < 2) & (df['s_de'].notna()), 'score'] += 1\n    \n    # LSEG bonus (when both sources agree on quality)\n    # Both sources show high ROE\n    both_roe = (df['s_roe'].notna()) & (df['l_roe'].notna()) & (df['l_roe'] > 15.0)  # LSEG ROE is in percentage\n    df.loc[both_roe, 'score'] += 2\n    \n    # LSEG PEG is reasonable (< 2.0 means stock isn't overvalued relative to growth)\n    df.loc[(df['l_peg'] > 0) & (df['l_peg'] < 2.0), 'score'] += 1\n    \n    # Select top N by score\n    ranked = df.sort_values('score', ascending=False)\n    target_stocks = ranked.head(TOP_N_STOCKS).index.tolist()\n    \n    # Equal weight\n    weight = 1.0 / len(target_stocks) if target_stocks else 0\n    \n    for stock in target_stocks:\n        if data.can_trade(stock):\n            order_target_percent(stock, weight)\n    \n    for stock in context.portfolio.positions:\n        if stock not in target_stocks and data.can_trade(stock):\n            order_target_percent(stock, 0)\n    \n    # Log\n    lseg_confirmed = ranked.head(TOP_N_STOCKS)['l_roe'].notna().sum()\n    print(f\"[{context.datetime.date()}] {len(target_stocks)} stocks, {lseg_confirmed} with LSEG data\")\n\ndef analyze(context, perf):\n    \"\"\"Analyze results with detailed metrics and pyfolio.\"\"\"\n    returns = perf['returns']\n    \n    # Calculate basic metrics\n    total_return = (perf['portfolio_value'].iloc[-1] / perf['portfolio_value'].iloc[0] - 1) * 100\n    \n    # Annualized metrics\n    days = (perf.index[-1] - perf.index[0]).days\n    years = days / 365.25\n    cagr = ((perf['portfolio_value'].iloc[-1] / perf['portfolio_value'].iloc[0]) ** (1/years) - 1) * 100\n    \n    # Risk metrics\n    sharpe = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n    sortino = returns.mean() / returns[returns < 0].std() * np.sqrt(252) if len(returns[returns < 0]) > 0 else 0\n    \n    # Drawdown\n    cumulative = (1 + returns).cumprod()\n    running_max = cumulative.expanding().max()\n    drawdown = (cumulative - running_max) / running_max\n    max_dd = drawdown.min() * 100\n    \n    # Win rate\n    winning_days = (returns > 0).sum()\n    total_days = len(returns)\n    win_rate = (winning_days / total_days * 100) if total_days > 0 else 0\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"BACKTEST RESULTS\")\n    print(\"=\"*80)\n    print(f\"\\nPeriod: {perf.index[0].date()} to {perf.index[-1].date()} ({days} days)\")\n    print(f\"\\nReturns:\")\n    print(f\"  Total Return:       {total_return:>10.2f}%\")\n    print(f\"  CAGR:               {cagr:>10.2f}%\")\n    print(f\"  Final Value:        ${perf['portfolio_value'].iloc[-1]:>10,.2f}\")\n    print(f\"\\nRisk Metrics:\")\n    print(f\"  Sharpe Ratio:       {sharpe:>10.2f}\")\n    print(f\"  Sortino Ratio:      {sortino:>10.2f}\")\n    print(f\"  Max Drawdown:       {max_dd:>10.2f}%\")\n    print(f\"  Volatility (ann):   {returns.std() * np.sqrt(252) * 100:>10.2f}%\")\n    print(f\"\\nTrading:\")\n    print(f\"  Win Rate:           {win_rate:>10.2f}%\")\n    print(f\"  Avg Daily Return:   {returns.mean() * 100:>10.4f}%\")\n    print(f\"  Best Day:           {returns.max() * 100:>10.2f}%\")\n    print(f\"  Worst Day:          {returns.min() * 100:>10.2f}%\")\n    print(\"=\"*80)\n    \n    return perf\n\nprint(\"✓ Strategy functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running backtest: 2023-01-01 to 2024-11-01\n",
      "\n",
      "⚠ Yahoo Finance bundles not available: No module named 'zipline.data.bundles.yahoo_bundle'\n",
      "⚠ NASDAQ Data Link bundles not available: No module named 'zipline.data.bundles.nasdaq_bundle'\n",
      "✓ Sharadar bundles registered\n",
      "\n",
      "Available bundles:\n",
      "  - yahoo, yahoo-tech, yahoo-dow, yahoo-sp500\n",
      "  - nasdaq, nasdaq-premium, nasdaq-free, nasdaq-sp500\n",
      "  - sharadar, sharadar-tech, sharadar-sp500, sharadar-all\n",
      "\n",
      "Use 'zipline bundles' to see which bundles have been ingested.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.zipline/extension.py:56: UserWarning: Overwriting bundle with name 'sharadar'\n",
      "  register('sharadar', sharadar_bundle())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Multi-Source Fundamentals Strategy\n",
      "================================================================================\n",
      "Universe: 11 stocks\n",
      "Sharadar: ROE, P/E, D/E\n",
      "LSEG: ROE, PEG, MarketCap\n",
      "Top N: 5\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found in fundamentals database for dates 2023-01-03 to 2023-01-10, sids ['103837', '103908', '104612', '104628', '105149']...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-03] 5 stocks, 0 with LSEG data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found in fundamentals database for dates 2023-01-11 to 2023-07-14, sids ['103837', '103908', '104612', '104628', '105149']...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-01] 5 stocks, 0 with LSEG data\n",
      "[2023-03-01] 5 stocks, 0 with LSEG data\n",
      "[2023-04-03] 5 stocks, 0 with LSEG data\n",
      "[2023-05-01] 5 stocks, 0 with LSEG data\n",
      "[2023-06-01] 5 stocks, 0 with LSEG data\n",
      "[2023-07-03] 5 stocks, 0 with LSEG data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found in fundamentals database for dates 2023-07-17 to 2024-01-16, sids ['103837', '103908', '104612', '104628', '104914']...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-01] 5 stocks, 0 with LSEG data\n",
      "[2023-09-01] 5 stocks, 0 with LSEG data\n",
      "[2023-10-02] 5 stocks, 0 with LSEG data\n",
      "[2023-11-01] 5 stocks, 0 with LSEG data\n",
      "[2023-12-01] 5 stocks, 0 with LSEG data\n",
      "[2024-01-02] 5 stocks, 0 with LSEG data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found in fundamentals database for dates 2024-01-17 to 2024-07-18, sids ['103837', '103908', '104612', '104628', '104914']...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-01] 5 stocks, 0 with LSEG data\n",
      "[2024-03-01] 5 stocks, 0 with LSEG data\n",
      "[2024-04-01] 5 stocks, 0 with LSEG data\n",
      "[2024-05-01] 5 stocks, 0 with LSEG data\n",
      "[2024-06-03] 5 stocks, 0 with LSEG data\n",
      "[2024-07-01] 5 stocks, 0 with LSEG data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found in fundamentals database for dates 2024-07-19 to 2024-11-01, sids ['103837', '103908', '104612', '104628', '104914']...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-01] 5 stocks, 0 with LSEG data\n",
      "[2024-09-03] 5 stocks, 0 with LSEG data\n",
      "[2024-10-01] 5 stocks, 0 with LSEG data\n",
      "[2024-11-01] 5 stocks, 0 with LSEG data\n",
      "\n",
      "================================================================================\n",
      "Backtest Complete\n",
      "================================================================================\n",
      "Total Return: 116.26%\n",
      "Sharpe: 2.13\n",
      "================================================================================\n",
      "\n",
      "✓ Backtest successful!\n"
     ]
    }
   ],
   "source": [
    "START = pd.Timestamp('2023-01-01')  # No timezone!\n",
    "END = pd.Timestamp('2024-11-01')    # No timezone!\n",
    "\n",
    "print(f\"Running backtest: {START.date()} to {END.date()}\\n\")\n",
    "\n",
    "try:\n",
    "    results = run_algorithm(\n",
    "        start=START,\n",
    "        end=END,\n",
    "        initialize=initialize,\n",
    "        before_trading_start=before_trading_start,\n",
    "        analyze=analyze,\n",
    "        capital_base=100000,\n",
    "        bundle='sharadar',\n",
    "        custom_loader=custom_loader,  # KEY: Pass custom loader here\n",
    "    )\n",
    "    print(\"\\n✓ Backtest successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Performance Analysis & Visualization"
  },
  {
   "cell_type": "code",
   "source": "if results is not None:\n    # Export full results to CSV\n    output_file = '/notebooks/multi_source_backtest_results.csv'\n    results.to_csv(output_file)\n    print(f\"✓ Results exported to: {output_file}\")\n    \n    # Create summary statistics\n    summary = {\n        'Metric': [\n            'Start Date',\n            'End Date',\n            'Total Days',\n            'Initial Capital',\n            'Final Value',\n            'Total Return (%)',\n            'CAGR (%)',\n            'Sharpe Ratio',\n            'Sortino Ratio',\n            'Max Drawdown (%)',\n            'Volatility (ann %)',\n            'Win Rate (%)',\n            'Best Day (%)',\n            'Worst Day (%)',\n            'Avg Daily Return (%)'\n        ],\n        'Value': [\n            results.index[0].date(),\n            results.index[-1].date(),\n            (results.index[-1] - results.index[0]).days,\n            results['portfolio_value'].iloc[0],\n            results['portfolio_value'].iloc[-1],\n            (results['portfolio_value'].iloc[-1] / results['portfolio_value'].iloc[0] - 1) * 100,\n            ((results['portfolio_value'].iloc[-1] / results['portfolio_value'].iloc[0]) ** \n             (365.25 / (results.index[-1] - results.index[0]).days) - 1) * 100,\n            results['returns'].mean() / results['returns'].std() * np.sqrt(252),\n            results['returns'].mean() / results['returns'][results['returns'] < 0].std() * np.sqrt(252),\n            ((1 + results['returns']).cumprod() / \n             (1 + results['returns']).cumprod().expanding().max() - 1).min() * 100,\n            results['returns'].std() * np.sqrt(252) * 100,\n            (results['returns'] > 0).sum() / len(results['returns']) * 100,\n            results['returns'].max() * 100,\n            results['returns'].min() * 100,\n            results['returns'].mean() * 100\n        ]\n    }\n    \n    summary_df = pd.DataFrame(summary)\n    summary_file = '/notebooks/multi_source_backtest_summary.csv'\n    summary_df.to_csv(summary_file, index=False)\n    print(f\"✓ Summary exported to: {summary_file}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"SUMMARY STATISTICS\")\n    print(\"=\"*80)\n    print(summary_df.to_string(index=False))\n    print(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Export Results",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if results is not None and PYFOLIO_AVAILABLE:\n    print(\"Generating Pyfolio tearsheet...\")\n    print(\"=\"*80)\n    \n    # Extract returns and positions for pyfolio\n    returns = results['returns']\n    positions = None  # Pyfolio can work without positions\n    transactions = None  # Pyfolio can work without transactions\n    \n    try:\n        # Create a simple tearsheet\n        pf.create_simple_tear_sheet(returns, benchmark_rets=None)\n        print(\"\\n✓ Pyfolio analysis complete\")\n    except Exception as e:\n        print(f\"⚠ Pyfolio tearsheet generation failed: {e}\")\n        print(\"Note: This is optional - basic analysis is shown above\")\n        \nelif results is not None and not PYFOLIO_AVAILABLE:\n    print(\"=\"*80)\n    print(\"Pyfolio not available\")\n    print(\"=\"*80)\n    print(\"\\nTo install pyfolio-reloaded:\")\n    print(\"  pip install pyfolio-reloaded\")\n    print(\"\\nThis will enable additional tearsheet analysis including:\")\n    print(\"  - Rolling statistics\")\n    print(\"  - Exposure analysis\")  \n    print(\"  - Position concentration\")\n    print(\"  - Transaction analysis\")\n    print(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Pyfolio Tearsheet (if available)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if results is not None:\n    # Extract returns and positions\n    returns = results['returns']\n    positions = results[[col for col in results.columns if 'positions' in col.lower()]]\n    \n    # Create figure with subplots\n    fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n    fig.suptitle('Multi-Source Fundamentals Strategy Performance', fontsize=16, fontweight='bold')\n    \n    # 1. Cumulative Returns\n    cumulative = (1 + returns).cumprod()\n    axes[0, 0].plot(cumulative.index, cumulative.values, linewidth=2, color='#2E86AB')\n    axes[0, 0].set_title('Cumulative Returns', fontsize=12, fontweight='bold')\n    axes[0, 0].set_ylabel('Growth of $1')\n    axes[0, 0].grid(True, alpha=0.3)\n    axes[0, 0].axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Break-even')\n    axes[0, 0].legend()\n    \n    # 2. Drawdown\n    running_max = cumulative.expanding().max()\n    drawdown = (cumulative - running_max) / running_max * 100\n    axes[0, 1].fill_between(drawdown.index, drawdown.values, 0, alpha=0.3, color='red')\n    axes[0, 1].plot(drawdown.index, drawdown.values, linewidth=1.5, color='darkred')\n    axes[0, 1].set_title('Drawdown', fontsize=12, fontweight='bold')\n    axes[0, 1].set_ylabel('Drawdown (%)')\n    axes[0, 1].grid(True, alpha=0.3)\n    \n    # 3. Daily Returns Distribution\n    axes[1, 0].hist(returns * 100, bins=50, alpha=0.7, color='#06A77D', edgecolor='black')\n    axes[1, 0].axvline(returns.mean() * 100, color='red', linestyle='--', linewidth=2, label=f'Mean: {returns.mean()*100:.3f}%')\n    axes[1, 0].set_title('Daily Returns Distribution', fontsize=12, fontweight='bold')\n    axes[1, 0].set_xlabel('Daily Return (%)')\n    axes[1, 0].set_ylabel('Frequency')\n    axes[1, 0].legend()\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    # 4. Rolling Sharpe (30-day)\n    rolling_sharpe = returns.rolling(30).mean() / returns.rolling(30).std() * np.sqrt(252)\n    axes[1, 1].plot(rolling_sharpe.index, rolling_sharpe.values, linewidth=1.5, color='#A23B72')\n    axes[1, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n    axes[1, 1].axhline(y=1, color='green', linestyle='--', alpha=0.5, label='Sharpe = 1')\n    axes[1, 1].set_title('Rolling 30-Day Sharpe Ratio', fontsize=12, fontweight='bold')\n    axes[1, 1].set_ylabel('Sharpe Ratio')\n    axes[1, 1].legend()\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    # 5. Monthly Returns Heatmap\n    monthly_returns = returns.resample('M').apply(lambda x: (1 + x).prod() - 1) * 100\n    monthly_returns.index = monthly_returns.index.to_period('M')\n    \n    # Pivot for heatmap\n    monthly_pivot = monthly_returns.to_frame('returns')\n    monthly_pivot['year'] = monthly_returns.index.year\n    monthly_pivot['month'] = monthly_returns.index.month\n    heatmap_data = monthly_pivot.pivot(index='year', columns='month', values='returns')\n    \n    sns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='RdYlGn', center=0, \n                cbar_kws={'label': 'Return (%)'}, ax=axes[2, 0], linewidths=0.5)\n    axes[2, 0].set_title('Monthly Returns Heatmap (%)', fontsize=12, fontweight='bold')\n    axes[2, 0].set_xlabel('Month')\n    axes[2, 0].set_ylabel('Year')\n    \n    # 6. Portfolio Value\n    axes[2, 1].plot(results.index, results['portfolio_value'], linewidth=2, color='#F18F01')\n    axes[2, 1].set_title('Portfolio Value', fontsize=12, fontweight='bold')\n    axes[2, 1].set_ylabel('Value ($)')\n    axes[2, 1].grid(True, alpha=0.3)\n    axes[2, 1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"\\n✓ Visualizations complete\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}