{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Source Fundamentals: Sharadar + Custom LSEG\n",
        "\n",
        "**Simplified Example**: Focusing on 3 common metrics\n",
        "\n",
        "This notebook demonstrates combining Sharadar SF1 with custom LSEG data using metrics available in both sources:\n",
        "- **ROE** (Return on Equity)\n",
        "- **P/E Ratio** (Price to Earnings)\n",
        "- **D/E Ratio** (Debt to Equity)\n",
        "\n",
        "**What This Shows:**\n",
        "1. Load and compare the same metrics from both sources\n",
        "2. Build a consensus score when both sources agree\n",
        "3. Run a working backtest using both datasets\n",
        "\n",
        "**Test Universe**: Small set of stocks (AAPL, MSFT, GOOGL, etc.) that exist in your custom database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Add custom_data to path\n",
        "sys.path.insert(0, '/app/examples/custom_data')\n",
        "\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import (\n",
        "    attach_pipeline,\n",
        "    pipeline_output,\n",
        "    order_target_percent,\n",
        "    record,\n",
        "    schedule_function,\n",
        "    date_rules,\n",
        "    time_rules,\n",
        ")\n",
        "from zipline.pipeline import Pipeline\n",
        "from zipline.pipeline.data.sharadar import SharadarFundamentals\n",
        "from zipline.pipeline.filters import StaticAssets\n",
        "from zipline.data.bundles import load as load_bundle, register\n",
        "from zipline.data.bundles.sharadar_bundle import sharadar_bundle\n",
        "from zipline.data.custom import CustomSQLiteLoader\n",
        "from zipline.pipeline.data.db import Database, Column\n",
        "\n",
        "# Register bundle\n",
        "register('sharadar', sharadar_bundle())\n",
        "\n",
        "print(\"\u2713 Imports complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Custom Fundamentals Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomFundamentals(Database):\n",
        "    \"\"\"Custom LSEG fundamentals - matching columns to Sharadar.\"\"\"\n",
        "    CODE = \"fundamentals\"\n",
        "    LOOKBACK_WINDOW = 240\n",
        "    \n",
        "    # Common metrics (exist in both Sharadar and LSEG)\n",
        "    ROE = Column(float)              # Same as Sharadar 'roe'\n",
        "    PERatio = Column(float)          # Same as Sharadar 'pe'\n",
        "    DebtToEquity = Column(float)     # Same as Sharadar 'de'\n",
        "    \n",
        "    # Additional LSEG metrics\n",
        "    Revenue = Column(float)\n",
        "    NetIncome = Column(float)\n",
        "    \n",
        "print(\"\u2713 Custom database defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Custom Loader (Required for Backtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_custom_loader():\n",
        "    \"\"\"Setup custom loader with proper column registration.\"\"\"\n",
        "    class LoaderDict(dict):\n",
        "        def get(self, key, default=None):\n",
        "            if key in self:\n",
        "                return self[key]\n",
        "            \n",
        "            # Match by dataset and column name\n",
        "            if hasattr(key, 'dataset') and hasattr(key, 'name'):\n",
        "                key_dataset_name = str(key.dataset).split('<')[0]\n",
        "                key_col_name = key.name\n",
        "                \n",
        "                for registered_col, loader in self.items():\n",
        "                    if hasattr(registered_col, 'dataset') and hasattr(registered_col, 'name'):\n",
        "                        reg_dataset_name = str(registered_col.dataset).split('<')[0]\n",
        "                        reg_col_name = registered_col.name\n",
        "                        \n",
        "                        if key_dataset_name == reg_dataset_name and key_col_name == reg_col_name:\n",
        "                            return loader\n",
        "            \n",
        "            raise KeyError(key)\n",
        "    \n",
        "    custom_loader_dict = LoaderDict()\n",
        "    db_dir = Path.home() / '.zipline' / 'data' / 'custom'\n",
        "    loader = CustomSQLiteLoader(\"fundamentals\", db_dir=db_dir)\n",
        "    \n",
        "    # Register all columns\n",
        "    for attr_name in dir(CustomFundamentals):\n",
        "        attr = getattr(CustomFundamentals, attr_name)\n",
        "        if hasattr(attr, 'dataset'):\n",
        "            custom_loader_dict[attr] = loader\n",
        "    \n",
        "    print(f\"\u2713 Custom loader registered with {len(custom_loader_dict)} columns\")\n",
        "    return custom_loader_dict\n",
        "\n",
        "custom_loader = setup_custom_loader()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Multi-Source Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Strategy configuration\n",
        "TOP_N_STOCKS = 5\n",
        "UNIVERSE_TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'JPM', 'V', 'WMT', 'XOM', 'TSLA']\n",
        "\n",
        "def make_pipeline():\n",
        "    \"\"\"Pipeline using both Sharadar and Custom LSEG data.\"\"\"\n",
        "    \n",
        "    # Load universe from bundle\n",
        "    bundle_data = load_bundle('sharadar')\n",
        "    \n",
        "    # Get assets for our tickers\n",
        "    assets = []\n",
        "    for ticker in UNIVERSE_TICKERS:\n",
        "        try:\n",
        "            asset = bundle_data.asset_finder.lookup_symbol(ticker, as_of_date=None)\n",
        "            assets.append(asset)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    universe = StaticAssets(assets)\n",
        "    \n",
        "    # Sharadar metrics\n",
        "    s_roe = SharadarFundamentals.roe.latest\n",
        "    s_pe = SharadarFundamentals.pe.latest\n",
        "    s_de = SharadarFundamentals.de.latest\n",
        "    \n",
        "    # Custom LSEG metrics\n",
        "    l_roe = CustomFundamentals.ROE.latest\n",
        "    l_pe = CustomFundamentals.PERatio.latest\n",
        "    l_de = CustomFundamentals.DebtToEquity.latest\n",
        "    \n",
        "    return Pipeline(\n",
        "        columns={\n",
        "            's_roe': s_roe,\n",
        "            's_pe': s_pe,\n",
        "            's_de': s_de,\n",
        "            'l_roe': l_roe,\n",
        "            'l_pe': l_pe,\n",
        "            'l_de': l_de,\n",
        "        },\n",
        "        screen=universe,\n",
        "    )\n",
        "\n",
        "print(\"\u2713 Pipeline factory defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategy Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize(context):\n",
        "    \"\"\"Initialize multi-source strategy.\"\"\"\n",
        "    attach_pipeline(make_pipeline(), 'multi_source')\n",
        "    \n",
        "    schedule_function(\n",
        "        rebalance,\n",
        "        date_rules.month_start(),\n",
        "        time_rules.market_open(hours=1)\n",
        "    )\n",
        "    \n",
        "    context.stocks_held = []\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Multi-Source Fundamentals Strategy\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Universe: {len(UNIVERSE_TICKERS)} stocks\")\n",
        "    print(f\"Common metrics: ROE, P/E, D/E\")\n",
        "    print(f\"Top N: {TOP_N_STOCKS}\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "def before_trading_start(context, data):\n",
        "    context.pipeline_data = pipeline_output('multi_source')\n",
        "\n",
        "def rebalance(context, data):\n",
        "    \"\"\"Monthly rebalancing with consensus scoring.\"\"\"\n",
        "    df = context.pipeline_data.copy()\n",
        "    \n",
        "    if len(df) == 0:\n",
        "        return\n",
        "    \n",
        "    # Consensus scoring\n",
        "    df['score'] = 0\n",
        "    \n",
        "    # Sharadar points\n",
        "    df.loc[(df['s_roe'] > 0.15) & (df['s_roe'].notna()), 'score'] += 1\n",
        "    df.loc[(df['s_pe'] < 25) & (df['s_pe'] > 0), 'score'] += 1\n",
        "    df.loc[(df['s_de'] < 2) & (df['s_de'].notna()), 'score'] += 1\n",
        "    \n",
        "    # LSEG bonus (when both sources agree)\n",
        "    both_roe = (df['s_roe'].notna()) & (df['l_roe'].notna()) & (df['l_roe'] > 0.15)\n",
        "    df.loc[both_roe, 'score'] += 2\n",
        "    \n",
        "    # Select top N by score\n",
        "    ranked = df.sort_values('score', ascending=False)\n",
        "    target_stocks = ranked.head(TOP_N_STOCKS).index.tolist()\n",
        "    \n",
        "    # Equal weight\n",
        "    weight = 1.0 / len(target_stocks) if target_stocks else 0\n",
        "    \n",
        "    for stock in target_stocks:\n",
        "        if data.can_trade(stock):\n",
        "            order_target_percent(stock, weight)\n",
        "    \n",
        "    for stock in context.portfolio.positions:\n",
        "        if stock not in target_stocks and data.can_trade(stock):\n",
        "            order_target_percent(stock, 0)\n",
        "    \n",
        "    # Log\n",
        "    lseg_confirmed = ranked.head(TOP_N_STOCKS)['l_roe'].notna().sum()\n",
        "    print(f\"[{context.datetime.date()}] {len(target_stocks)} stocks, {lseg_confirmed} with LSEG data\")\n",
        "\n",
        "def analyze(context, perf):\n",
        "    returns = perf['returns']\n",
        "    total_return = (perf['portfolio_value'].iloc[-1] / perf['portfolio_value'].iloc[0] - 1) * 100\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Backtest Complete\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Total Return: {total_return:.2f}%\")\n",
        "    print(f\"Sharpe: {returns.mean() / returns.std() * np.sqrt(252):.2f}\" if returns.std() > 0 else \"N/A\")\n",
        "    print(\"=\"*80)\n",
        "    return perf\n",
        "\n",
        "print(\"\u2713 Strategy functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Backtest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "START = pd.Timestamp('2023-01-01', tz='UTC')\n",
        "END = pd.Timestamp('2024-11-01', tz='UTC')\n",
        "\n",
        "print(f\"Running backtest: {START.date()} to {END.date()}\\n\")\n",
        "\n",
        "try:\n",
        "    results = run_algorithm(\n",
        "        start=START,\n",
        "        end=END,\n",
        "        initialize=initialize,\n",
        "        before_trading_start=before_trading_start,\n",
        "        analyze=analyze,\n",
        "        capital_base=100000,\n",
        "        bundle='sharadar',\n",
        "        custom_loader=custom_loader,  # KEY: Pass custom loader here\n",
        "    )\n",
        "    print(\"\\n\u2713 Backtest successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\u274c Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    results = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "### \u2705 Multi-Source Data Integration\n",
        "- Loaded both Sharadar and custom LSEG fundamentals\n",
        "- Focused on 3 common metrics: ROE, P/E, D/E\n",
        "- Used proper custom loader setup for backtesting\n",
        "\n",
        "### \u2705 Consensus Scoring\n",
        "- Base points from Sharadar metrics\n",
        "- Bonus points when LSEG confirms (both sources agree)\n",
        "- Top N stocks by combined score\n",
        "\n",
        "### \u2705 Working Backtest\n",
        "- Small universe (11 stocks with custom data)\n",
        "- Monthly rebalancing\n",
        "- Complete performance tracking\n",
        "\n",
        "**Key Takeaway**: By focusing on common metrics and using the proper loader setup, we can successfully combine multiple fundamental data sources in production backtests."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}