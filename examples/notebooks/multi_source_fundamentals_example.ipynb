{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Source Fundamentals: Sharadar + Custom LSEG Data\n",
    "\n",
    "This notebook demonstrates how to combine **two fundamental data sources** in a single strategy:\n",
    "- **Sharadar SF1**: 80+ quarterly metrics via Pipeline\n",
    "- **Custom LSEG**: Your proprietary fundamental data via CustomFundamentals\n",
    "\n",
    "**What You'll Learn:**\n",
    "- Access both Sharadar and custom fundamentals simultaneously\n",
    "- Compare metrics from different sources\n",
    "- Build consensus scores from multiple sources\n",
    "- Handle missing data across sources\n",
    "- Run a complete backtest mixing both datasets\n",
    "\n",
    "**Use Cases:**\n",
    "- **Data Quality Checks**: Compare Sharadar vs LSEG for same metric\n",
    "- **Coverage Expansion**: Use LSEG where Sharadar is missing, vice versa\n",
    "- **Consensus Signals**: Only trade when both sources agree\n",
    "- **Alpha Discovery**: Find discrepancies between sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add custom_data to path for imports\n",
    "sys.path.insert(0, '/app/examples/custom_data')\n",
    "\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.data import EquityPricing\n",
    "from zipline.pipeline.data.sharadar import SharadarFundamentals\n",
    "from zipline.pipeline.loaders.sharadar_fundamentals import make_sharadar_fundamentals_loader\n",
    "from zipline.pipeline.engine import SimplePipelineEngine\n",
    "from zipline.pipeline.domain import US_EQUITIES\n",
    "from zipline.pipeline.factors import Returns, SimpleMovingAverage\n",
    "from zipline.data.bundles import load, register\n",
    "from zipline.data.bundles.sharadar_bundle import sharadar_bundle\n",
    "\n",
    "# Import custom fundamentals database class\n",
    "from database_class_approach import CustomFundamentals\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 25)\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Both Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Loading Multi-Source Fundamentals\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Register and load Sharadar bundle\n",
    "print(\"\\nStep 1/4: Loading Sharadar bundle...\")\n",
    "register('sharadar', sharadar_bundle())\n",
    "bundle_data = load('sharadar')\n",
    "print(\"  ✓ Sharadar bundle loaded\")\n",
    "\n",
    "# Step 2: Create Sharadar fundamentals loader\n",
    "print(\"\\nStep 2/4: Creating Sharadar fundamentals loader...\")\n",
    "sharadar_loader = make_sharadar_fundamentals_loader('sharadar')\n",
    "print(f\"  ✓ Sharadar loader created: {sharadar_loader.fundamentals_path}\")\n",
    "\n",
    "# Step 3: Load custom fundamentals database\n",
    "print(\"\\nStep 3/4: Loading custom LSEG fundamentals database...\")\n",
    "from zipline.data.custom import CustomSQLiteLoader\n",
    "\n",
    "custom_fundamentals_path = '/root/.zipline/data/custom/fundamentals_zipline.db'\n",
    "custom_loader = CustomSQLiteLoader(custom_fundamentals_path)\n",
    "print(f\"  ✓ Custom LSEG loader created: {custom_fundamentals_path}\")\n",
    "\n",
    "# Step 4: Find valid trading session\n",
    "print(\"\\nStep 4/4: Finding valid trading session...\")\n",
    "trading_calendar = bundle_data.equity_daily_bar_reader.trading_calendar\n",
    "sessions = trading_calendar.sessions_in_range(\n",
    "    pd.Timestamp('2024-11-01'),\n",
    "    pd.Timestamp('2024-11-15')\n",
    ")\n",
    "test_date = sessions[-1]\n",
    "print(f\"  ✓ Using test date: {test_date.date()}\")\n",
    "\n",
    "# Create Pipeline engine with multi-source loader\n",
    "def get_loader(column):\n",
    "    \"\"\"Route columns to appropriate loader.\"\"\"\n",
    "    if hasattr(column, 'dataset'):\n",
    "        if column.dataset == SharadarFundamentals:\n",
    "            return sharadar_loader\n",
    "        elif column.dataset == CustomFundamentals:\n",
    "            return custom_loader\n",
    "    return sharadar_loader  # Default\n",
    "\n",
    "engine = SimplePipelineEngine(\n",
    "    get_loader=get_loader,\n",
    "    asset_finder=bundle_data.asset_finder,\n",
    "    default_domain=US_EQUITIES,\n",
    ")\n",
    "print(\"\\n✓ Multi-source Pipeline engine ready\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Comparison - Sharadar vs Custom LSEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline with metrics from BOTH sources\n",
    "comparison_pipeline = Pipeline(\n",
    "    columns={\n",
    "        # Sharadar metrics (SF1)\n",
    "        'sharadar_revenue': SharadarFundamentals.revenue.latest,\n",
    "        'sharadar_netinc': SharadarFundamentals.netinc.latest,\n",
    "        'sharadar_roe': SharadarFundamentals.roe.latest,\n",
    "        'sharadar_pe': SharadarFundamentals.pe.latest,\n",
    "        'sharadar_de': SharadarFundamentals.de.latest,\n",
    "        'sharadar_marketcap': SharadarFundamentals.marketcap.latest,\n",
    "        \n",
    "        # Custom LSEG metrics\n",
    "        'lseg_revenue': CustomFundamentals.Revenue.latest,\n",
    "        'lseg_netincome': CustomFundamentals.NetIncome.latest,\n",
    "        'lseg_roe': CustomFundamentals.ROE.latest,\n",
    "        'lseg_pe': CustomFundamentals.PERatio.latest,\n",
    "        'lseg_de': CustomFundamentals.DebtToEquity.latest,\n",
    "        'lseg_assets': CustomFundamentals.TotalAssets.latest,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Running multi-source comparison pipeline...\")\n",
    "comparison_data = engine.run_pipeline(comparison_pipeline, test_date, test_date)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Multi-Source Data Comparison\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total assets: {len(comparison_data):,}\")\n",
    "print(f\"\\nData coverage by source:\")\n",
    "print(f\"  Sharadar metrics: {comparison_data[['sharadar_revenue', 'sharadar_roe']].dropna(how='all').shape[0]:,} assets\")\n",
    "print(f\"  LSEG metrics: {comparison_data[['lseg_revenue', 'lseg_roe']].dropna(how='all').shape[0]:,} assets\")\n",
    "\n",
    "# Find assets with data from BOTH sources\n",
    "both_sources = comparison_data[\n",
    "    comparison_data['sharadar_roe'].notna() &\n",
    "    comparison_data['lseg_roe'].notna()\n",
    "]\n",
    "print(f\"  Both sources: {len(both_sources):,} assets\")\n",
    "\n",
    "print(f\"\\nSample comparison (stocks with both Sharadar + LSEG data):\\n\")\n",
    "if len(both_sources) > 0:\n",
    "    sample = both_sources.head(10)\n",
    "    display_cols = ['sharadar_roe', 'lseg_roe', 'sharadar_pe', 'lseg_pe', 'sharadar_de', 'lseg_de']\n",
    "    print(sample[display_cols].to_string())\n",
    "else:\n",
    "    print(\"  Note: No stocks have data from both sources on this date.\")\n",
    "    print(\"  This is expected if your custom database has a limited universe.\")\n",
    "    print(\"\\n  Showing Sharadar data:\")\n",
    "    sharadar_only = comparison_data[comparison_data['sharadar_roe'].notna()].head(10)\n",
    "    print(sharadar_only[['sharadar_revenue', 'sharadar_roe', 'sharadar_pe']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Quality Check - Compare ROE from Both Sources\n",
    "\n",
    "For stocks where both sources have data, compare the ROE values to check consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(both_sources) > 5:\n",
    "    # Calculate difference between sources\n",
    "    both_sources_copy = both_sources.copy()\n",
    "    both_sources_copy['roe_diff'] = abs(both_sources_copy['sharadar_roe'] - both_sources_copy['lseg_roe'])\n",
    "    both_sources_copy['roe_pct_diff'] = (\n",
    "        both_sources_copy['roe_diff'] / both_sources_copy['sharadar_roe'].abs() * 100\n",
    "    )\n",
    "    \n",
    "    print(\"ROE Comparison Statistics:\")\n",
    "    print(f\"  Mean difference: {both_sources_copy['roe_diff'].mean():.4f}\")\n",
    "    print(f\"  Median difference: {both_sources_copy['roe_diff'].median():.4f}\")\n",
    "    print(f\"  Max difference: {both_sources_copy['roe_diff'].max():.4f}\")\n",
    "    print(f\"\\n  Correlation: {both_sources['sharadar_roe'].corr(both_sources['lseg_roe']):.4f}\")\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(both_sources['sharadar_roe'] * 100, both_sources['lseg_roe'] * 100, alpha=0.6)\n",
    "    plt.xlabel('Sharadar ROE (%)', fontsize=11)\n",
    "    plt.ylabel('LSEG ROE (%)', fontsize=11)\n",
    "    plt.title('ROE Comparison: Sharadar vs LSEG', fontsize=12, fontweight='bold')\n",
    "    plt.plot([-50, 50], [-50, 50], 'r--', alpha=0.5, label='Perfect Agreement')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    both_sources_copy['roe_pct_diff'].hist(bins=20)\n",
    "    plt.xlabel('ROE % Difference', fontsize=11)\n",
    "    plt.ylabel('Frequency', fontsize=11)\n",
    "    plt.title('Distribution of ROE Differences', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough overlapping data for comparison plot.\")\n",
    "    print(\"Your custom LSEG database may have a limited stock universe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Multi-Source Screening Strategy\n",
    "\n",
    "Build a screening strategy that combines insights from both sources:\n",
    "1. **Primary Source**: Use Sharadar (broader coverage)\n",
    "2. **Validation**: Use LSEG where available to confirm signals\n",
    "3. **Consensus**: Higher confidence when both sources agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy: Quality stocks with consensus from both sources (where available)\n",
    "strategy_pipeline = Pipeline(\n",
    "    columns={\n",
    "        # Sharadar fundamentals (primary)\n",
    "        's_revenue': SharadarFundamentals.revenue.latest,\n",
    "        's_netinc': SharadarFundamentals.netinc.latest,\n",
    "        's_roe': SharadarFundamentals.roe.latest,\n",
    "        's_pe': SharadarFundamentals.pe.latest,\n",
    "        's_de': SharadarFundamentals.de.latest,\n",
    "        's_marketcap': SharadarFundamentals.marketcap.latest,\n",
    "        \n",
    "        # LSEG fundamentals (validation)\n",
    "        'l_roe': CustomFundamentals.ROE.latest,\n",
    "        'l_pe': CustomFundamentals.PERatio.latest,\n",
    "        'l_de': CustomFundamentals.DebtToEquity.latest,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Running multi-source strategy pipeline...\")\n",
    "strategy_data = engine.run_pipeline(strategy_pipeline, test_date, test_date)\n",
    "\n",
    "# Filter for quality stocks using Sharadar (primary criteria)\n",
    "quality_sharadar = strategy_data[\n",
    "    (strategy_data['s_roe'] > 0.15) &       # ROE > 15%\n",
    "    (strategy_data['s_pe'] > 0) &\n",
    "    (strategy_data['s_pe'] < 25) &         # P/E < 25\n",
    "    (strategy_data['s_de'] < 2) &          # D/E < 2\n",
    "    (strategy_data['s_netinc'] > 0) &      # Profitable\n",
    "    (strategy_data['s_marketcap'] > 1e9)   # Market cap > $1B\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Multi-Source Quality Screen Results\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nQuality stocks (Sharadar criteria): {len(quality_sharadar)}\")\n",
    "\n",
    "# Add consensus scoring\n",
    "quality_sharadar['has_lseg_data'] = quality_sharadar['l_roe'].notna()\n",
    "quality_sharadar['consensus_score'] = 0\n",
    "\n",
    "# Add points for Sharadar quality\n",
    "quality_sharadar.loc[quality_sharadar['s_roe'] > 0.20, 'consensus_score'] += 1\n",
    "quality_sharadar.loc[quality_sharadar['s_pe'] < 20, 'consensus_score'] += 1\n",
    "quality_sharadar.loc[quality_sharadar['s_de'] < 1, 'consensus_score'] += 1\n",
    "\n",
    "# Add bonus points where LSEG confirms\n",
    "lseg_confirms_roe = (\n",
    "    quality_sharadar['l_roe'].notna() &\n",
    "    (quality_sharadar['l_roe'] > 0.15)\n",
    ")\n",
    "quality_sharadar.loc[lseg_confirms_roe, 'consensus_score'] += 2  # Bonus for LSEG confirmation\n",
    "\n",
    "# Sort by consensus score\n",
    "quality_sharadar = quality_sharadar.sort_values('consensus_score', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Quality Stocks (by consensus score):\\n\")\n",
    "top_picks = quality_sharadar.head(20)\n",
    "display_cols = ['s_roe', 'l_roe', 's_pe', 'l_pe', 's_de', 'has_lseg_data', 'consensus_score']\n",
    "print(top_picks[display_cols].to_string())\n",
    "\n",
    "# Show breakdown\n",
    "print(f\"\\nConsensus Score Breakdown:\")\n",
    "print(quality_sharadar.groupby('consensus_score').size().sort_index(ascending=False).to_string())\n",
    "\n",
    "# High conviction picks (both sources agree)\n",
    "high_conviction = quality_sharadar[\n",
    "    quality_sharadar['has_lseg_data'] &\n",
    "    (quality_sharadar['consensus_score'] >= 4)\n",
    "]\n",
    "print(f\"\\n✓ High conviction picks (LSEG confirms + high score): {len(high_conviction)} stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Coverage Analysis\n",
    "\n",
    "Understand where each data source provides coverage and where they overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage analysis\n",
    "coverage_analysis = pd.DataFrame({\n",
    "    'Metric': ['Revenue', 'ROE', 'P/E', 'D/E'],\n",
    "    'Sharadar Coverage': [\n",
    "        comparison_data['sharadar_revenue'].notna().sum(),\n",
    "        comparison_data['sharadar_roe'].notna().sum(),\n",
    "        comparison_data['sharadar_pe'].notna().sum(),\n",
    "        comparison_data['sharadar_de'].notna().sum(),\n",
    "    ],\n",
    "    'LSEG Coverage': [\n",
    "        comparison_data['lseg_revenue'].notna().sum(),\n",
    "        comparison_data['lseg_roe'].notna().sum(),\n",
    "        comparison_data['lseg_pe'].notna().sum(),\n",
    "        comparison_data['lseg_de'].notna().sum(),\n",
    "    ],\n",
    "})\n",
    "\n",
    "# Calculate overlap\n",
    "coverage_analysis['Both Sources'] = [\n",
    "    (comparison_data['sharadar_revenue'].notna() & comparison_data['lseg_revenue'].notna()).sum(),\n",
    "    (comparison_data['sharadar_roe'].notna() & comparison_data['lseg_roe'].notna()).sum(),\n",
    "    (comparison_data['sharadar_pe'].notna() & comparison_data['lseg_pe'].notna()).sum(),\n",
    "    (comparison_data['sharadar_de'].notna() & comparison_data['lseg_de'].notna()).sum(),\n",
    "]\n",
    "\n",
    "coverage_analysis['Sharadar %'] = (\n",
    "    coverage_analysis['Sharadar Coverage'] / len(comparison_data) * 100\n",
    ").round(1)\n",
    "\n",
    "coverage_analysis['LSEG %'] = (\n",
    "    coverage_analysis['LSEG Coverage'] / len(comparison_data) * 100\n",
    ").round(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Coverage Analysis\")\n",
    "print(\"=\"*80)\n",
    "print(coverage_analysis.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(coverage_analysis))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, coverage_analysis['Sharadar Coverage'], width, label='Sharadar', alpha=0.8)\n",
    "ax.bar(x, coverage_analysis['LSEG Coverage'], width, label='LSEG', alpha=0.8)\n",
    "ax.bar(x + width, coverage_analysis['Both Sources'], width, label='Both', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Metric', fontsize=12)\n",
    "ax.set_ylabel('Number of Assets', fontsize=12)\n",
    "ax.set_title('Data Coverage: Sharadar vs LSEG', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(coverage_analysis['Metric'])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Runnable Backtest Strategy\n",
    "\n",
    "Now let's run a complete backtest using both data sources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline import run_algorithm\n",
    "from zipline.api import (\n",
    "    attach_pipeline,\n",
    "    pipeline_output,\n",
    "    order_target_percent,\n",
    "    record,\n",
    "    schedule_function,\n",
    "    date_rules,\n",
    "    time_rules,\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# STRATEGY CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "TOP_N_STOCKS = 15\n",
    "REBALANCE_FREQ = 'monthly'\n",
    "\n",
    "# ============================================================================\n",
    "# PIPELINE FACTORY\n",
    "# ============================================================================\n",
    "\n",
    "def make_multi_source_pipeline():\n",
    "    \"\"\"\n",
    "    Create pipeline combining Sharadar + LSEG fundamentals.\n",
    "    \n",
    "    Strategy:\n",
    "    - Use Sharadar as primary source (broader coverage)\n",
    "    - Use LSEG for validation where available\n",
    "    - Prefer stocks where both sources show quality metrics\n",
    "    \"\"\"\n",
    "    # Sharadar metrics\n",
    "    s_roe = SharadarFundamentals.roe.latest\n",
    "    s_pe = SharadarFundamentals.pe.latest\n",
    "    s_de = SharadarFundamentals.de.latest\n",
    "    s_netinc = SharadarFundamentals.netinc.latest\n",
    "    s_marketcap = SharadarFundamentals.marketcap.latest\n",
    "    \n",
    "    # LSEG metrics (for confirmation)\n",
    "    l_roe = CustomFundamentals.ROE.latest\n",
    "    l_pe = CustomFundamentals.PERatio.latest\n",
    "    \n",
    "    # Quality screen (Sharadar)\n",
    "    quality_screen = (\n",
    "        (s_roe > 0.15) &      # ROE > 15%\n",
    "        (s_pe > 0) &\n",
    "        (s_pe < 25) &         # P/E < 25\n",
    "        (s_de < 2) &          # D/E < 2\n",
    "        (s_netinc > 0) &      # Profitable\n",
    "        (s_marketcap > 1e9)   # $1B+ market cap\n",
    "    )\n",
    "    \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            's_roe': s_roe,\n",
    "            's_pe': s_pe,\n",
    "            's_de': s_de,\n",
    "            's_marketcap': s_marketcap,\n",
    "            'l_roe': l_roe,\n",
    "            'l_pe': l_pe,\n",
    "        },\n",
    "        screen=quality_screen,\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# STRATEGY LOGIC\n",
    "# ============================================================================\n",
    "\n",
    "def initialize(context):\n",
    "    \"\"\"Initialize strategy.\"\"\"\n",
    "    # Attach multi-source pipeline\n",
    "    attach_pipeline(make_multi_source_pipeline(), 'multi_source')\n",
    "    \n",
    "    # Schedule rebalancing\n",
    "    if REBALANCE_FREQ == 'monthly':\n",
    "        schedule_function(\n",
    "            rebalance,\n",
    "            date_rules.month_start(),\n",
    "            time_rules.market_open(hours=1)\n",
    "        )\n",
    "    else:\n",
    "        schedule_function(\n",
    "            rebalance,\n",
    "            date_rules.week_start(),\n",
    "            time_rules.market_open(hours=1)\n",
    "        )\n",
    "    \n",
    "    # Daily recording\n",
    "    schedule_function(\n",
    "        record_vars,\n",
    "        date_rules.every_day(),\n",
    "        time_rules.market_close()\n",
    "    )\n",
    "    \n",
    "    context.stocks_held = []\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Multi-Source Fundamentals Strategy Initialized\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Top N stocks: {TOP_N_STOCKS}\")\n",
    "    print(f\"Rebalance frequency: {REBALANCE_FREQ}\")\n",
    "    print(f\"Data sources: Sharadar SF1 + Custom LSEG\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def before_trading_start(context, data):\n",
    "    \"\"\"Update pipeline data daily.\"\"\"\n",
    "    context.pipeline_data = pipeline_output('multi_source')\n",
    "\n",
    "\n",
    "def rebalance(context, data):\n",
    "    \"\"\"Monthly/weekly rebalancing.\"\"\"\n",
    "    pipeline_data = context.pipeline_data\n",
    "    \n",
    "    if len(pipeline_data) == 0:\n",
    "        print(f\"[{context.datetime.date()}] No stocks passed quality screen\")\n",
    "        # Exit all positions\n",
    "        for stock in context.portfolio.positions:\n",
    "            order_target_percent(stock, 0)\n",
    "        context.stocks_held = []\n",
    "        return\n",
    "    \n",
    "    # Calculate consensus score\n",
    "    pipeline_data = pipeline_data.copy()\n",
    "    pipeline_data['consensus_score'] = 0\n",
    "    \n",
    "    # Points for Sharadar quality\n",
    "    pipeline_data.loc[pipeline_data['s_roe'] > 0.20, 'consensus_score'] += 2\n",
    "    pipeline_data.loc[pipeline_data['s_pe'] < 20, 'consensus_score'] += 1\n",
    "    pipeline_data.loc[pipeline_data['s_de'] < 1, 'consensus_score'] += 1\n",
    "    \n",
    "    # Bonus where LSEG confirms\n",
    "    lseg_confirms = (\n",
    "        pipeline_data['l_roe'].notna() &\n",
    "        (pipeline_data['l_roe'] > 0.15)\n",
    "    )\n",
    "    pipeline_data.loc[lseg_confirms, 'consensus_score'] += 2\n",
    "    \n",
    "    # Select top N by consensus score, then by ROE\n",
    "    ranked = pipeline_data.sort_values(\n",
    "        ['consensus_score', 's_roe'],\n",
    "        ascending=[False, False]\n",
    "    )\n",
    "    \n",
    "    target_stocks = ranked.head(TOP_N_STOCKS).index.tolist()\n",
    "    \n",
    "    # Equal weight portfolio\n",
    "    target_weight = 1.0 / len(target_stocks) if target_stocks else 0\n",
    "    \n",
    "    # Rebalance\n",
    "    for stock in target_stocks:\n",
    "        if data.can_trade(stock):\n",
    "            order_target_percent(stock, target_weight)\n",
    "    \n",
    "    # Exit positions not in target\n",
    "    for stock in context.portfolio.positions:\n",
    "        if stock not in target_stocks and data.can_trade(stock):\n",
    "            order_target_percent(stock, 0)\n",
    "    \n",
    "    context.stocks_held = target_stocks\n",
    "    \n",
    "    # Log rebalancing\n",
    "    lseg_confirmed = ranked.head(TOP_N_STOCKS)['l_roe'].notna().sum()\n",
    "    print(f\"[{context.datetime.date()}] Rebalanced: {len(target_stocks)} stocks, \"\n",
    "          f\"{lseg_confirmed} confirmed by LSEG\")\n",
    "\n",
    "\n",
    "def record_vars(context, data):\n",
    "    \"\"\"Record daily metrics.\"\"\"\n",
    "    record(\n",
    "        num_positions=len(context.portfolio.positions),\n",
    "        portfolio_value=context.portfolio.portfolio_value,\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze(context, perf):\n",
    "    \"\"\"Analyze backtest results.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Backtest Complete - Performance Summary\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    returns = perf['returns']\n",
    "    total_return = (perf['portfolio_value'].iloc[-1] / perf['portfolio_value'].iloc[0] - 1) * 100\n",
    "    \n",
    "    print(f\"\\nTotal Return: {total_return:.2f}%\")\n",
    "    print(f\"Start Value: ${perf['portfolio_value'].iloc[0]:,.2f}\")\n",
    "    print(f\"End Value: ${perf['portfolio_value'].iloc[-1]:,.2f}\")\n",
    "    print(f\"\\nAvg Daily Return: {returns.mean() * 100:.3f}%\")\n",
    "    print(f\"Volatility (daily): {returns.std() * 100:.3f}%\")\n",
    "    print(f\"Sharpe Ratio: {returns.mean() / returns.std() * np.sqrt(252):.3f}\" if returns.std() > 0 else \"N/A\")\n",
    "    print(f\"\\nMax Positions: {perf['num_positions'].max():.0f}\")\n",
    "    print(f\"Avg Positions: {perf['num_positions'].mean():.1f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "    \n",
    "    return perf\n",
    "\n",
    "print(\"✓ Strategy functions defined\")\n",
    "print(\"  Ready to run backtest!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest parameters\n",
    "START_DATE = pd.Timestamp('2023-01-01', tz='UTC')\n",
    "END_DATE = pd.Timestamp('2024-11-01', tz='UTC')\n",
    "CAPITAL_BASE = 100000  # $100K starting capital\n",
    "\n",
    "print(f\"Running backtest from {START_DATE.date()} to {END_DATE.date()}...\\n\")\n",
    "\n",
    "try:\n",
    "    results = run_algorithm(\n",
    "        start=START_DATE,\n",
    "        end=END_DATE,\n",
    "        initialize=initialize,\n",
    "        before_trading_start=before_trading_start,\n",
    "        analyze=analyze,\n",
    "        capital_base=CAPITAL_BASE,\n",
    "        bundle='sharadar',\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✓ Backtest completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Backtest failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results is not None:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    \n",
    "    # Portfolio value\n",
    "    axes[0].plot(results.index, results['portfolio_value'], linewidth=2)\n",
    "    axes[0].set_title('Portfolio Value Over Time', fontsize=13, fontweight='bold')\n",
    "    axes[0].set_ylabel('Value ($)', fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].axhline(y=CAPITAL_BASE, color='r', linestyle='--', alpha=0.5, label='Starting Capital')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Cumulative returns\n",
    "    cum_returns = (1 + results['returns']).cumprod() - 1\n",
    "    axes[1].plot(results.index, cum_returns * 100, linewidth=2, color='green')\n",
    "    axes[1].set_title('Cumulative Returns', fontsize=13, fontweight='bold')\n",
    "    axes[1].set_ylabel('Return (%)', fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Number of positions\n",
    "    axes[2].plot(results.index, results['num_positions'], linewidth=1.5, color='orange')\n",
    "    axes[2].set_title('Number of Positions', fontsize=13, fontweight='bold')\n",
    "    axes[2].set_ylabel('Positions', fontsize=11)\n",
    "    axes[2].set_xlabel('Date', fontsize=11)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].axhline(y=TOP_N_STOCKS, color='r', linestyle='--', alpha=0.5, label=f'Target ({TOP_N_STOCKS})')\n",
    "    axes[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save results\n",
    "    results_path = '/notebooks/multi_source_backtest_results.csv'\n",
    "    results.to_csv(results_path)\n",
    "    print(f\"\\n✓ Results saved to: {results_path}\")\n",
    "else:\n",
    "    print(\"No results to visualize (backtest failed).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "### ✅ Multi-Source Data Integration\n",
    "- Successfully loaded both Sharadar SF1 and custom LSEG fundamentals\n",
    "- Used custom loader routing to access both sources simultaneously\n",
    "- Compared metrics across sources for data quality validation\n",
    "\n",
    "### ✅ Data Quality Analysis\n",
    "- Compared ROE, P/E, D/E from both sources\n",
    "- Identified overlapping coverage\n",
    "- Calculated correlation and differences\n",
    "\n",
    "### ✅ Consensus Scoring\n",
    "- Built composite quality score using both sources\n",
    "- Gave bonus points when LSEG confirms Sharadar signals\n",
    "- Identified high-conviction picks where both sources agree\n",
    "\n",
    "### ✅ Production-Ready Strategy\n",
    "- Complete backtest using multi-source fundamentals\n",
    "- Monthly rebalancing with quality screening\n",
    "- Performance tracking and visualization\n",
    "\n",
    "---\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "**Coverage**:\n",
    "- Sharadar provides broad coverage (~5,000+ stocks)\n",
    "- Custom LSEG provides validation/confirmation\n",
    "- Overlap depends on your LSEG universe\n",
    "\n",
    "**Data Quality**:\n",
    "- Compare metrics across sources to catch errors\n",
    "- Use consensus when both sources available\n",
    "- Fall back to Sharadar for broader coverage\n",
    "\n",
    "**Strategy Design**:\n",
    "- Primary screen: Sharadar (broader coverage)\n",
    "- Validation: LSEG where available\n",
    "- Confidence boost: Both sources agree\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Expand Custom Universe**: Add more stocks to LSEG database for better coverage\n",
    "2. **Add More Metrics**: Compare additional fundamental metrics\n",
    "3. **Discrepancy Analysis**: Investigate large differences between sources\n",
    "4. **Alpha Discovery**: Find stocks where sources disagree (potential mispricing)\n",
    "5. **Production Deployment**: Use consensus scores in live trading\n",
    "\n",
    "---\n",
    "\n",
    "**Documentation**:\n",
    "- Sharadar Guide: `docs/SHARADAR_FUNDAMENTALS_GUIDE.md`\n",
    "- Custom Data Guide: `examples/custom_data/README.md`\n",
    "- Database Class: `examples/custom_data/DATABASE_CLASS_GUIDE.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
