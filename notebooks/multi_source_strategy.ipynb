{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Source Fundamentals Strategy\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Multi-source data integration** - Combining Sharadar and custom LSEG fundamentals\n",
    "2. **FlightLog monitoring** - Real-time log streaming\n",
    "3. **Pyfolio analysis** - Comprehensive performance tearsheet\n",
    "4. **run_strategy helper** - Easy strategy execution\n",
    "\n",
    "## Strategy Overview\n",
    "\n",
    "**Consensus Quality Strategy:**\n",
    "- Universe: Top 100 stocks by market cap (Sharadar)\n",
    "- Quality filter: ROE > 15% from BOTH Sharadar AND LSEG\n",
    "- Selection: Top 5 by Sharadar ROE with dual confirmation\n",
    "- Rebalance: Weekly\n",
    "\n",
    "The key insight: When multiple data sources agree on quality metrics, we have higher confidence.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Sharadar bundle ingested:** `zipline ingest -b sharadar`\n",
    "2. **Custom LSEG database:** `~/.zipline/data/custom/fundamentals.sqlite`\n",
    "3. **FlightLog running:** Check terminal on port 9020 (optional)\n",
    "4. **Pyfolio installed:** `pip install pyfolio-reloaded`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Register Bundle and Import Multi-Source Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Sharadar bundle (required for Jupyter notebooks)\n",
    "from zipline.data.bundles import register\n",
    "from zipline.data.bundles.sharadar_bundle import sharadar_bundle\n",
    "\n",
    "register(\n",
    "    'sharadar',\n",
    "    sharadar_bundle(\n",
    "        tickers=None,\n",
    "        incremental=True,\n",
    "        include_funds=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"\u2713 Sharadar bundle registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the centralized multi-source module - simple!\n",
    "from zipline.pipeline import multi_source as ms\n",
    "\n",
    "# Zipline API\n",
    "from zipline import run_algorithm\n",
    "from zipline.api import (\n",
    "    attach_pipeline,\n",
    "    pipeline_output,\n",
    "    order_target_percent,\n",
    "    schedule_function,\n",
    "    date_rules,\n",
    "    time_rules,\n",
    "    record,\n",
    ")\n",
    "\n",
    "# Progress logging\n",
    "from zipline.utils.progress import enable_progress_logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "logging.getLogger('matplotlib.category').setLevel(logging.WARNING)\n",
    "\n",
    "print(\"\u2713 Imports successful\")\n",
    "print(f\"\\nAvailable multi_source components:\")\n",
    "print(f\"  - ms.Pipeline\")\n",
    "print(f\"  - ms.Database\")\n",
    "print(f\"  - ms.Column\")\n",
    "print(f\"  - ms.sharadar\")\n",
    "print(f\"  - ms.setup_auto_loader()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup FlightLog (Optional)\n",
    "\n",
    "FlightLog provides real-time log monitoring in a separate terminal.\n",
    "\n",
    "**To use FlightLog:**\n",
    "1. Open a second terminal\n",
    "2. Run: `docker logs -f zipline-flightlog`\n",
    "3. You'll see colorized logs streaming in real-time during the backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.utils.flightlog_client import enable_flightlog, log_to_flightlog\n",
    "\n",
    "# Enable FlightLog\n",
    "try:\n",
    "    enable_flightlog(host='localhost', port=9020)\n",
    "    log_to_flightlog('\ud83d\ude80 Multi-Source Strategy - FlightLog Connected', level='INFO')\n",
    "    print(\"\u2705 FlightLog enabled - check your second terminal!\")\n",
    "    FLIGHTLOG_ENABLED = True\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f  FlightLog not available: {e}\")\n",
    "    print(\"   Continuing without FlightLog...\")\n",
    "    FLIGHTLOG_ENABLED = False\n",
    "    # Define no-op function\n",
    "    def log_to_flightlog(msg, level='INFO'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable progress logging\n",
    "enable_progress_logging(\n",
    "    algo_name='MultiSource-Consensus',\n",
    "    update_interval=5  # Update every 5 trading days\n",
    ")\n",
    "\n",
    "print(\"\u2705 Progress logging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom LSEG Fundamentals Database\n",
    "\n",
    "Using the new centralized imports, defining a custom database is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSEGFundamentals(ms.Database):\n",
    "    \"\"\"Custom LSEG fundamentals database.\"\"\"\n",
    "    \n",
    "    CODE = \"fundamentals\"  # Must match SQLite database name\n",
    "    LOOKBACK_WINDOW = 252\n",
    "    \n",
    "    # Define columns matching database schema\n",
    "    ReturnOnEquity_SmartEstimat = ms.Column(float)\n",
    "    ForwardPEG_DailyTimeSeriesRatio_ = ms.Column(float)\n",
    "    CompanyMarketCap = ms.Column(float)\n",
    "    Debt_Total = ms.Column(float)\n",
    "\n",
    "print(\"\u2713 LSEG Fundamentals database defined\")\n",
    "print(f\"  Database: {LSEGFundamentals.CODE}\")\n",
    "print(f\"  Location: ~/.zipline/data/custom/{LSEGFundamentals.CODE}.sqlite\")\n",
    "print(f\"  Columns: {', '.join([k for k in dir(LSEGFundamentals) if not k.startswith('_') and k not in ['CODE', 'LOOKBACK_WINDOW']])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multi-Source Pipeline\n",
    "\n",
    "Mix Sharadar and LSEG data seamlessly in one pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(universe_size=100, selection_size=5):\n",
    "    \"\"\"\n",
    "    Multi-source consensus quality pipeline.\n",
    "    \n",
    "    Combines Sharadar and LSEG fundamentals to find high-quality stocks\n",
    "    where both data sources agree on quality metrics.\n",
    "    \"\"\"\n",
    "    # ========================================================================\n",
    "    # Sharadar Fundamentals\n",
    "    # ========================================================================\n",
    "    s_roe = ms.SharadarFundamentals.roe.latest\n",
    "    s_fcf = ms.SharadarFundamentals.fcf.latest\n",
    "    s_marketcap = ms.SharadarFundamentals.marketcap.latest\n",
    "    s_pe = ms.SharadarFundamentals.pe.latest\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LSEG Custom Fundamentals\n",
    "    # ========================================================================\n",
    "    l_roe = LSEGFundamentals.ReturnOnEquity_SmartEstimat.latest\n",
    "    l_peg = LSEGFundamentals.ForwardPEG_DailyTimeSeriesRatio_.latest\n",
    "    l_marketcap = LSEGFundamentals.CompanyMarketCap.latest\n",
    "    l_debt = LSEGFundamentals.Debt_Total.latest\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Universe: Top N by market cap (Sharadar)\n",
    "    # ========================================================================\n",
    "    universe = s_marketcap.top(universe_size)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Quality Filters\n",
    "    # ========================================================================\n",
    "    # Sharadar quality\n",
    "    sharadar_quality = (\n",
    "        (s_roe > 15.0) &\n",
    "        (s_fcf > 0) &\n",
    "        (s_pe > 0) & (s_pe < 30)\n",
    "    )\n",
    "    \n",
    "    # LSEG quality\n",
    "    lseg_quality = (\n",
    "        (l_roe > 15.0) &\n",
    "        (l_peg > 0) & (l_peg < 2.5)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Consensus: BOTH sources agree = higher confidence\n",
    "    # ========================================================================\n",
    "    both_confirm_quality = sharadar_quality & lseg_quality\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Selection: Top M by Sharadar ROE with dual confirmation\n",
    "    # ========================================================================\n",
    "    selection = s_roe.top(selection_size, mask=universe & both_confirm_quality)\n",
    "    \n",
    "    return ms.Pipeline(\n",
    "        columns={\n",
    "            # Sharadar metrics\n",
    "            's_roe': s_roe,\n",
    "            's_fcf': s_fcf,\n",
    "            's_marketcap': s_marketcap,\n",
    "            's_pe': s_pe,\n",
    "            # LSEG metrics\n",
    "            'l_roe': l_roe,\n",
    "            'l_peg': l_peg,\n",
    "            'l_marketcap': l_marketcap,\n",
    "            'l_debt': l_debt,\n",
    "            # Quality flags\n",
    "            'sharadar_quality': sharadar_quality,\n",
    "            'lseg_quality': lseg_quality,\n",
    "            'both_confirm': both_confirm_quality,\n",
    "        },\n",
    "        screen=selection,\n",
    "    )\n",
    "\n",
    "print(\"\u2713 Multi-source pipeline defined\")\n",
    "print(\"\\nPipeline features:\")\n",
    "print(\"  - Sharadar: ROE, FCF, MarketCap, PE\")\n",
    "print(\"  - LSEG: ROE, PEG, MarketCap, Debt\")\n",
    "print(\"  - Consensus scoring: Both sources must agree\")\n",
    "print(\"  - Universe: Top 100 by market cap\")\n",
    "print(\"  - Selection: Top 5 by ROE with dual confirmation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Strategy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(context):\n",
    "    \"\"\"Initialize strategy.\"\"\"\n",
    "    log_to_flightlog('='*80, level='INFO')\n",
    "    log_to_flightlog('\ud83d\ude80 Multi-Source Consensus Quality Strategy', level='INFO')\n",
    "    log_to_flightlog('='*80, level='INFO')\n",
    "    \n",
    "    # Attach pipeline\n",
    "    pipe = make_pipeline(universe_size=100, selection_size=5)\n",
    "    attach_pipeline(pipe, 'multi_source')\n",
    "    \n",
    "    log_to_flightlog('Pipeline attached:', level='INFO')\n",
    "    log_to_flightlog('  - Data sources: Sharadar + LSEG', level='INFO')\n",
    "    log_to_flightlog('  - Universe: Top 100 by market cap', level='INFO')\n",
    "    log_to_flightlog('  - Selection: Top 5 by ROE (dual confirmation)', level='INFO')\n",
    "    \n",
    "    # Schedule weekly rebalancing\n",
    "    schedule_function(\n",
    "        rebalance,\n",
    "        date_rules.week_start(),\n",
    "        time_rules.market_open(hours=1)\n",
    "    )\n",
    "    \n",
    "    log_to_flightlog('  - Rebalancing: Weekly (Monday at market open)', level='INFO')\n",
    "    log_to_flightlog('='*80, level='INFO')\n",
    "    \n",
    "    # Initialize tracking\n",
    "    context.rebalance_count = 0\n",
    "    context.confirmed_selections = []\n",
    "\n",
    "\n",
    "def before_trading_start(context, data):\n",
    "    \"\"\"Get pipeline data before market opens.\"\"\"\n",
    "    context.pipeline_data = pipeline_output('multi_source')\n",
    "\n",
    "\n",
    "def rebalance(context, data):\n",
    "    \"\"\"Weekly rebalancing.\"\"\"\n",
    "    context.rebalance_count += 1\n",
    "    \n",
    "    if context.pipeline_data is None or context.pipeline_data.empty:\n",
    "        log_to_flightlog(f'\u26a0\ufe0f  Rebalance #{context.rebalance_count}: No stocks in pipeline', level='WARNING')\n",
    "        return\n",
    "    \n",
    "    # Get tradeable stocks\n",
    "    all_selected = context.pipeline_data.index\n",
    "    selected_stocks = [s for s in all_selected if data.can_trade(s)]\n",
    "    \n",
    "    if not selected_stocks:\n",
    "        log_to_flightlog(f'\u26a0\ufe0f  Rebalance #{context.rebalance_count}: No tradeable stocks', level='WARNING')\n",
    "        return\n",
    "    \n",
    "    # Equal weight\n",
    "    target_weight = 1.0 / len(selected_stocks)\n",
    "    \n",
    "    # Get current positions\n",
    "    current_positions = set(context.portfolio.positions.keys())\n",
    "    target_positions = set(selected_stocks)\n",
    "    \n",
    "    # Sell positions no longer selected\n",
    "    for stock in current_positions - target_positions:\n",
    "        if data.can_trade(stock):\n",
    "            order_target_percent(stock, 0.0)\n",
    "    \n",
    "    # Buy/rebalance selected stocks\n",
    "    for stock in selected_stocks:\n",
    "        if data.can_trade(stock):\n",
    "            order_target_percent(stock, target_weight)\n",
    "    \n",
    "    # Count confirmations\n",
    "    confirmed = context.pipeline_data['both_confirm'].sum()\n",
    "    \n",
    "    # Get stock symbols and key metrics\n",
    "    holdings_info = []\n",
    "    for stock in selected_stocks:\n",
    "        symbol = stock.symbol\n",
    "        s_roe = context.pipeline_data.loc[stock, 's_roe']\n",
    "        l_roe = context.pipeline_data.loc[stock, 'l_roe']\n",
    "        confirmed_flag = '\u2713' if context.pipeline_data.loc[stock, 'both_confirm'] else '\u2717'\n",
    "        holdings_info.append(f\"{symbol} (S_ROE:{s_roe:.1f}%, L_ROE:{l_roe:.1f}% {confirmed_flag})\")\n",
    "    \n",
    "    log_to_flightlog(\n",
    "        f'\ud83d\udcca Rebalance #{context.rebalance_count}: '\n",
    "        f'{len(selected_stocks)} stocks, {confirmed} with dual confirmation',\n",
    "        level='INFO'\n",
    "    )\n",
    "    log_to_flightlog(f'   Holdings: {\", \".join(holdings_info)}', level='INFO')\n",
    "    \n",
    "    # Track for analysis\n",
    "    context.confirmed_selections.append((data.current_dt, confirmed, len(selected_stocks)))\n",
    "\n",
    "\n",
    "def handle_data(context, data):\n",
    "    \"\"\"Record daily metrics.\"\"\"\n",
    "    record(\n",
    "        portfolio_value=context.portfolio.portfolio_value,\n",
    "        cash=context.portfolio.cash,\n",
    "        leverage=context.account.leverage,\n",
    "        positions_count=len(context.portfolio.positions),\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze(context, perf):\n",
    "    \"\"\"Analyze results at end of backtest.\"\"\"\n",
    "    log_to_flightlog('='*80, level='INFO')\n",
    "    log_to_flightlog('\u2705 Backtest Complete!', level='INFO')\n",
    "    log_to_flightlog('='*80, level='INFO')\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    returns = perf['returns']\n",
    "    final_value = perf['portfolio_value'].iloc[-1]\n",
    "    initial_value = perf['portfolio_value'].iloc[0]\n",
    "    total_return = (final_value / initial_value - 1) * 100\n",
    "    \n",
    "    # Sharpe ratio (annualized)\n",
    "    sharpe = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "    \n",
    "    # Max drawdown\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    running_max = cum_returns.expanding().max()\n",
    "    drawdown = (cum_returns - running_max) / running_max\n",
    "    max_dd = drawdown.min() * 100\n",
    "    \n",
    "    # Win rate\n",
    "    winning_days = (returns > 0).sum()\n",
    "    total_days = len(returns[returns != 0])\n",
    "    win_rate = (winning_days / total_days * 100) if total_days > 0 else 0\n",
    "    \n",
    "    log_to_flightlog('BACKTEST SUMMARY:', level='INFO')\n",
    "    log_to_flightlog(f'  Period: {perf.index[0].date()} to {perf.index[-1].date()}', level='INFO')\n",
    "    log_to_flightlog(f'  Trading Days: {len(perf)}', level='INFO')\n",
    "    log_to_flightlog(f'  Rebalances: {context.rebalance_count}', level='INFO')\n",
    "    log_to_flightlog('', level='INFO')\n",
    "    log_to_flightlog('PERFORMANCE:', level='INFO')\n",
    "    log_to_flightlog(f'  Initial Value: ${initial_value:,.2f}', level='INFO')\n",
    "    log_to_flightlog(f'  Final Value: ${final_value:,.2f}', level='INFO')\n",
    "    log_to_flightlog(f'  Total Return: {total_return:.2f}%', level='INFO')\n",
    "    log_to_flightlog(f'  Sharpe Ratio: {sharpe:.2f}', level='INFO')\n",
    "    log_to_flightlog(f'  Max Drawdown: {max_dd:.2f}%', level='INFO')\n",
    "    log_to_flightlog(f'  Win Rate: {win_rate:.1f}%', level='INFO')\n",
    "    log_to_flightlog('='*80, level='INFO')\n",
    "    \n",
    "    return perf\n",
    "\n",
    "print(\"\u2713 Strategy functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Backtest with Auto Loader\n",
    "\n",
    "Notice how simple this is - just one line for the loader setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest parameters\n",
    "START = pd.Timestamp('2023-01-01')\n",
    "END = pd.Timestamp('2024-11-01')\n",
    "CAPITAL = 100000\n",
    "\n",
    "print(f\"Running backtest from {START.date()} to {END.date()}...\")\n",
    "print(f\"Starting capital: ${CAPITAL:,.2f}\")\n",
    "print(f\"Bundle: sharadar\")\n",
    "print(f\"Custom DB: fundamentals\")\n",
    "print()\n",
    "\n",
    "# Run backtest - notice the simple one-line loader setup!\n",
    "results = run_algorithm(\n",
    "    start=START,\n",
    "    end=END,\n",
    "    initialize=initialize,\n",
    "    before_trading_start=before_trading_start,\n",
    "    handle_data=handle_data,\n",
    "    analyze=analyze,\n",
    "    capital_base=CAPITAL,\n",
    "    bundle='sharadar',\n",
    "    custom_loader=ms.setup_auto_loader(),  # That's it! Auto-detects everything\n",
    ")\n",
    "\n",
    "print(\"\\n\u2705 Backtest complete!\")\n",
    "print(f\"Final portfolio value: ${results['portfolio_value'].iloc[-1]:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key metrics\n",
    "returns = results['returns']\n",
    "final_value = results['portfolio_value'].iloc[-1]\n",
    "initial_value = results['portfolio_value'].iloc[0]\n",
    "total_return = (final_value / initial_value - 1) * 100\n",
    "\n",
    "# Sharpe ratio\n",
    "sharpe = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "\n",
    "# Max drawdown\n",
    "cum_returns = (1 + returns).cumprod()\n",
    "running_max = cum_returns.expanding().max()\n",
    "drawdown = (cum_returns - running_max) / running_max\n",
    "max_dd = drawdown.min() * 100\n",
    "\n",
    "# Volatility\n",
    "volatility = returns.std() * np.sqrt(252) * 100\n",
    "\n",
    "# CAGR\n",
    "days = (results.index[-1] - results.index[0]).days\n",
    "years = days / 365.25\n",
    "cagr = ((final_value / initial_value) ** (1 / years) - 1) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Period: {results.index[0].date()} to {results.index[-1].date()}\")\n",
    "print(f\"Days: {len(results)} trading days ({years:.2f} years)\")\n",
    "print()\n",
    "print(f\"Initial Value: ${initial_value:,.2f}\")\n",
    "print(f\"Final Value: ${final_value:,.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "print(f\"CAGR: {cagr:.2f}%\")\n",
    "print()\n",
    "print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "print(f\"Max Drawdown: {max_dd:.2f}%\")\n",
    "print(f\"Volatility: {volatility:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio value and drawdown\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Portfolio value\n",
    "results['portfolio_value'].plot(ax=ax1, label='Portfolio Value', linewidth=2)\n",
    "ax1.set_ylabel('Portfolio Value ($)', fontsize=12)\n",
    "ax1.set_title('Multi-Source Consensus Quality Strategy - Portfolio Value', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "# Drawdown\n",
    "(drawdown * 100).plot(ax=ax2, label='Drawdown', color='red', alpha=0.7, linewidth=2)\n",
    "ax2.fill_between(drawdown.index, 0, drawdown * 100, color='red', alpha=0.3)\n",
    "ax2.set_ylabel('Drawdown (%)', fontsize=12)\n",
    "ax2.set_xlabel('Date', fontsize=12)\n",
    "ax2.set_title('Drawdown Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='lower left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Pyfolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyfolio\n",
    "try:\n",
    "    import pyfolio as pf\n",
    "    PYFOLIO_AVAILABLE = True\n",
    "    print(\"\u2713 Pyfolio imported successfully\")\n",
    "except ImportError:\n",
    "    PYFOLIO_AVAILABLE = False\n",
    "    print(\"\u26a0\ufe0f  Pyfolio not installed. Install with: pip install pyfolio-reloaded\")\n",
    "    print(\"   Skipping pyfolio analysis...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYFOLIO_AVAILABLE:\n",
    "    # Extract returns (required)\n",
    "    returns = results['returns']\n",
    "    \n",
    "    # Extract positions (optional but recommended)\n",
    "    positions_data = []\n",
    "    \n",
    "    for date, row in results.iterrows():\n",
    "        pos_dict = {}\n",
    "        \n",
    "        # Get cash\n",
    "        if 'cash' in results.columns:\n",
    "            pos_dict['cash'] = row['cash']\n",
    "        \n",
    "        # Get stock positions\n",
    "        if row['positions']:\n",
    "            for pos in row['positions']:\n",
    "                sid = pos['sid']\n",
    "                amount = pos['amount']\n",
    "                last_sale_price = pos['last_sale_price']\n",
    "                \n",
    "                if hasattr(sid, 'symbol'):\n",
    "                    symbol = sid.symbol\n",
    "                    pos_dict[symbol] = amount * last_sale_price\n",
    "        \n",
    "        if pos_dict:\n",
    "            positions_data.append((date, pos_dict))\n",
    "    \n",
    "    if positions_data:\n",
    "        positions = pd.DataFrame([p[1] for p in positions_data],\n",
    "                                index=[p[0] for p in positions_data])\n",
    "        positions = positions.fillna(0)\n",
    "    else:\n",
    "        positions = None\n",
    "    \n",
    "    # Extract transactions (optional)\n",
    "    transactions_list = []\n",
    "    for date, row in results.iterrows():\n",
    "        if row['transactions']:\n",
    "            for txn in row['transactions']:\n",
    "                sid = txn['sid']\n",
    "                symbol = sid.symbol if hasattr(sid, 'symbol') else str(sid)\n",
    "                \n",
    "                transactions_list.append({\n",
    "                    'symbol': symbol,\n",
    "                    'amount': txn['amount'],\n",
    "                    'price': txn['price'],\n",
    "                    'value': txn['amount'] * txn['price'],\n",
    "                })\n",
    "    \n",
    "    if transactions_list:\n",
    "        transactions = pd.DataFrame(transactions_list,\n",
    "                                   index=[date for date, row in results.iterrows()\n",
    "                                         if row['transactions'] for _ in row['transactions']])\n",
    "    else:\n",
    "        transactions = None\n",
    "    \n",
    "    print(\"\u2713 Data prepared for pyfolio\")\n",
    "    print(f\"  Returns: {len(returns)} days\")\n",
    "    if positions is not None:\n",
    "        print(f\"  Positions: {len(positions)} days, {len(positions.columns)} assets\")\n",
    "    print(f\"  Transactions: {len(transactions) if transactions is not None else 0} trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Pyfolio Tearsheet\n",
    "\n",
    "This creates a comprehensive analysis including:\n",
    "- Summary statistics\n",
    "- Worst drawdown periods\n",
    "- Rolling metrics (Sharpe, volatility)\n",
    "- Monthly/yearly returns heatmap\n",
    "- Return distribution plots\n",
    "- Position analysis\n",
    "- Transaction analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYFOLIO_AVAILABLE:\n",
    "    # Create full tearsheet\n",
    "    pf.create_full_tear_sheet(\n",
    "        returns,\n",
    "        positions=positions,\n",
    "        transactions=transactions,\n",
    "        live_start_date=None,\n",
    "        round_trips=False,\n",
    "        estimate_intraday=False,\n",
    "    )\n",
    "else:\n",
    "    print(\"Pyfolio not available - skipping tearsheet generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Pyfolio Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYFOLIO_AVAILABLE:\n",
    "    # Calculate detailed metrics\n",
    "    annual_return = pf.timeseries.annual_return(returns)\n",
    "    sharpe_ratio = pf.timeseries.sharpe_ratio(returns)\n",
    "    max_drawdown = pf.timeseries.max_drawdown(returns)\n",
    "    sortino_ratio = pf.timeseries.sortino_ratio(returns)\n",
    "    calmar_ratio = pf.timeseries.calmar_ratio(returns)\n",
    "    volatility = pf.timeseries.annual_volatility(returns)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED PYFOLIO METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Annual Return: {annual_return*100:.2f}%\")\n",
    "    print(f\"Annual Volatility: {volatility*100:.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "    print(f\"Sortino Ratio: {sortino_ratio:.2f}\")\n",
    "    print(f\"Calmar Ratio: {calmar_ratio:.2f}\")\n",
    "    print(f\"Max Drawdown: {max_drawdown*100:.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Cumulative returns\n",
    "    cum_returns = pf.timeseries.cum_returns(returns)\n",
    "    total_return = cum_returns.iloc[-1]\n",
    "    print(f\"\\nTotal Return: {total_return*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save results\n",
    "# results.to_csv('multi_source_backtest_results.csv')\n",
    "# returns.to_csv('multi_source_returns.csv')\n",
    "# if positions is not None:\n",
    "#     positions.to_csv('multi_source_positions.csv')\n",
    "# if transactions is not None:\n",
    "#     transactions.to_csv('multi_source_transactions.csv')\n",
    "\n",
    "print(\"To save results, uncomment the lines above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. **Multi-Source Integration:** Successfully combined Sharadar and LSEG fundamentals in one pipeline\n",
    "2. **Simple Setup:** Used centralized `multi_source` module for clean imports\n",
    "3. **Auto Loader:** One-line setup with `ms.setup_auto_loader()`\n",
    "4. **FlightLog Monitoring:** Real-time log streaming during backtest\n",
    "5. **Comprehensive Analysis:** Pyfolio tearsheet with detailed metrics\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Consensus Scoring:** Higher confidence when multiple sources agree\n",
    "- **Quality Filters:** ROE > 15%, FCF > 0, PE < 30, PEG < 2.5\n",
    "- **Weekly Rebalancing:** Systematic position updates\n",
    "- **Equal Weighting:** Simple, transparent allocation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Experiment with parameters:**\n",
    "   - Universe size (50, 100, 200)\n",
    "   - Selection size (3, 5, 10)\n",
    "   - Quality thresholds\n",
    "   - Rebalancing frequency\n",
    "\n",
    "2. **Add more factors:**\n",
    "   - Momentum\n",
    "   - Value metrics\n",
    "   - Technical indicators\n",
    "\n",
    "3. **Compare strategies:**\n",
    "   - Sharadar only\n",
    "   - LSEG only\n",
    "   - Consensus (both sources)\n",
    "\n",
    "4. **Risk management:**\n",
    "   - Position sizing\n",
    "   - Stop losses\n",
    "   - Volatility targeting\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Documentation:** `docs/MULTI_SOURCE_DATA.md`\n",
    "- **Quick Reference:** `docs/MULTI_SOURCE_QUICKREF.md`\n",
    "- **Examples:** `examples/custom_data/simple_multi_source_example.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}